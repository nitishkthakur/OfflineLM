{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1494fa2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RetrievalQA' from 'langchain' (/home/nitish/Documents/github/jarvis-offline/.venv/lib/python3.12/site-packages/langchain/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_experimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PythonREPLTool            \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_ollama\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA, PromptTemplate, LLMChain\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'RetrievalQA' from 'langchain' (/home/nitish/Documents/github/jarvis-offline/.venv/lib/python3.12/site-packages/langchain/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent   \n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool            \n",
    "from langchain_ollama  import ChatOllama\n",
    "from langchain import RetrievalQA, PromptTemplate, LLMChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbc6bc",
   "metadata": {},
   "source": [
    "## Build an agent which has access to a Tool which writes and executes python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61926f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the Euclidean norm (or vector norm) of the given vector [3, 4, 5].\n",
      "Action: Python_REPL\n",
      "Action Input: import math\n",
      "vector = [3, 4, 5]\n",
      "norm = math.sqrt(sum([x**2 for x in vector]))\n",
      "print(norm)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m7.0710678118654755\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The vector norm of [3, 4, 5] is approximately 7.071.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Result: The vector norm of [3, 4, 5] is approximately 7.071.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate your LLM\n",
    "llm = ChatOllama(model = \"qwen2.5:7b\", temperature=0)\n",
    "\n",
    "# Create the REPL tool\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# Spin up a “python agent”\n",
    "agent = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=python_repl,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Ask it to both write & run code\n",
    "result = agent.run(\n",
    "    \"Compute the vector norm of [3, 4, 5] and return the result.\")\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b848e",
   "metadata": {},
   "source": [
    "### Combine this with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bc9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "create_python_agent(\n",
      "    llm: langchain_core.language_models.base.BaseLanguageModel,\n",
      "    tool: langchain_experimental.tools.python.tool.PythonREPLTool,\n",
      "    agent_type: langchain.agents.agent_types.AgentType = <AgentType.ZERO_SHOT_REACT_DESCRIPTION: \u001b[33m'zero-shot-react-description'\u001b[39m>,\n",
      "    callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    verbose: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    prefix: str = \u001b[33m'You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \"I don\\'t know\" as the answer.\\n'\u001b[39m,\n",
      "    agent_executor_kwargs: Optional[Dict[str, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs: Dict[str, Any],\n",
      ") -> langchain.agents.agent.AgentExecutor\n",
      "\u001b[31mDocstring:\u001b[39m Construct a python agent from an LLM and tool.\n",
      "\u001b[31mFile:\u001b[39m      ~/Documents/github/jarvis-offline/.venv/lib/python3.12/site-packages/langchain_experimental/agents/agent_toolkits/python/base.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1️⃣ Your LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# 2️⃣ A vectorstore + retriever for RAG\n",
    "emb = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_existing_collection(\"my_collection\", embedding_function=emb)\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "# 3️⃣ Wrap RAG as a Tool\n",
    "rag_tool = Tool.from_function(\n",
    "    rag_chain.run,\n",
    "    name=\"rag_retriever\",\n",
    "    description=\"Use this to fetch relevant context from your document store.\"\n",
    ")\n",
    "\n",
    "# 4️⃣ Python REPL tool\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# 5️⃣ Put them both into an agent\n",
    "tools = [rag_tool, Tool.from_function(python_repl.run, name=\"python_repl\")]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 6️⃣ Run a mixed task\n",
    "prompt = \"\"\"\n",
    "Load the relevant data for 'quarterly earnings analysis' using rag_retriever.\n",
    "Then write Python code that computes the 90-day moving average of the 'revenue' field\n",
    "and return the result.\n",
    "\"\"\"\n",
    "print(agent.run(prompt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
