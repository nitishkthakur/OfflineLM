Discrete Choice Methods with
Simulation

Kenneth Train
University of California, Berkeley
National Economic Research Associates

Version dated March 8, 2002
Publisher: Cambridge University Press
Scheduled publication date: Autumn 2002.
Please contact me with any corrections, comments,
and suggestions, at train@econ.berkeley.edu
or 415-291-1023.

to
Daniel McFadden
and
in memory of
Kenneth Train, Sr.

This copy is made available for use by individuals for their personal
research and study. Permission is not granted to use any part of this
work for any other purpose whatsoever without the written consent of
Cambridge University Press.

iv

Contents
1 Introduction
1
1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Choice Probabilities and Integration . . . . . . . . . . . 3
1.3 Outline of book . . . . . . . . . . . . . . . . . . . . . . . 7
1.4 Topics not covered . . . . . . . . . . . . . . . . . . . . . 8
1.5 A couple notes . . . . . . . . . . . . . . . . . . . . . . . 12

I

Behavioral Models

13

2 Properties
2.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 The choice set . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Derivation of choice probabilities . . . . . . . . . . . . .
2.4 Speciﬁc models . . . . . . . . . . . . . . . . . . . . . . .
2.5 Identiﬁcation of choice models . . . . . . . . . . . . . . .
2.5.1 Only diﬀerences in utility matter . . . . . . . . .
2.5.2 The overall scale of utility is irrelevant . . . . . .
2.6 Aggregation . . . . . . . . . . . . . . . . . . . . . . . . .
2.6.1 Sample enumeration . . . . . . . . . . . . . . . .
2.6.2 Segmentation . . . . . . . . . . . . . . . . . . . .
2.7 Forecasting . . . . . . . . . . . . . . . . . . . . . . . . .
2.8 Recalibration of constants . . . . . . . . . . . . . . . . .

15
15
15
19
22
24
24
29
35
37
38
39
39

3 Logit
3.1 Choice probabilities . . . . . . . . . . . . . . . . . . . .
3.2 The scale parameter . . . . . . . . . . . . . . . . . . . .
3.3 Power and limitations of logit . . . . . . . . . . . . . . .
3.3.1 Taste variation . . . . . . . . . . . . . . . . . . .

41
41
48
50
50

v

vi

CONTENTS
3.3.2 Substitution patterns . . . . . . . . . . . . . . .
3.3.3 Panel data . . . . . . . . . . . . . . . . . . . . .
3.4 Non-linear representative utility . . . . . . . . . . . . . .
3.5 Consumer Surplus . . . . . . . . . . . . . . . . . . . . .
3.6 Derivatives and Elasticities . . . . . . . . . . . . . . . .
3.7 Estimation . . . . . . . . . . . . . . . . . . . . . . . . .
3.7.1 Exogenous sample . . . . . . . . . . . . . . . . .
3.7.2 Choice-based samples . . . . . . . . . . . . . . .
3.8 Goodness of Fit and Hypothesis Testing . . . . . . . . .
3.8.1 Goodness of ﬁt . . . . . . . . . . . . . . . . . . .
3.8.2 Hypothesis testing . . . . . . . . . . . . . . . . .
3.9 Case Study . . . . . . . . . . . . . . . . . . . . . . . . .
3.10 Derivation of Logit Probabilities . . . . . . . . . . . . .

53
59
61
64
67
70
70
76
78
78
80
81
85

4 GEV
87
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.2 Nested logit . . . . . . . . . . . . . . . . . . . . . . . . . 88
4.2.1 Substitution patterns . . . . . . . . . . . . . . . 88
4.2.2 Choice probabilities . . . . . . . . . . . . . . . . 90
4.2.3 Decomposition into two logits . . . . . . . . . . . 93
4.2.4 Estimation . . . . . . . . . . . . . . . . . . . . . 96
4.2.5 Equivalence of nested logit formulas . . . . . . . 98
4.3 Three-Level Nested Logit . . . . . . . . . . . . . . . . . 98
4.4 Overlapping Nests . . . . . . . . . . . . . . . . . . . . . 101
4.4.1 Paired combinatorial logit . . . . . . . . . . . . . 102
4.4.2 Generalized nested logit . . . . . . . . . . . . . . 104
4.5 Heteroskedastic Logit . . . . . . . . . . . . . . . . . . . 105
4.6 The GEV family . . . . . . . . . . . . . . . . . . . . . . 106
5 Probit
111
5.1 Choice probabilities . . . . . . . . . . . . . . . . . . . . 111
5.2 Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . 114
5.3 Taste variation . . . . . . . . . . . . . . . . . . . . . . . 121
5.4 Substitution patterns/non-IIA . . . . . . . . . . . . . . . 123
5.5 Panel data . . . . . . . . . . . . . . . . . . . . . . . . . . 126
5.6 Simulation of the choice probabilities . . . . . . . . . . . 130
5.6.1 Accept-reject simulator . . . . . . . . . . . . . . 131
5.6.2 Smoothed A-R simulators . . . . . . . . . . . . . 136
5.6.3 GHK simulator . . . . . . . . . . . . . . . . . . . 139

CONTENTS

vii

6 Mixed Logit
153
6.1 Choice probabilities . . . . . . . . . . . . . . . . . . . . 153
6.2 Random coeﬃcients . . . . . . . . . . . . . . . . . . . . 156
6.3 Error-components . . . . . . . . . . . . . . . . . . . . . . 158
6.4 Substitution patterns . . . . . . . . . . . . . . . . . . . . 160
6.5 Approximation to any random utility model . . . . . . . 161
6.6 Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . 163
6.7 Panel data . . . . . . . . . . . . . . . . . . . . . . . . . . 165
6.8 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . 168
7 Variations on a Theme
173
7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 173
7.2 SP/RP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
7.3 Ranked Data . . . . . . . . . . . . . . . . . . . . . . . . 178
7.3.1 Standard and mixed logit . . . . . . . . . . . . . 179
7.3.2 Probit . . . . . . . . . . . . . . . . . . . . . . . . 181
7.4 Ordered Responses . . . . . . . . . . . . . . . . . . . . . 182
7.4.1 Multiple ordered responses . . . . . . . . . . . . 186
7.5 Contingent Valuation . . . . . . . . . . . . . . . . . . . . 188
7.6 Mixed Models . . . . . . . . . . . . . . . . . . . . . . . . 190
7.6.1 Mixed Nested Logit . . . . . . . . . . . . . . . . 191
7.6.2 Mixed Probit . . . . . . . . . . . . . . . . . . . . 192
7.7 Dynamic optimization . . . . . . . . . . . . . . . . . . . 193
7.7.1 Two-periods, no uncertainty about future impacts195
7.7.2 Multiple periods . . . . . . . . . . . . . . . . . . 199
7.7.3 Uncertainty about future impacts . . . . . . . . . 203

II

Estimation

209

8 Numerical Maximization
211
8.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . 211
8.2 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
8.3 Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 213
8.3.1 Newton-Raphson . . . . . . . . . . . . . . . . . . 213
8.3.2 BHHH . . . . . . . . . . . . . . . . . . . . . . . . 220
8.3.3 BHHH-2 . . . . . . . . . . . . . . . . . . . . . . . 223
8.3.4 Steepest Ascent . . . . . . . . . . . . . . . . . . . 224
8.3.5 DFP and BFGS . . . . . . . . . . . . . . . . . . 225
8.4 Convergence criterion . . . . . . . . . . . . . . . . . . . 226

CONTENTS

viii
8.5
8.6
8.7

Local versus global maximum . . . . . . . . . . . . . . . 227
Variance of the Estimates . . . . . . . . . . . . . . . . . 228
Information Identity . . . . . . . . . . . . . . . . . . . . 229

9 Drawing from Densities
233
9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 233
9.2 Random Draws . . . . . . . . . . . . . . . . . . . . . . . 234
9.2.1 Standard normal and uniform . . . . . . . . . . . 234
9.2.2 Transformations of standard normal . . . . . . . 234
9.2.3 Inverse cumulative for univariate densities . . . . 235
9.2.4 Truncated univariate densities . . . . . . . . . . 236
9.2.5 Choleski transformation for multivariate normals 236
9.2.6 Accept-reject for truncated multivariate densities 238
9.2.7 Importance sampling . . . . . . . . . . . . . . . . 239
9.2.8 Gibbs sampling . . . . . . . . . . . . . . . . . . . 241
9.2.9 Metropolis-Hastings algorithm . . . . . . . . . . 242
9.3 Variance Reduction . . . . . . . . . . . . . . . . . . . . . 244
9.3.1 Antithetics . . . . . . . . . . . . . . . . . . . . . 245
9.3.2 Systematic sampling . . . . . . . . . . . . . . . . 248
9.3.3 Halton sequences . . . . . . . . . . . . . . . . . . 252
9.3.4 Randomized Halton draws . . . . . . . . . . . . . 263
9.3.5 Scrambled Halton draws . . . . . . . . . . . . . . 265
9.3.6 Other procedures . . . . . . . . . . . . . . . . . . 269
10 Simulation-Assisted Estimation
271
10.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . 271
10.2 Deﬁnition of estimators . . . . . . . . . . . . . . . . . . 273
10.2.1 Maximum simulated likelihood: MSL . . . . . . . 273
10.2.2 Method of simulated moments: MSM . . . . . . 274
10.2.3 Method of simulated scores: MSS . . . . . . . . . 277
10.3 The central limit theorem . . . . . . . . . . . . . . . . . 280
10.4 Traditional estimators . . . . . . . . . . . . . . . . . . . 282
10.5 Simulation-based estimators . . . . . . . . . . . . . . . . 285
10.5.1 Maximum simulated likelihood . . . . . . . . . . 290
10.5.2 Method of simulated moments . . . . . . . . . . 291
10.5.3 Method of simulated scores . . . . . . . . . . . . 292
10.6 Numerical Solution . . . . . . . . . . . . . . . . . . . . . 293

CONTENTS

ix

11 Individual-Level Parameters
295
11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 295
11.2 Derivation of conditional distribution . . . . . . . . . . . 298
11.3 Implications of estimation of θ . . . . . . . . . . . . . . 301
11.4 Monte Carlo illustration . . . . . . . . . . . . . . . . . . 304
11.5 Average conditional distribution . . . . . . . . . . . . . 307
11.6 Case Study . . . . . . . . . . . . . . . . . . . . . . . . . 307
11.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . 319
12 Bayesian Procedures
321
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 321
12.2 Overview of Bayesian concepts . . . . . . . . . . . . . . 324
12.2.1 Bayesian properties of θ̄ . . . . . . . . . . . . . . 326
12.2.2 Classical properties of θ̄: The Bernstein-von Mises
theorem . . . . . . . . . . . . . . . . . . . . . . . 327
12.3 Simulation of posterior mean . . . . . . . . . . . . . . . 331
12.4 Drawing from the posterior . . . . . . . . . . . . . . . . 333
12.5 Posteriors for Normals . . . . . . . . . . . . . . . . . . . 335
12.5.1 Result A: Unknown mean, known variance . . . . 335
12.5.2 Result B: Unknown variance, known mean . . . . 337
12.5.3 Unknown mean and variance . . . . . . . . . . . 340
12.6 Hierarchical Bayes for mixed logit . . . . . . . . . . . . . 340
12.6.1 Succinct restatement . . . . . . . . . . . . . . . . 345
12.7 Case Study: Choice of energy supplier . . . . . . . . . . 346
12.7.1 Independent normal coeﬃcients . . . . . . . . . . 347
12.7.2 Multivariate normal coeﬃcients . . . . . . . . . . 349
12.7.3 Fixed coeﬃcients for some variables . . . . . . . 350
12.7.4 Lognormals . . . . . . . . . . . . . . . . . . . . . 352
12.7.5 Triangulars . . . . . . . . . . . . . . . . . . . . . 353
12.7.6 Summary of results . . . . . . . . . . . . . . . . . 355
12.8 Bayesian procedures for probit models . . . . . . . . . . 355

x

CONTENTS

Chapter 1

Introduction
1.1

Motivation

When I wrote my ﬁrst book, Qualitative Choice Analysis, in the mid
1980’s, the ﬁeld had reached a critical juncture. The break-through
concepts that deﬁned the ﬁeld had been made. The basic models —
mainly logit and nested logit — had been introduced, and the statistical and economic properties of these models had been derived.
Applications had proven successful in many diﬀerent areas, including
transportation, energy, housing, and marketing — to name only a few.
The ﬁeld is at a similar juncture today for a new generation of procedures. The ﬁrst-generation models contained important limitations
that inhibited their applicability and realism. These limitations were
well recognized at the time, but ways to overcome them had not yet
been discovered. Over the past twenty years, tremendous progress has
been made, leading to what can only be called a sea-change in the
approach and methods of choice analysis. The early models have now
been supplemented by a variety of more powerful and more ﬂexible
methods. The new concepts have arisen gradually, with researchers
building on the work of others. However, in a sense, the change has
been more like a quantum leap than a gradual progression. The ways
that researchers think about, specify, and estimate their models has
changed. Importantly, a kind of consensus, or understanding, seems to
have emerged about the new methodology. Among researchers working
in the ﬁeld, a deﬁnite sense of purpose and progress prevails.
My purpose in writing this new book is to bring these ideas together, in a form that exempliﬁes the unity of approach that I feel
1

2

CHAPTER 1. INTRODUCTION

has emerged, and in a format that makes the methods accessible to
a wide audience. The advances have mostly centered on simulation.
Essentially, simulation is the researcher’s response to the inability of
computers to perform integration. Stated more precisely, simulation
provides a numerical approximation to integrals, with diﬀerent methods oﬀering diﬀerent properties and being applicable to diﬀerent kinds
of integrands.
Simulation allows estimation of otherwise intractable models. Practically any model can be estimated by some form of simulation. The
researcher is therefore freed from previous constraints on model speciﬁcation – constraints that reﬂected mathematical convenience rather
than the economic reality of the situation. This new ﬂexibility is a
tremendous boon to research. It allows more realistic representation
of the hugely varied choice situations that arise in the world. It enables the researcher to obtain more information from any given dataset
and, in many cases, allows previously unapproachable issues to be addressed.
This ﬂexibility places a new burden on the researcher. First, the
methods themselves are more complicated than earlier procedures and
utilize many concepts and procedures that are not covered in standard econometrics courses. Understanding the various techniques —
their advantages and limitations, and the relations among them — is
important when choosing the appropriate method in any particular
application and for developing new methods when none of the existing
models seems right. The purpose of this book is to assist readers along
this path.
Second, to implement a new method, or a variant on an old method,
the researcher needs to be able to program the procedure into computer software. This means that the researcher will often need to
know how maximum likelihood and other estimation methods work
from a computational perspective, how to code speciﬁc models, and
how to take existing code and change it to represent variations in
behavior. Some models, such as mixed logit and pure probit in addition of course to standard logit, are available in commercially available statistical packages. In fact, code for these and other models, as
well as manuals and sample data, are available (free) at my website
http://elsa.berkeley.edu/∼train. Whenever appropriate, researchers
should use available codes rather than writing their own. However,
the true value of the new approach to choice modeling is the ability to

1.2. CHOICE PROBABILITIES AND INTEGRATION

3

create tailor-made models. The computational and programming steps
that are needed to implement a new model are usually not diﬃcult. An
important goal of the book is to teach these skills as an integral part
of the exposition of the models themselves. I personally ﬁnd programming to be extremely valuable pedagogically. The process of coding
a model helps me to understand how exactly the model operates, the
reasons and implications of its structure, what features constitute the
essential elements that cannot be changed while maintaining the basic
approach, and which features are arbitrary and can easily be changed.
I imagine other people learn this way too.

1.2

Choice Probabilities and Integration

To focus ideas, I will now establish the conceptual basis for discrete
choice models and show where integration comes into play. An agent
(i.e., person, ﬁrm, decision-maker) faces a choice, or a series of choices
over time, among a set of options. For example, a customer chooses
which of several competing products to buy; a ﬁrm decides which technology to use in production; a student chooses which answer to give
on a multiple choice test; a survey respondent chooses an integer between 1 and 5 on a Lickert-scale question; a worker chooses whether to
continue working each year or retire. Denote the outcome of the decision(s) in any given situation as y, where y indicates the chosen option
or sequence of options. We assume for the purposes of this book that
the outcome variable is discrete in that it takes a countable number of
values. Many of the concepts that we describe are easily transferable
to situations where the outcome variable is continuous. However, notation and terminology is diﬀerent with continuous outcome variables
than discrete ones. Also, discrete choices generally reveal less information about the choice process than continuous-outcome choices, such
that the econometrics of discrete choice is usually more challenging.
Our goal is to understand the behavioral process that leads to the
agent’s choice. We take a causal perspective. There are factors that
collectively determine, or cause, the agent’s choice. Some of these
factors are observed by the researcher and some are not. The observed
factors are labeled x and the unobserved factors ε. The factors relate
to the agent’s choice through a function y = h(x, ε). This function
is called the behavioral process. It is deterministic in the sense that
given x and ε, the choice of the agent is fully determined.

CHAPTER 1. INTRODUCTION

4

Since ε is not observed, the agent’s choice is not deterministic and
cannot be predicted exactly. Instead, the probability of any particular
outcome is derived. The unobserved terms are considered random
with density f (ε). The probability that the agent chooses a particular
outcome from the set of all possible outcomes is simply the probability
that the unobserved factors are such that the behavioral process results
in that outcome: P (y|x) = Prob(ε s.t. h(x, ε) = y).
We can express this probability in a more useable form. Deﬁne an
indicator function I[h(x, ε) = y] that takes the value of 1 when the
statement in brackets is true and 0 when the statement is false. That
is, I[·] = 1 if the value of ε, combined with x, induces the agent to
choose outcome y and 0 if the value of ε, combined with x, induces
the agent to choose some other outcome. Then the probability that
the agent chooses outcome y is simply the expected value of this indicator function, where the expectation is over all possible values of the
unobserved factors:
P (y|x) = Prob(I[h(x, ε) = y] = 1)


=

I[h(x, ε) = y]f (ε) dε .

(1.1)

Stated in this form, the probability is an integral — speciﬁcally an
integral of an indicator for the outcome of the behavioral process over
all possible values of the unobserved factors.
To calculate this probability, the integral must be evaluated. There
are three possibilities.

Complete closed-form expression
For certain speciﬁcations of h and f , the integral can be expressed in
closed form. In these cases, the choice probability can be calculated
exactly from the closed-form formula. For example, consider a binary
logit model of whether or not a person takes a given action, such as
buying a new product. The behavioral model is speciﬁed as follows.
The person would obtain some net beneﬁt or utility from taking the
action. This utility, which can be either positive or negative, consists
of a part that is observed by the researcher, β  x where x is a vector
of variables and β is a vector of parameters, and a part that is not
observed, ε: U = β  x + ε. The person takes the action only if the
utility is positive, that is, only if doing so provides a net beneﬁt. The

1.2. CHOICE PROBABILITIES AND INTEGRATION

5

probability that the person takes
the action, given what the researcher

can observe, is therefore P = I[β  x + ε > 0]f (ε)dε where f is the
density of ε. Assume that ε is distributed logistic, such that its density
is f (ε) = e−ε /(1 + e−ε )2 with cumulative distribution F (ε) = 1/(1 +
e−ε ). Then the probability of the person taking the action is:


P

=


=

I[β  x + ε > 0]f (ε)dε
I[ε > −β  x]f (ε)dε

 ∞

=

ε=−β  x

f (ε)dε

= 1 − F (−β  x) = 1 −

1
1 + eβ  x



=

eβ x
1 + eβ  x

For any x, the probability can be calculated exactly as P = exp(β  x)/(1+
exp(β  x)).
Other models also have closed-form expressions for the probabilities. Multinomial logit (in chapter 3), nested logit (chapter 4), and
ordered logit (chapter 7) are prominent examples. The methods that
I described in my ﬁrst book and that served as the basis for the ﬁrst
wave of interest in discrete choice analysis relied almost exclusively on
models with closed-form expressions for the choice probabilities. In
general, however, the integral for probabilities cannot be expressed in
closed form. More to the point, restrictions must be placed on the
behavioral model h and the distribution of random terms f in order
for the integral to take a closed form. These restrictions can make the
models unrealistic for many situations.

Complete simulation
Rather than solve the integral analytically, it can be approximated
through simulation. Simulation is applicable in one form or another
to practically any speciﬁcation of h and f . Simulation relies on the
fact that integration
over a density is a form of averaging. Consider

the integral t̄ = t(ε)f (ε)dε where t(ε) is a statistic based on ε which
has density f (ε). This integral is the expected value of t over all
possible values of ε. This average can be approximated in an intuitively

CHAPTER 1. INTRODUCTION

6

straightforward way. Take numerous draws of ε from its distribution
f , calculate t(ε) for each draw, and average the results. This simulated
average is an unbiased estimate of the true average. It approaches the
true average as more and more draws are used in the simulation.
This concept of simulating an average is the basis for all simulation
methods, at least all of those that we consider in this book. As given
in eq. (1.1), the probability of a particular outcome is an average of
the indicator I(·) over all possible values of ε. The probability, when
expressed in this form, can be simulated directly as follows: (1) Take a
draw of ε from f (ε). Label this draw ε1 , where the superscript denotes
that it is the ﬁrst draw. (2) Determine whether h(x, ε1 ) = y with this
value of ε. If so, create I 1 = 1, otherwise set I 1 = 0. (3) Repeat steps
1 and 2 many times, for a total of R draws. The indicator for each
draw is labeled I r for r = 1, . . . , R. (4) Calculate the average of the

r
I r ’s. This average is the simulated probability: P̌ (i | x) = R1 R
r=1 I .
It is the proportion of times that the draws of the unobserved factors,
when combined with the observed variables x, result in outcome y.
As we will see in the chapters to follow, this simulator, while easy
to understand, has some unfortunate properties. Choice probabilities
can often be expressed as averages of other statistics, rather than the
average of an indicator function. The simulators based on these other
statistics are calculated analogously, by taking draws from the density,
calculating the statistic and averaging the results. Probit (in chapter
5) is the most prominent example of a model estimated by complete
simulation. Various methods of simulating the probit probabilities
have been developed based on averages of various statistics over various
(related) densities.

Partial simulation/partial closed form
So far we have provided two polar extremes: either solve the integral
analytically or simulate it. In many situations, it is possible to do some
of both.
Suppose the random terms can be decomposed into two parts labeled ε1 and ε2 . Let the joint density of ε1 and ε2 be f (ε) = f (ε1 , ε2 ).
The joint density can be expressed as the product of a marginal and a
conditional density: f (ε1 , ε2 ) = f (ε2 |ε1 ) · f (ε1 ). With this decomposition, the probability in eq. (1.1) can be expressed as:


P (y|x) =

I[h(x, ε) = y]f (ε) dε

1.3. OUTLINE OF BOOK




=
ε1

ε2

7


I[h(x, ε1 , ε2 ) = y]f (ε2 |ε1 ) dε2 f (ε1 ) dε1 .

Now suppose that a closed form exists for the integral in large
brackets. Label this formula g(ε1 ) ≡ ε2 I[h(x, ε1 , ε2 ) = y]f (ε2 |ε1 ) dε2 ,
which is conditional
on the value of ε1 . The probability then becomes

P (y|x) = ε1 g(ε1 ) f (ε1 ) dε1 . If a closed- form solution does not exist
for this integral, then it is approximated through simulation. Note
that it is simply the average of g over the marginal density of ε1 . The
probability is simulated by taking draws from f (ε1 ), calculating g(ε1 )
for each draw, and averaging the results.
This procedure is called “convenient error partitioning” (Train,
1998). The integral over ε2 given ε1 is calculated exactly while the
integral over ε1 is simulated. There are clear advantages to this approach over complete simulation. Analytic integrals are both more
accurate and easier to calculate than simulated integrals. It is useful, therefore, when possible, to decompose the random terms such
that some of them can be integrated analytically, even if the rest must
be simulated. Mixed logit (in chapter 6) is a prominent example of a
model that uses this decomposition eﬀectively. Other examples include
Gourieroux and Monfort’s (1993) binary probit model on panel data
and Bhat’s (1999) analysis of ordered responses.

1.3

Outline of book

Discrete choices analysis consists of two interrelated tasks: speciﬁcation of the behavioral model and estimation of the parameters of that
model. Simulation plays a part in both tasks. Simulation allows the
researcher to approximate the choice probabilities that arise in the
behavioral model. As we have stated, the ability to use simulation
frees the researcher to specify models without the constraint that the
resulting probabilities have a closed form. Simulation also enters the
estimation task. The properties of an estimator, such as maximum
likelihood, can change when simulated probabilities are used instead
of the actual probabilities. Understanding these changes, and mitigating any ill eﬀects, is important for a researcher. In some cases,
such as with Bayesian procedures, the estimator itself is an integral
over a density (as opposed to the choice probability being an integral).
Simulation allows these estimators to be implemented even when the
integral that deﬁnes the estimator does not take a closed form.

8

CHAPTER 1. INTRODUCTION

The book is organized around these two tasks. Part I describes
behavioral models that have been proposed to describe the choice process. The chapters in this section move from the simplest model, logit,
to progressively more general and consequently more complex models.
A chapter is devoted to each of: logit, the family of generalized extreme
value models (whose most prominent member is nested logit), probit,
and mixed logit. This part of the book ends with a chapter entitled
“variations on a theme,” which covers a variety of models that build
upon the concepts in the previous chapters. The point of this chapter
is more than simply to introduce various new models. The chapter illustrates the underlying concept of the book, namely, that researchers
need not rely on the few common speciﬁcations that have been programmed into software but can design models that reﬂect the unique
setting, data and goals of their project, writing their own software and
using simulation as needed.
Part II describes estimation of the behavioral models. Numerical
maximization is covered ﬁrst, since most estimation procedures involve
maximization of some function, such as the log-likelihood function. We
then describe procedures for taking draws from various kinds of densities, which is the basis for simulation. This chapter also describes different kinds of draws, including antithetic variants and quasi-random
sequences, that can provide greater simulation accuracy than independent random draws. We then turn to simulation-assisted estimation,
looking ﬁrst at classical procedures, including maximum simulated likelihood, method of simulated moments, and method of simulated scores.
Finally, we examine Bayesian estimation procedures, which use simulation to approximate moments of the posterior distribution. The
Bayesian estimator can be interpreted from either a Bayesian or classical perspective and has the advantage of avoiding some of the numerical
diﬃculties associated with classical estimators. The power that simulation provides when coupled with Bayesian procedures makes this
chapter a ﬁtting ﬁnale for the book.

1.4

Topics not covered

I feel it is useful to say a few words about what the book does not cover.
There are several topics that could logically be included but are not.
One is the branch of empirical industrial organization that involves
estimation of discrete choice models of consumer demand on market-

1.4. TOPICS NOT COVERED

9

level data. Customer-level demand is speciﬁed by a discrete choice
model, such as logit or mixed logit. This formula for customer-level
demand is aggregated over consumers to obtain market-level demand
functions that relate prices to shares. Market equilibrium prices are
determined as the interaction of these demand functions with supply,
based on marginal costs and the game that the ﬁrms are assumed to
play. Berry (1994) and Berry, Levinsohn and Pakes (1995) developed
methods for estimating the demand parameters when the customerlevel model takes a ﬂexible form such as mixed logit. The procedure
has been implemented in numerous markets for diﬀerentiated goods,
such as ready-to-eat cereals (Nevo, 2001).
I have decided not to cover these procedures, despite their importance, because they are very diﬀerent, in motivation, data, and
methodology, than all the other material in the book. They use marketlevel data rather than customer-level. The observed demand is a set
of continuous variables, representing market shares, rather than discrete variables representing individual customers’ choices. Prices are
endogenous, determined by the interaction of demand and supply. In
contrast, prices faced by an individual customer are not aﬀected by
that customer’s choice; prices are therefore exogenous from market
forces when modeling customer-level demand. Other types of endogeneity may arise with customer-level data, but the endogeneity from
demand/supply interaction, which market level data embody, does not.
The focus of the market-level methods, and the insight provided
by the contributors to these methods, are diﬀerent from those for
customer-level data. Instruments become paramount since price is
endogenous. The dominant questions, and the basis for much of the
discussion in the ﬁeld, concern the selection of instruments: what instruments are appropriate and what identifying assumptions are necessary with any given instruments? These questions do not arise with
customer-level data (unless, of course, some other form of endogeneity
is present). The dominant methodological issue is also diﬀerent. Since
instruments are necessary, the methodological question becomes: how
can market share data, which arise from demand functions in which the
unobserved factors enter nonlinearly, be transformed to allow the use
of instrumental variables estimation, which operates eﬀectively when
the unobserved factors enter linearly? Berry et al.’s contribution was
in determining the appropriate transformation and how to perform it.
This issue does not arise in customer-level data. For interested read-

10

CHAPTER 1. INTRODUCTION

ers, Nevo (2000) provides a useful guide to the procedures, including
programming instructions and an discussion of the appropriate choice
of instruments.
A second area that this book does not cover is discrete/continuous
models. These models arise when a regression equation for a continuous variable is related in any of several ways to a discrete choice. The
most prominent situations are the following.
1. The continuous variable depends on a discrete explanatory variable that is determined endogenously with the dependent variable. For example, consider an analysis of the impact of jobtraining programs on wages. A regression equation is speciﬁed
with wages as the dependent variable and a dummy variable for
whether the person participated in a job-training program. The
coeﬃcient of the participation dummy indicates the impact of
the program on wages. The situation is complicated, however, by
the fact that participation is voluntary: people choose whether to
participate in job-training programs. The decision to participate
is at least partially determined by factors that also aﬀect the person’s wage, such as the innate drive, or “go-for-it” attitude, of the
person. Estimation of the regression by ordinary least squares is
biased in this situation, since the program-participation dummy
is correlated with the errors in the wage equation.
2. A regression equation is estimated on a sample of observations
that are selected on the basis of a discrete choice that is determined endogenously with the dependent variable. For example, a
researcher might want to estimate the impact of weather on peak
energy load (that is, consumption during the highest-demand
hour of the day). Data on energy loads by time of day are only
available only for households that have chosen time-of-use rates.
However, the households’ choice of rate plan can be expected
to be related to their energy consumption, with customers who
have high peak loads tending not to choose time-of-use rates,
since those rates charge high prices in the peak. Estimation of
the regression equation on this “self-selected” sample is biased
unless the endogeneity of the sample is accounted for.
3. The continuous dependent variable is truncated. For example,
consumption of goods by households is necessarily positive. Stated

1.4. TOPICS NOT COVERED

11

statistically, consumption is truncated below at zero, and for
many goods (such as opera tickets) observed consumption is at
this truncation point for a large share of the population. Estimation of the regression without regard to the truncation can cause
bias.

The initial concepts regarding appropriate treatment of continuous/discrete models were developed by Heckman (1978, 1979) and
Dubin and McFadden (1984). These early concepts are covered in my
earlier book (Train, 1986, Ch. 5). Since then, the ﬁeld has expanded
tremendously. An adequate discussion of the issues and procedures
would take a book in itself. Moreover, the ﬁeld has not reached (at
least in my view) the same type of juncture that discrete choice modeling has reached. Many fundamental concepts are still being hotly debated, and potentially valuable new procedures have been introduced
so recently that there has not been an opportunity for researchers to
test them in a variety of settings. The ﬁeld is still expanding more
than it is coalescing.
There are several on-going directions of research in this area. The
early procedures were highly dependent on distributional assumptions
that are hard to verify. Researchers have been developing semi- and
non-parametric procedures that are hopefully more robust. The special 1986 issue of the Journal of Econometrics provides a set of important articles on the topic. Papers by Lewbel and Linton (forthcoming)
and Levy (2001) describe more recent developments. Another important development concerns the representation of behavior in these settings. The relation between the discrete and continuous variables has
been generalized beyond the fairly simple representation that the early
methods assumed. For example, in the context of job training, it is
likely that the impact of the training diﬀers over people and that people choose to participate in the training program on the basis of the
impact it will have on them. Stated in econometric terms: the coefﬁcient of the participation dummy in the wage equation varies over
people and aﬀects the value of the dummy. The dummy is correlated
with its own coeﬃcient, as well as with the unobserved variables that
enter the error of the regression. A recent discussion of approaches to
this issue is provided by Carneiro et al. (2001).

CHAPTER 1. INTRODUCTION

12

1.5

A couple notes

Throughout the book, I refer to the researcher as ”she” and the decisionmaker as ”he.” This usage, as well as being comparatively gender neutral (or at least symmetrically non-inclusive), allows both people to be
referred to in the same paragraph without confusion.
Many colleagues have provided valuable comments and suggestions
on earlier drafts of the book. I a very grateful for this help. I thank:
Greg Allenby, Moshe Ben-Akiva, Chandra Bhat, Denis Bolduc, David
Brownstone, Siddhartha Chib, Jon Eisen-Hecht, Florian Heiss, David
Hensher, Joe Herriges, Rich Johnson, Frank Koppelman, Jordan Louviere, Aviv Nevo, Juan de Dios Ortuzar, Ken Small, Joan Walker, Cliﬀ
Winston, Joachim Winter, and the students in my graduate econometrics course.
I welcome readers to contact me if you feel I have not covered
material that you consider important, or if I have confused rather than
enlightened any of the material that I do cover. Hopefully, another
edition of this book will someday materialize.

Part I

Behavioral Models

13

Chapter 2

Properties of Discrete
Choice Models
2.1

Overview

This chapter describes the features that are common to all discrete
choice models. We start by discussing the choice set, which is the set
of options that are available to the decision-maker. We then deﬁne
choice probabilities and derive them from utility maximizing behavior.
The most prominent types of discrete choice models, namely logit,
GEV, probit, and mixed logit, are introduced and compared within the
context of this general derivation. Utility, as a constructed measure
of well-being, has no natural level or scale. This fact has important
implications for the speciﬁcation and normalization of discrete choice
models, which we explore. We then show how individual-level models
are aggregated to obtain market-level predictions, and how the models
are used for forecasting over time.

2.2

The choice set

Discrete choice models describe decision-makers’ choices among alternatives. The decision-makers can be people, households, ﬁrms, or any
other decision-making unit, and the alternatives might represent competing products, courses of action, or any other options or items over
which choices must be made. To ﬁt within a discrete choice framework,
the set of alternatives, called “the choice set,” needs to exhibit three
15

16

CHAPTER 2. PROPERTIES

characteristics. First, the alternatives must be mutually exclusive from
the decision-maker’s perspective. Choosing one alternative necessarily
implies not choosing any of the other alternatives. The decision-maker
chooses only one alternative from the choice set. Second, the choice
set must be exhaustive, in that all possible alternatives are included.
The decision-maker necessarily chooses one of the alternatives. Third,
the number of alternatives must be ﬁnite. The researcher can count
the alternatives and eventually be ﬁnished counting.
The ﬁrst and second criteria are not restrictive. Appropriate definition of alternatives can nearly always assure that the alternatives
are mutually exclusive and the choice set is exhaustive. For example,
suppose two alternatives labeled A and B are not mutually exclusive
because the decision-maker can choose both of the alternatives. The
alternatives can be redeﬁned to be “A only,” “B only,” and “both A
and B,” which are necessarily mutually exclusive. Similarly, a set of
alternatives might not be exhaustive because the decision-maker has
the option of not choosing any of them. In this case, an extra alternative can be deﬁned as “none of the other alternatives.” The expanded
choice set, consisting of the original alternatives plus this new one, is
clearly exhaustive.
Often the researcher can satisfy these two conditions in several different ways. The appropriate speciﬁcation of the choice set in these
situations is governed largely by the goals of the research and the data
that are available to the researcher. Consider households’ choice among
heating fuels, a topic which has been studied extensively in eﬀorts to
forecast energy use and to develop eﬀective fuel-switching and energy
conservation programs. The available fuels are usually natural gas,
electricity, oil and wood. These four alternatives, as listed, violate both
mutual exclusivity and exhaustiveness. The alternatives are not mutually exclusive because a household can (and many do) have two types
of heating, e.g., a natural gas central heater and electric room heaters,
or a wood stove along with electric baseboard heating. And the set
is not exhaustive because the household can have no heating (which,
unfortunately, is not as rare as one might hope.) The researcher can
handle each of these issues in several ways. To obtain mutually exclusive alternatives, one approach is to list every possible combination
of heating fuels as an alternative. The alternatives are then deﬁned
as: “electricity alone,” “electricity and natural gas, but no other fuels,”
and so on. Another approach is to deﬁne the choice as the choice among

2.2. THE CHOICE SET

17

fuels for the “primary” heating source. Under this procedure, the researcher develops a rule for determining which heating fuel is primary
when a household uses multiple heating fuels. By deﬁnition, only one
fuel (electricity, natural gas, oil, or wood) is primary. The advantage
of listing every possible combination of fuels is that it avoids the need
to deﬁne a “primary” fuel, which is a diﬃcult and somewhat arbitrary
distinction. Also, with all combinations considered, the researcher has
the ability to examine the factors that determine households’ use of
multiple fuels. However, to implement this approach, the researcher
needs data that distinguish the alternatives, for example, the cost of
heating a house with natural gas and electricity versus the cost with
natural gas alone. If the researcher restricts the analysis to choice of
primary fuel, then the data requirements are less severe. Only the
costs associated with each fuel are needed. Also, a model with four
alternatives is inherently easier to estimate and forecast with than a
model with the large number of alternatives that arises when every
possible combination of fuels is considered. The researcher will need
to take these tradeoﬀs into consideration when specifying the choice
set.
The same type of issue arises with regard to exhaustiveness. In
our case of heating fuel choice, the researcher can either include “no
heating” as an alternative or can redeﬁne the choice situation as being
the choice of heating fuel conditional on having heating. The ﬁrst
approach allows the researcher to examine the factors that relate to
whether a household has heating. However, this ability is only realized
if the researcher has data that meaningfully relate to whether or not
a household has heating. Under the second approach, the researcher
excludes from the analysis households without heating, and, by doing
so, is relieved of the need for data that relate to these households.
As we have just described, the conditions of mutual exclusivity
and exhaustiveness can usually be satisﬁed, and the researcher often
has several approaches for doing so. In contrast, the third condition,
namely, that the number of alternatives is ﬁnite, is actually restrictive.
This condition is the deﬁning characteristic of discrete choice models
and distinguishes their realm of application from that for regression
models. With regression models, the dependent variable is continuous,
which means that there is an inﬁnite number of possible outcomes.
The outcome might be chosen by a decision-maker, such as the decision of how much money to hold in savings accounts. However, the

18

CHAPTER 2. PROPERTIES

alternatives available to the decision-maker, which are every possible
monetary value above zero, is not ﬁnite (at least not if all fractions
are considered, which is an issue we return to below.) When there is
an inﬁnite number of alternatives, discrete choice models cannot be
applied.

Often regression models and discrete choice models are distinguished
by saying that regressions examine choices of “how much” and discrete
choice models examine choice of “which.” This distinction, while perhaps illustrative, is not actually accurate. Discrete choice models can
and have been used to examine choices of “how much.” A prominent
example is households’ choice of how many cars to own. The alternatives are 0, 1, 2, and so on, up to the highest number that the
researcher deﬁnes as feasible (or observed.) This choice set contains a
ﬁnite number of mutually exclusive and exhaustive alternatives, such
that it is appropriate for analysis via discrete choice models. The researcher can also deﬁne the choice set more succinctly as 0, 1, and
2 or more vehicles, if the goals of the research can be met with this
speciﬁcation.

When considered in this way, most choices involving “how many”
can be represented in a discrete choice framework. In the case of
savings accounts, every one-dollar increment (or even every one-cent
increment) can be considered an alternative, and as long as some ﬁnite maximum exists, then the choice set ﬁts the criteria for discrete
choice. Whether to use regression or discrete choice models in these
situations is a speciﬁcation issue that the researcher must consider.
Usually a regression model is more natural and is certainly easier. A
discrete choice model would be used in these situations only if there
are compelling reasons for doing so. As an example, Train, McFadden
and Ben-Akiva (1987) analyzed the number and duration of phone
calls that households make, using a discrete choice model instead of a
regression model because the discrete choice model allowed greater ﬂexibility in handling the non-linear price schedules that households face.
In general, the researcher needs to consider the goals of the research
and the capabilities of alternative methods when deciding whether to
apply a discrete choice model.

2.3. DERIVATION OF CHOICE PROBABILITIES

2.3

19

Derivation of choice probabilities

Discrete choice models are usually derived under an assumption of
utility-maximizing behavior by the decision-maker. Thurstone (1927)
originally developed the concepts in terms of psychological stimuli,
leading to a binary probit model of whether respondents can diﬀerentiate the level of stimulus. Marschak (1960) interpreted the stimuli
as utility and provided a derivation from utility maximization. Following Marschak, models that can be derived in this way are called
random utility models (RUMs). It is important to note, however, that
models derived from utility maximization can also be used to represent
decision-making that does not entail utility maximization. The derivation assures that the model is consistent with utility maximization; it
does not preclude the model from being consistent with other forms
of behavior. The models can also be seen as simply describing the
relation of explanatory variables to the outcome of a choice, without
reference to exactly how the choice is made.
Random utility models are derived as follows. A decision-maker,
labeled n, faces a choice among J alternatives. The decision-maker
would obtain a certain level of utility (or proﬁt) from each alternative.
The utility that decision-maker n obtains from alternative j is Unj , j =
1, . . . , J. This utility is known to the decision-maker but not, as we see
below, by the researcher. The decision-maker chooses the alternative
that provides the greatest utility. The behavioral model is therefore:
choose alternative i if and only if Uni > Unj ∀ j = i.
Consider now the researcher. The researcher does not observe the
decision-maker’s utility. The researcher observes some attributes of
the alternatives as faced by the decision-maker, labeled xnj ∀ j, and
some attributes of the decision-maker, labeled sn , and can specify a
function that relates these observed factors to the decision-maker’s
utility. The function is denoted Vnj = V (xnj , sn ) ∀ j and is often
called ”representative utility.” Usually, V depends on parameters that
are unknown to the researcher and therefore estimated statistically;
however, this dependence is suppressed for the moment.
Since there are aspects of utility that the researcher does not or
cannot observe, Vnj = Unj . Utility is decomposed as Unj = Vnj + εnj ,
where εnj captures the factors that aﬀect utility but are not included in
Vnj . This decomposition is fully general, since εnj is deﬁned as simply
the diﬀerence between true utility Unj and the part of utility that the

CHAPTER 2. PROPERTIES

20

researcher captures in Vnj . Given its deﬁnition, the characteristics of
εnj , such as its distribution, depend critically on the researcher’s speciﬁcation of Vnj . In particular, εnj is not deﬁned for a choice situation
per se. Rather, it is deﬁned relative to a researcher’s representation of
that choice situation. This distinction becomes relevant when evaluating the appropriateness of various speciﬁc discrete choice models.
The researcher does not know εnj ∀ j and therefore treats these
terms as random. The joint density of the random vector εn = εn1 , . . . , εnJ 
is denoted f (εn ). With this density, the researcher can make probabilistic statements about the decision-maker’s choice. The probability
that decision-maker n chooses alternative i is
Pni = P rob(Uni > Unj ∀ j = i)
= P rob(Vni + εni > Vnj + εnj ∀ j = i)
= P rob(εnj − εni < Vni − Vnj ∀ j = i)

(2.1)

This probability is a cumulative distribution, namely, the probability that each random term εnj − εni is below the observed quantity
Vni − Vnj . Using the density f (εn ), this cumulative probability can be
rewritten as:
Pni = P rob(εnj − εni < Vni − Vnj ∀ j = i)


=
ε

I(εnj − εni < Vni − Vnj ∀ j = i)f (εn )dεn ,

(2.2)

where I(·) is the indicator function, equaling 1 when the term in parentheses is true and 0 otherwise. This is a multidimensional integral over
the density of the unobserved portion of utility, f (εn ). Diﬀerent discrete choice models are obtained from diﬀerent speciﬁcations of this
density, that is, from diﬀerent assumptions about the distribution of
the unobserved portion of utility. The integral takes a closed-form only
for certain speciﬁcations of f (·). Logit and nested logit have closedform expressions for this integral. They are derived under the assumption that the unobserved portion of utility is distributed iid extreme
value and a type of generalized extreme value, respectively. Probit is
derived under the assumption that f (·) is a multivariate normal, and
mixed logit is based on the assumption that the unobserved portion
of utility consists of a part that follows any distribution speciﬁed by
the researcher plus a part that is iid extreme value. With probit and
mixed logit, the resulting integral does not have a closed form and

2.3. DERIVATION OF CHOICE PROBABILITIES

21

is evaluated numerically through simulation. Each of these models is
discussed in detail in subsequent chapters.
The meaning of choice probabilities is more subtle, and more revealing, than it might at ﬁrst appear. An example serves as illustration.
Consider a person who can take either a car or bus to work. The
researcher observes the time and cost that the person would incur under each mode. However, the researcher realizes that there are factors
other than time and cost that aﬀect the person’s utility and hence his
choice. The researcher speciﬁes
Vc = αTc + βMc
Vb = αTb + βMb
where Tc and Mc are the time and cost (i.e., money) that the person
incurs traveling to work by car, Tb and Mb are deﬁned analogously
for bus, and the subscript n denoting the person is omitted for convenience. The coeﬃcients α and β are either known or estimated by the
researcher.
Suppose that, given α and β and the researcher’s measures of the
time and cost by car and bus, it turns out that Vc = 4 and Vb = 3. This
means that, on observed factors, car is better for this person than bus
by 1 unit. (We discuss below the normalization of utility that sets the
dimension to these units.) It does not mean, however, that the person
necessarily chooses car, since there are other factors not observed by
the researcher that aﬀect the person. The probability that the person
chooses bus instead of car is the probability that the unobserved factors for bus are suﬃciently better than those for car to overcome the
advantage that car has on observed factors. Speciﬁcally, the person
will choose bus if the unobserved portion of utility is higher than that
for car by at least 1 unit, thus overcoming the 1 unit advantage that
car has on observed factors. The probability of this person choosing
bus is therefore the probability that εb − εc > 1. Conversely, the person will choose car if the unobserved utility for bus is not better than
that for car by at least 1 unit, that is, if εb − εc < 1. Since 1 is the
diﬀerence between Vc and Vb in our example, the probabilities can be
stated more explicitly as:
Pc

=

P rob(εb − εc < Vc − Vb )

and
Pb

=

P rob(εb − εc > Vc − Vb )

CHAPTER 2. PROPERTIES

22
=

P rob(εc − εb < Vb − Vc ).

These equations are the same as equation (2.1) above, re-expressed for
our car-bus example.
The question arises in the derivation of the choice probabilities:
what is meant by the distribution of εn ? The interpretation that the
researcher places on this density aﬀects the researcher’s interpretation of the choice probabilities. The most prominent way to think
about this distribution is as follows. Consider a population of people who face the same observed utility Vnj ∀ j as person n. Among
these people, the values of the unobserved factors diﬀer. The density
f (εn ) is the distribution of the unobserved portion of utility within
the population of people who face the same observed portion of utility.
Under this interpretation, the probability Pni is the share of people
who choose alternative i within the population of people who face the
same observed utility for each alternative as person n. The distribution can also be considered in subjective terms, as representing the
researcher’s subjective probability that the person’s unobserved utility
will take given values. In this case, the Pni is the probability that
the researcher ascribes to the person’s choosing alternative i given the
researcher’s ideas about the unobserved portions of the person’s utility. As a third possibility, the distribution can represent the eﬀect of
factors that are quixotic to the decision-maker himself (representing,
e.g., aspects of bounded rationality), such that Pni is the probability
that these quixotic factors induce the person to choose alternative i
given the observed, non-quixotic factors.

2.4

Speciﬁc models

Logit, GEV, probit, and mixed logit are discussed at length in the subsequent chapters. However, a quick preview of these models is useful
at this point, to show how they relate to the general derivation of all
choice models and how they diﬀer within this derivation. As stated
above, diﬀerent choice models are derived under diﬀerent speciﬁcations
of the density of unobserved factors, f (εn ). The issues therefore are:
what distribution is assumed for each model, and what is the motivation for these diﬀerent assumptions.
Logit (discussed in Chapter 3) is by far the most widely used discrete choice model. It is derived under the assumption that εni is

2.4. SPECIFIC MODELS

23

distributed iid extreme value for all i. The critical part of the assumption is that the unobserved factors are uncorrelated over alternatives,
as well as having the same variance for all alternatives. This assumption, while restrictive, provides a very convenient form for the choice
probability. The popularity of the logit model is due to this convenience. However, the assumption of independence can be inappropriate in some situations. Unobserved factors related to one alternative
might be similar to those related to another alternative. For example, a person who dislikes travel by bus because of the presence of
other riders might have a similar reaction to rail travel; if so, then the
unobserved factors aﬀecting bus and rail are corrrelated rather than independent. The assumption of independence also enters When a logit
model is applied to sequences of choices over time. The logit model
assumes that each choice is independent of the others. In many cases,
one would expect that unobserved factors that aﬀect the choice in one
period would persist, at least somewhat, into the next period, inducing
dependence among the choices over time.
The development of other models has arisen largely to avoid the
independence assumption within a logit. Generalized extreme value
models (GEV, discussed in Chapter 4) are based, as the name implies,
on a generalization of the extreme value distribution. The generalization can take many forms, but the common element is that it allows
correlation in unobserved factors over alternatives and collapses to the
logit model when this correlation is zero. Depending on the type of
GEV model, the correlations can be more or less ﬂexible. For example,
a comparatively simple GEV model places the alternatives into several
groups called nests, with unobserved factors having the same correlation for all alternatives within a nest and no correlation for alternatives
in diﬀerent nests. More complex forms allow essentially any pattern
of correlation. GEV models usually have closed-forms for the choice
probabilities, such that simulation is not required for their estimation.
Probits (Chapter 5) are based on the assumption that the unobserved factors are distributed jointly normal: εn = εn1 , ldots, εnJ  ∼
N (0, Ω). With full covariance matrix Ω, any pattern of correlation
and heteroskedasticity can be accommodated. When applied to sequences of choices over time, the unobserved factors are assumed to be
jointly normal over time as well as over alternatives, with any temporal correlation pattern. The ﬂexibility of the probit model in handling
correlations over alternatives and time is its main advantage. Its only

24

CHAPTER 2. PROPERTIES

functional limitation is arises from its reliance on the normal distribution. In some situations, unobserved factors might not be normally
distributed. For example, customer’s willingness to pay for a desirable attribute of a product is necessary positive. Assuming that this
unobserved factor is normally distributed contradicts the fact that it
is positive, since the normal distribution has density on both sides of
zero.
Mixed logit (chapter 6) allows the unobserved factors to follow any
distribution. The deﬁning characteristic of a mixed logit is that the
unobserved factors can be decomposed into a part that contains all the
correlation and heteroskedasticity, and another part that is iid extreme
value. The ﬁrst part can follow any distribution, including non-normal
distributions. We will show that mixed logit can approximate any
discrete choice model and, as such, is fully general.
Other discrete choice models (Chapter 7) have been speciﬁed by
researchers for speciﬁc purposes. Often these models are obtained by
combining concepts from other models. For example, a mixed probit is
obtained by decomposing the unobserved factors into two parts, as in
mixed logit, but giving the second part a normal distribution instead
of extreme value. This model has the generality of mixed logit and
yet for some situations can be easier to estimate. By understanding
the derivation and motivation for all the models, each researcher can
specify a model that is tailor-made for the situation and goals of her
research.

2.5

Identiﬁcation of choice models

Several aspects of the behavioral decision process aﬀect the speciﬁcation and estimation of any discrete choice model. The issues can be
summarized easily in two statements: “Only diﬀerences in utility matter” and “The scale of utility is arbitrary.” The implications of these
statements are far-reaching, subtle and, in many cases, quite complex.
We discuss them below.

2.5.1

Only diﬀerences in utility matter

The absolute level of utility is irrelevant to both the decision-maker’s
behavior and the researcher’s model. If a constant is added to the
utility of all alternatives, the alternative with the highest utility doesn’t

2.5. IDENTIFICATION OF CHOICE MODELS

25

change. The decision-maker chooses the same alternative with Unj ∀ j
as with Unj + k ∀ j for any constant k. A colloquial way to express
this fact is, “A rising tide raises all boats.”
The level of utility doesn’t matter from the researcher’s perspective
either. The choice probability is Pni = P rob(Uni > Unj ∀ j = i) =
P rob(Uni − Unj > 0 ∀ j = i), which depends only on the diﬀerence
in utility, not its absolute level. When utility is decomposed into the
observed and unobserved parts, equation (2.1) expresses the choice
probability as Pni = P rob(εnj − εni < Vni − Vnj ∀ j = i), which also
depends only on diﬀerences.
The fact that only diﬀerences in utility matter has several implications for the identiﬁcation and speciﬁcation of discrete choice models.
In general it means that the only parameters that can be estimated
(that is, are identiﬁed) are those that capture diﬀerences across alternatives. This general statement takes several forms.

Alternative-speciﬁc constants
It is often reasonable to specify the observed part of utility to be linear
in parameters with a constant: Vnj = xnj β + kj , ∀ j, where xnj is a
vector of variables that relate to alternative j as faced by decisionmaker n, β are coeﬃcients of these variables, and kj is a constant that
is speciﬁc to alternative j. The alternative-speciﬁc constant for an
alternative captures the average impact on utility of all factors that
are not included in the model. As such, they serve a similar function
as the constant in a regression model, which also captures the average
impact of all unincluded factors.
When alternative-speciﬁc constants are included, the unobserved
portion of utility, εnj , has zero mean by construction. If εnj has a
nonzero mean when the constants are not included, then adding the
constants makes the remaining error have zero mean: that is, if Unj =
xnj β + ε∗nj with E(εnj )∗ = kj = 0, then Unj = xnj β + kj + εnj with
E(εnj ) = 0. It is reasonable, therefore, to include a constant in Vnj
for each alternative. However, since only diﬀerences in utility matter,
only diﬀerences in the alternative-speciﬁc constants are relevant, not
their absolute levels. To reﬂect this fact, the researcher must set the
overall level of these constants.
The concept is readily apparent in the car-bus example. A speciﬁ-

CHAPTER 2. PROPERTIES

26
cation of utility that takes the form:

Uc = αTc + βMc + kc0 + εc
Ub = αTb + βMb + kb0 + εb
with kb0 − kc0 = d, is equivalent to a model with
Uc = αTc + βMc + kc1 + εc
Ub = αTb + βMb + kb1 + εb
where the diﬀerence in the new constants is the same as the diﬀerence
in the old constants, namely kb1 − kc1 = d = kb0 − kc0 . Any model with
the same diﬀerence in constants is equivalent. In terms of estimation,
it is impossible to estimate both constants since an inﬁnite number of
values of the two constants (any values that have the same diﬀerence)
result in the same choice probabilities.
To account for this fact, the researcher must normalize the absolute
levels of the constants. The standard procedure is to normalize one
of the constants to zero. For example, the researcher might normalize
the constant for the car alternative to zero:
Uc = αTc + βMc + εc
Ub = αTb + βMb + kb + εb
Under this normalization, the value of kb is d, which is the diﬀerence in
the original (unnormalized) constants. The bus constant is interpreted
as the average impact of unincluded factors on the utility of bus relative
to car.
With J alternatives, at most J − 1 alternative-speciﬁc constants
can enter the model, with one of the constants normalized to zero. It
is irrelevant which constant is normalized to zero: the other constants
are interpreted as being relative to whichever one is set to zero. The
researcher could normalize to some value other than zero, of course;
however, there would be no point in doing so, since normalizing to
zero is easier (the constant is simply left out of the model) and has the
same eﬀect.
Socio-demographic variables
The same issue aﬀects the way that socio-demographic variables enter
a model. Attributes of the alternatives, such as the time and cost of

2.5. IDENTIFICATION OF CHOICE MODELS

27

travel on diﬀerent modes, generally vary over alternatives. However,
attributes of the decision-maker do not vary over alternatives. They
can only enter the model if they are speciﬁed in ways that create
diﬀerences in utility over alternatives.
Consider for example the impact of a person’s income on the decision of whether to take bus or car to work. It is reasonable to suppose
that a person’s utility is higher with higher income, whether the person
takes bus or car. Utility is speciﬁed as:
Uc = αTc + βMc + θc0 Y + εc
Ub = αTb + βMb + θb0 Y + kb + εb
where Y is income and θc0 and θb0 capture the eﬀect of changes in
income on the utility of taking car and bus, respectively. We expect
that θc0 > 0 and θb0 > 0 since greater income makes people happier no
matter what mode they take. However, θc0 = θb0 since income probably
has a diﬀerent eﬀect on the person depending on their mode of travel.
Since only diﬀerences in utility matter, the absolute levels of θc0 and
θb0 cannot be estimated, only their diﬀerence. To set the level, one of
these parameters is normalized to zero. The model becomes:
Uc = αTc + βMc + εc
Ub = αTb + βMb + θb Y + kb + εb
where θb = θb0 −θc0 and is interpreted as the diﬀerential eﬀect of income
on the utility of bus compared to car. The value of θb can be either
positive or negative.
Socio-demographic variables can enter utility in other ways. For
example, cost is often divided by income:
Uc = αTc + βMc /Y + εc
Ub = αTb + βMb /Y + θb Y + kb + εb
The coeﬃcient of cost in this speciﬁcation is β/Y . Since this coeﬃcient
decreases in Y , the model reﬂects the concept that cost becomes less
important in a person’s decision-making, relative to other issues, when
income rises.
When socio-demographic variables are interacted with attributes
of the alternatives, there is no need to normalize the coeﬃcients. The
socio-demographic variables aﬀect the diﬀerences in utility through

CHAPTER 2. PROPERTIES

28

their interaction with the attributes of the alternatives. The diﬀerence
Uc − Ub = . . . β(Mc − Mb )/Y . . . varies with income since costs diﬀer
over alternatives.
Number of independent error terms
As given by equation (2.2), the choice probabilities take the form


Pni =

ε

I(εnj − εni > Vnj − Vni ∀ j = i)f (εn )dεn .

This probability is a J dimensional integral over the density of the J
error terms in εn = εn1 , . . . , εnJ . The dimension can be reduced,
however, through recognizing that only diﬀerences in utility matter.
With J errors (one for each alternative), there are J − 1 error diﬀerences. The choice probability can be expressed as a J − 1 dimensional
integral over the density of these error diﬀerences:
Pni = P rob(Uni > Unj ∀ j = i)
= P rob(εnj − εni < Vni − Vnj ∀ j = i)
= P rob(ε̃nji < Vni − Vnj ∀ j = i)


=

I(ε̃nji < Vni − Vnj ∀ j = i)g(ε̃ni )dε̃ni

where ε̃nji = εnj − εni is the diﬀerence in errors for alternatives i
and j; ε̃ni = ε̃n1i , . . . , εnJi  is the J − 1 dimensional vector of error
diﬀerences, with the . . . over all alternatives except i; and g(·) is the
density of these error diﬀerences. Expressed in this way, the choice
probability is a J − 1 dimensional integral.
The density of the error diﬀerences g(·), and the density of the
original errors, f (·), are related in a particular way. Suppose a model
is speciﬁed with an error for each alternative: εn = εn1 , . . . , εnJ 
with density f (εn ). This model is equivalent to a model with J − 1
errors deﬁned as ε̃njk = εnj − εnk for any k and density g(ε̃nk ) derived
from f (εn ). For any f (εn ), the corresponding g(ε̃nk ) can be derived.
However, since εn has more elements than ε̃nk , there is an inﬁnite
number of densities for the J error terms that give the same density for
the J −1 error diﬀerences. Stated equivalently, any g(ε̃nk ) is consistent
with an inﬁnite number of diﬀerent f (εn )’s. Since choice probabilities
can always be expressed as depending only on g(ε̃nk ), one dimension

2.5. IDENTIFICATION OF CHOICE MODELS

29

of the density of f (εn ) is not identiﬁed and must be normalized by the
researcher.
The normalization of f (εn ) can be handled in various ways. For
some models, such as logit, the distribution of the error terms is sufﬁciently restrictive that the normalization occurs automatically with
the assumptions on the distribution. For other models, such as probit,
identiﬁcation is often obtained by specifying the model only in terms
of error diﬀerences, that is, by parameterizing g(·) without reference to
f (·). In all but the simplest models, the researcher needs to consider
the fact that only the density of error diﬀerences aﬀects the probabilities and therefore is identiﬁed. In discussing the various models in
subsequent chapters, we will return to this issue and how to handle it.

2.5.2

The overall scale of utility is irrelevant

Just as adding a constant to the utility of all alternatives does not
change the decision-maker’s choice, neither does multiplying each alternative’s utility by a constant. The alternative with the highest utility is
0 = V +ε
the same no matter how utility is scaled. The model Unj
nj
nj ∀j
1
is equivalent to Unj = λVnj + λεnj ∀j for any λ > 0. To account for
this fact, the researcher must normalize the scale of utility.
The standard way to normalize the scale of utility is to normalize
the variance of the error terms. The scale of utility and the variance of
the error terms are deﬁnitionally linked. When utility is multiplied by
λ, the variance of each εnj changes by λ2 : V ar(λεnj ) = λ2 V ar(εnj ).
Therefore normalizing the variance of the error terms is equivalent to
normalizing the scale of utility.
Normalization with iid errors
If the error terms are assumed to be independently, identically distributed, then the normalization for scale is straightforward. The researcher normalizes the error variance to some number, which is usually
chosen for convenience. Since all the errors have the same variance by
assumption, normalizing the variance of any of them sets the variance
for them all.
When the observed portion of utility is linear in parameters, the
normalization provides a way of interpreting coeﬃcients. Consider
0 = x β + ε0 where the variance of the error terms is
the model Unj
nj
nj
0
V ar(εnj ) = σ 2 . Suppose the research normalizes the scale by setting

30

CHAPTER 2. PROPERTIES

the error variance to 1. The original model becomes the following
1 = x (β/σ) + ε1 with V ar(ε1 ) = 1.
equivalent speciﬁcation: Unj
nj
nj
nj
The original coeﬃcients β are divided by the standard deviation of
the unobserved portion of utility. The new coeﬃcients β/σ reﬂect,
therefore, the impact of the observed variables relative to the standard
deviation of the unobserved factors.
The same concepts apply for whatever number the researcher chooses
for normalization. As we will see in the next chapter, the error variances in a standard logit model are traditionally normalized to π 2 /6,
which is √
about 1.6. In this case, the above model becomes Unj =

xnj (β/σ) 1.6 + εnj with V ar(εnj ) = 1.6. The coeﬃcients still reﬂect
the variance of the unobserved portion of utility.
√ The only diﬀerence
is that the coeﬃcients are larger by a factor of 1.6.
While it is immaterial which number is used by the researcher for
normalization, interpretation of model results must take the normalization into consideration. Suppose, for example, that a logit and an
independent probit model were both estimated on the same data. As
stated above, the error variance is normalized to 1.6 for logit. Suppose the researcher normalized the probit to have error variances of
1, which is traditional with independent probits. This diﬀerence in
normalization must be kept in mind when comparing estimates from
the √two models. In particular, the coeﬃcients in the logit model will
be 1.6 times larger than those for the probit model, simply due to
the diﬀerence in normalization. If the researcher does not take this
scale diﬀerence into account when comparing the models, she might
inadvertently think that the logit model implies that people care more
about the attributes (since the coeﬃcients are larger) than implied by
the probit model. For example, in a mode choice model, supposed
the estimated cost coeﬃcient is −0.55 from a logit model and −0.45
from an independent probit model. It is incorrect to say that the logit
model implies more sensitivity to costs than the probit model. The
coeﬃcients in one of the models must be adjusted to account√for the
diﬀerence in scale. The logit coeﬃcients can be divided by 1.6, so
that the error variance is 1, just like the probit model. With this adjustment, the comparable coeﬃcients are −0.43 for the logit model and
−0.45 for the probit model. The logit model implies less price sensitivity than the probit. Instead, the probit coeﬃcients could be converted
√
to the scale of the logit coeﬃcients by multiplying them by 1.6, in
which case the comparable coeﬃcients would be −0.55 for logit and

2.5. IDENTIFICATION OF CHOICE MODELS

31

−0.57 for probit.
A similar issue of interpretation arises when the same model is
estimated on diﬀerent data sets. The relative scale of the estimates
from the two data sets reﬂects the relative variance of unobserved
factors in the data sets. Suppose mode choice models were estimated
in Chicago and Boston. For Chicago, the estimated cost coeﬃcient is
−0.55 and the estimated coeﬃcient of time is −1.78. For Boston, the
estimates are −0.81 and −2.69. The ratio of the cost coeﬃcient to the
time coeﬃcient is very similar in the two cities: 0.309 in the Chicago
and 0.301 in Boston. However, the scale of the coeﬃcients is about ﬁfty
percent higher for Boston than Chicago. This scale diﬀerence means
that the unobserved portion of utility has less variance in Boston than
Chicago: since the coeﬃcients are divided by the standard deviation
of the unobserved portion of utility, lower coeﬃcients mean higher
standard deviation and hence variance. The models are revealing that
factors other than time and cost have less eﬀect on people in Boston
than in Chicago. Stated more intuitively, time and cost have more
importance, relative to unobserved factors, in Boston than in Chicago
– which is consistent with the larger scale of the coeﬃcients for Boston.
Normalization with heteroskedastic errors
In some situations, the variance of the error terms can be diﬀerent
for diﬀerent segments of the population. The researcher cannot set
the overall level of utility by normalizing the variance of the errors
for all segments, since the variance is diﬀerent in diﬀerent segments.
Instead, the researcher sets the overall scale of utility by normalizing
the variance for one segment, and then estimates the variance (and
hence scale) for each segment relative to this one segment.
For example, consider the situation described in the previous section, where the unobserved factors have greater variance in Chicago
than in Boston. If separate models are estimated for Chicago and
Boston, then the variance of the error term is normalized separately
for each model. The scale of the parameters in each model reﬂect the
variance of unincluded factors in that area. Suppose, however, that the
researcher wants to estimate a model on data for both Chicago and
Boston. She cannot normalize the variance of the unobserved factors
for all travelers to the same number, since the variance is diﬀerent for
travelers in Boston than those in Chicago. Instead, the researcher sets

CHAPTER 2. PROPERTIES

32

the overall scale of utility by normalizing the variance in one area (say
Boston) and then estimates the variance in the other area relative that
in the ﬁrst area (the variance in Chicago relative to that in Boston).
The model in its original form is
Unj

= αTnj + βMnj + εB
nj ∀n in Boston

Unj

= αTnj + βMnj + εC
nj ∀n in Chicago,

C
where the variance of εB
nj is not the same as the variance of εnj . Label
)/V ar(εB
the ratio of variances as k = V ar(εC
nj ). We can divide the
√ nj
utility for travelers in Chicago by k; this division doesn’t aﬀect their
choices, of course, since the scale of utility doesn’t matter. However,
doing so allows us to re-write the model as

Unj = αTnj + βMnj + εnj ∀n in Boston
√
√
Unj = (α/ k)Tnj + (β/ k)Mnj + εnj ∀n in Chicago,
where now
is the same for all n in both cities (since
√the variance of εnj
C ) = [V ar(εB )/V ar(εC )]V ar(εC ) = V ar(εB ).
V ar(εC
/
k)
=
(1/k)V
ar(ε
nj
nj
nj
nj
nj
nj
The scale of utility is set by normalizing the variance of εnj . The parameter k, which is often called the scale parameter, is estimated along
with β and α. The estimated value of k tells the researcher the variance of unobserved factors in Chicago relative to that in Boston. For
example, k̂ = 1.2 implies that the variance of unobserved factors is
twenty percent greater in Chicago than Boston.
The variance of the error term can diﬀer over geographic regions,
data sets, time, or other factors. In all cases, the researcher sets the
overall scale of utility by normalizing one of the variances and then
estimating the other variances relative to the normalized one. Swait
and Louviere (1993) discuss the role of the scale parameter in discrete
choice models, describing the variety of reasons that variances can differ over observations. As well as the traditional concept of variance in
unobserved factors, psychological factors can come into play, depending on the choice situation and the interpretation of the researcher.
For example, Bradley and Daly (1994) allow the scale parameter to
vary over stated preference experiments in order to account for respondents’ fatigue in answering the survey questions. Ben-Akiva and
Morikawa (1990) allow the scale parameter to diﬀer for respondents’
stated intentions versus their actual market choices.

2.5. IDENTIFICATION OF CHOICE MODELS

33

Normalization with correlated errors
In the discussion so far we have assumed that εnj is independent over
alternatives. When the errors are correlated over alternatives, normalizing for scale is more complex. We have talked in terms of setting the
scale of utility. However, since only diﬀerences in utility matter, it is
more appropriate to talk in terms of setting the scale of utility diﬀerences. However, when errors are correlated, normalizing the variance
of the error for one alternative is not suﬃcient to set the scale of utility
diﬀerences.
The issue is most readily described in terms of a 4-alternative example. The utility for the four alternatives is Unj = Vnj +εnj , j = 1, . . . , 4.
The error vector εn = εn1 , . . . , εn4  has zero mean and covariance matrix:


σ11 σ12 σ13 σ14
 ·
σ22 σ23 σ24 


Ω=
(2.3)

 ·
· σ33 σ34 
·
·
· σ44
where the dots refer to the corresponding elements on the upper part
of the symmetric matrix.
Since only diﬀerences in utility matter, this model is equivalent to
one in which all utilities are diﬀerenced from, say, the ﬁrst alternative.
The equivalent model is Ũnj1 = Ṽnj1 − ε̃nj1 for j = 2, 3, 4, where
Ũnj1 = Unj − Un1 , Ṽnj1 = Vnj − Vn1 , and the vector of error diﬀerences
is ε̃n1 = (εn2 − εn1 ), (εn3 − εn1 ), (εn4 − εn1 ). The variance of each
error diﬀerence depends on the variances and covariances of the original
errors. For example, the variance of the diﬀerence between the ﬁrst and
second errors is: V ar(ε̃n21 ) = V ar(εn2 − εn1 ) = V ar(εn1 ) + V ar(εn2 ) −
2Cov(εn1 , εn2 ) = σ11 + σ22 − 2σ12 . We can similarly calculate the
covariance between ε̃n21 , which is the diﬀerence between the ﬁrst and
second errors, and ε̃n31 , which is the diﬀerence between the ﬁrst and
third errors: Cov(ε̃n21 , ε̃n31 ) = E(εn2 − εn1 )(εn3 − εn1 ) = E(εn2 εn −
εn2 εn1 −εn3 εn1 +εn1 εn1 ) = σ23 −σ21 −σ31 +σ11 . The covariance matrix
for the vector of error diﬀerences becomes:




σ11 + σ22 − 2σ12 σ11 + σ23 − σ12 − σ13 σ11 + σ24 − σ12 − σ14


·
σ11 + σ33 − 2σ13
σ11 + σ34 − σ13 − σ14  .
Ω̃1 = 
·
·
σ11 + σ44 − 2σ14
Setting the variance of one of the original errors is not suﬃcient to
set the variance of the error diﬀerences. For example, if the variance for

CHAPTER 2. PROPERTIES

34

the ﬁrst alternative were set to some number σ11 = k, the variance of
the diﬀerence between the errors for the ﬁrst two alternatives becomes
k + σ22 − σ12 . An inﬁnite number of values for σ22 − σ12 provide
equivalent models.
A common way to set the scale of utility when errors are not iid is
to normalize the variance of one of the error diﬀerences to some number. Setting the variance of an error diﬀerence sets the scale of utility
diﬀerences and hence of utility. Suppose we normalize the variance of
ε̃n21 to 1. The covariance matrix for the error diﬀerences, expressed in
terms of the covariances of the original errors, becomes:




1 (σ11 + σ23 − σ12 − σ13 )/m (σ11 + σ24 − σ12 − σ14 )/m


(σ11 + σ33 − 2σ13 )/m
(σ11 + σ34 − σ13 − σ14 )/m  ,
 ·
·
·
(σ11 + σ44 − 2σ14 )/m
(2.4)
√
where m = σ11 + σ22 − 2σ12 . Utility is divided by σ11 + σ22 − 2σ12
to obtain this scaling.
Note that when the error terms are iid, normalizing the variance of
one of these errors automatically normalizes the variance of the error
diﬀerences. With iid errors, σjj = σii and σij = 0 for i = j. Therefore,
if σ11 is normalized to k, then the variance of the error diﬀerence
becomes σ11 + σ22 − 2σ12 = k + k − 0 = 2k. The variance of the error
diﬀerence is indeed being normalized, the same as with non-iid errors.
Normalization has implications for the number of parameters that
can be estimated in the covariance matrix. The covariance of the original errors, Ω in equation (2.3), has ten elements in our 4-alternative
example. However, the covariance matrix of the error diﬀerences has
six elements, one of which is normalized to set the scale of utility differences. The covariance matrix for error diﬀerences with the variance
of the ﬁrst error diﬀerence normalized to k takes the form:




k ωab ωac


∗
Ω̃1 =  · ωbb ωbc 
·
·
ωcc

(2.5)

which has only ﬁve parameters. By recognizing the fact that only
diﬀerences matter and that the scale of utility is arbitrary, the number
of covariance parameters drops from ten to ﬁve. A model with J
alternatives has at most J(J − 1)/2 − 1 covariance parameters after
normalization.

2.6. AGGREGATION

35

Interpretation of the model is aﬀected by the normalization. Suppose for example that the elements of matrix (2.5) were estimated. The
parameter ωbb is the variance of the diﬀerence between the errors for
the ﬁrst and third alternatives relative to the variance of the diﬀerence
between the errors for the ﬁrst and second alternatives. Complicating
interpretation even further is the fact that the variance of the diﬀerence between the errors for two alternatives reﬂects the variances of
both as well as their covariance.
As we will see, the normalization of logit and nested logit models
is automatic with the distributional assumptions that are placed on
the error terms. Interpretation under these assumptions is relatively
straightforward. For mixed logit and probit, fewer assumptions are
placed on the distribution of error terms such that normalization is
not automatic. The researcher must keep the normalization issues in
mind when specifying and interpreting a model. We return to this topic
when discussing each discrete choice model in subsequent chapters.

2.6

Aggregation

Discrete choice models operate at the level of individual decisionmakers. However, the researcher is usually interested in some aggregate
measure, such as the average probability within a population or the
average response to a change in some factor.
In linear regression models, estimates of aggregate values of the
dependent variable are obtained by inserting aggregate values of the
explanatory variables into the model. For example, suppose hn is housing expenditures of person n, yn is the income of the person, and the
model relating them is hn = α + βyn . Since this model is linear, the
average expenditure on housing is simply calculated as α +β ȳ, where ȳ
is average income. Similarly, the average response to a one-unit change
in income is simply β, since β is the response for each person.
Discrete choice models are not linear in explanatory variables, and,
consequently, inserting aggregate values of the explanatory variables
into the models will not provide an unbiased estimate of the average probability or average response. The point can be made visually.
Consider Figure 2.1, which gives the probabilities of choosing a particular alternative for two individuals with the observed portion of their
utility (their “representative utility”) being a and b. The average probability is the average of the probabilities for the two people, namely,

CHAPTER 2. PROPERTIES

36

(Pa + Pb )/2. The average representative utility is (a + b)/2, and the
probability evaluated at this average is the point on the curve above
(a + b)/2. As shown for this case, the average probability is greater
than the probability evaluated at the average representative utility. In
general, the probability evaluated at the average representative utility
underestimates the average probability when the individuals’ choice
probabilities are low and overestimates when they are high.
Choice
Probability

Pb
average
probability
probability at
average

Pa
a

a+b
2

b

Representative
Utility

Figure 2.1: Diﬀerence between average probability and probability calculated at average representative utility.
Estimating the average response by calculating derivatives and elasticities at the average of the explanatory variables is similarly problematic. Consider Figure 2.2, depicting two individuals with representative
utilities a and b. The derivative of the choice probability for a change
in representative utility is small for both of these people (the slope of
the curve above a and b). Consequently, the average derivative is also
small. However, the derivative at the average representative utility is
very high (the slope above (a + b)/2.) Estimating average response in
this way can be seriously misleading. In fact, Talvitie (1976) found, in
a mode choice situation, that elasticities at the average representative
utility can be as much as two or three times greater or less than the
average of the individual elasticities.

2.6. AGGREGATION

37

Choice
Probability

a

a+b
2

b

Representative
Utility

Figure 2.2: Diﬀerence between average response and response calculated at average representative utility.
Aggregate outcome variables can be obtained consistently from discrete choice models in two ways, by sample enumeration or segmentation. We discuss each approach below.

2.6.1

Sample enumeration

The most straightforward, and by far the most popular, approach is
sample enumeration, by which the choice probabilities of each decisionmaker in a sample are summed, or averaged, over decision-makers.
Consider a discrete choice model that gives probability Pni that decisionmaker n will choose alternative i from a set of alternatives. Suppose a
sample of N decision-makers, labeled n = 1, . . . , N , is drawn from the
population for which aggregate statistics are required. (This sample
might be the sample on which the model was estimated. However,
it could also be a diﬀerent sample, collected in a diﬀerent area or a
later date than the estimation sample.) Each sampled decision-maker
n has some weight associated with him, wn , representing the number
of decision-makers similar to him in the population. For samples based
on exogenous factors, this weight is the inverse of the probability that
the decision-maker was selected into the sample. If the sample is purely

CHAPTER 2. PROPERTIES

38

random, then wn is the same for all n; and if the sample is stratiﬁed
random, then wn is the same for all n within a stratum.
A consistent estimate of the total number of decision-makers in the
population who choose alternative i, labeled N̂i , is simply the weighted
sum of the individual probabilities:
N̂i =

wn Pni .
n

The average probability, which is the estimated market share, is N̂i /N .
Average derivatives and elasticities are similarly obtained by calculating the derivative and elasticity for each sampled person and taking
the weighted average.

2.6.2

Segmentation

When the number of explanatory variables is small, and those variables
take only a few values, it is possible to estimate aggregate outcomes
without utilizing a sample of decision-makers. Consider, for example,
a model with only two variables entering the representative utility of
each alternative: education level and gender. Suppose the education
variable consists of four categories: did not complete high school, completed high school but did not attend college, attended college but did
not receive a degree, received a college degree. Then the total number
of diﬀerent types of decision-makers (called ”segments”) is eight: the
four education levels for each of the two genders. Choice probabilities
vary only over these eight segments, not over individuals within each
segment.
If the researcher has data on the number of people in each segment,
then the aggregate outcome variables can be estimated by calculating
the choice probability for each segment and taking the weighted sum
of these probabilities. The number of people estimated to choose alternative i is
8

N̂i =

ws P si,
s=1

where Psi is the probability that a decision-maker in segment s chooses
alternative i, and ws is the number of decision-makers in segment s.

2.7. FORECASTING

2.7

39

Forecasting

For forecasting into some future year, the procedures described above
for aggregate variables are applied. However, the exogenous variables
and/or the weights are adjusted to reﬂect changes that are anticipated
over time. With sample enumeration, the sample is adjusted so that
it looks like a sample that would be drawn in the future year. For
example, to forecast the number of people who will choose a given
alternative ﬁve years in the future, a sample drawn from the current
year is adjusted to reﬂect changes in socioeconomic and other factors
that are expected to occur over the next ﬁve years. The sample is adjusted by (i) changing the value of the variables associated with each
sampled decision-maker (e.g., increasing each decision-maker’s income
to represent real income growth over time), and/or (ii) changing the
weight attached to each decision-maker to reﬂect changes over time
in the number of decision-makers in the population that are similar to
the sampled decision-maker (e.g., increasing the weights for one-person
households and decreasing weights for large households to reﬂect expected decreases in household size over time.)
For the segmentation approach, changes in explanatory variables
over time are represented by changes in the number of decision-makers
in each segment. The explanatory variables themselves cannot logically
be adjusted since the distinct values of the explanatory variables deﬁne
the segments. Changing the variables associated with a decision-maker
in one segment simply shifts the decision-maker to another segment.

2.8

Recalibration of constants

As described in section (2.5.1), alternative-speciﬁc constants are often included in a model to capture the average impact of unobserved
factors. In forecasting, it is often useful to adjust these constants, to
reﬂect the fact that unobserved factors are diﬀerent for the forecast
area or year compared to the estimation sample. Market share data
from the forecast area can be used to “recalibrate” the constants appropriately. The recalibrated model can then be used to predict changes
in market shares due to changes in explanatory factors.
An iterative process is used to recalibrate the constants. Let αj0
be the estimated alternative-speciﬁc constant for alternative j. The
superscript 0 is used to indicate that these are the starting values in

40

CHAPTER 2. PROPERTIES

the iterative process. Let Si denote the share of decision-makers in the
forecast area that choose alternative j in the “base” year (usually, the
latest year for which such data are available.) Using the discrete choice
model with its original values of αj0 ∀ j, predict the share of decisionmakers in the forecast area who will choose each alternative. Label
these predictions Ŝj0 ∀ j. Compare the predicted shares with the actual
shares. If the actual share for an alternative exceeds the predicted
share, raise the constant for that alternative. Lower the constant if
the actual share is below the predicted. An eﬀective adjustment is:
αj1 = αj0 + ln(Sj /Ŝj0 ).
With the new constants, predict the share again, compare with the
actual shares, and if needed adjust the constants again. The process
is repeated until the forecasted shares are suﬃciently close to the actual shares. The model with these recalibrated constants is then used
to predict changes from base-year shares due to changes in observed
factors that aﬀect decision-makers’ choices.

Chapter 3

Logit
3.1

Choice probabilities

By far the easiest and most widely used discrete choice model is logit.
Its popularity is due to the fact that the formula for the choice probabilities takes a closed form and is readily interpretable. Originally, the
logit formula was derived by Luce (1959) from assumptions about the
characteristics of choice probabilities, namely the “independence from
irrelevant alternatives” property discussed in 3.3.2. Marschak (1960)
showed that these axioms implied that the model is consistent with
utility maximization. The relation of the logit formula to the distribution of unobserved utility (as opposed to the characteristics of choice
probabilities) was developed by Marley, as cited by Luce and Suppes
(1965), who showed that the extreme value distribution leads to the
logit formula. McFadden (1974) completed the analysis by showing
the opposite: that the logit formula for the choice probabilities necessarily implies that unobserved utility is distributed extreme value. In
his Nobel lecture, McFadden (2001) provides a fascinating history of
the development of this path-breaking model.
To derive the logit model, we use the general notation from Chapter 2 and add a speciﬁc distribution for unobserved utility. A decisionmaker, labeled n, faces J alternatives. The utility that the decisionmaker obtains from alternative j is decomposed into (1) a part labeled Vnj that is known by the researcher up to some parameters, and
(2) an unknown part εnj that is treated by the researcher as random:
Unj = Vnj +εnj ∀ j. The logit model is obtained by assuming that each
εnj is distributed independently, identically extreme value. The distri41

CHAPTER 3. LOGIT

42

bution is also called Gumbel and type I extreme value (and sometimes,
mistakenly, Weibull.) The density for each unobserved component of
utility is
−εnj

f (εnj ) = e−εnj e−e

(3.1)

and the cumulative distribution is
−εnj

F (εnj ) = e−e

.

(3.2)

The variance of this distribution is π 2 /6. By assuming the variance is
π 2 /6, we are implicitly normalizing the scale of utility, as discussed in
section 2.5. We return to this issue, and its impact on interpretation,
in the next section. The mean of the extreme value distribution is not
zero; however, the mean is immaterial since only diﬀerences in utility
matter (see Chapter 2) and the diﬀerence between two random terms
that have the same mean has itself a mean of zero.
The diﬀerence between two extreme value variables is distributed
logistic. That is, if εnj and εni are iid extreme value, then ε∗nji =
εnj − εni follows the logistic distribution
∗

F (ε∗nji ) =

eεnji
∗

1 + eεnji

.

(3.3)

This formula is sometimes used in describing binary logit models, i.e.,
models with two alternatives. Using the extreme value distribution
for the errors (and hence the logistic distribution for the error diﬀerences) is nearly the same as assuming that the errors are independently
normal. The extreme value gives slightly fatter tails than a normal,
which means that it allows for slightly more aberrant behavior than
the normal. Usually, however, the diﬀerence between extreme value
and independent normal errors is indistinguishable empirically.
The key assumption is not so much the shape of the distribution
as that the errors are independent of each other. This independence
means that the unobserved portion of utility for one alternative is unrelated to the unobserved portion of utility for another alternative. It
is a fairly restrictive assumption, and the development of other models such as those described in Chapters 4-6 has arisen largely for the
purpose of avoiding this assumption and allowing for correlated errors.
It is important to realize that the independence assumption is not
as restrictive as it might at ﬁrst seem, and in fact can be interpreted

3.1. CHOICE PROBABILITIES

43

as a natural outcome of a well-speciﬁed model. Recall from Chapter 2 that εnj is deﬁned as the diﬀerence between the utility that the
decision-maker actually obtains, Unj , and the representation of utility
that the researcher has developed using observed variables, Vnj . As
such, εnj and its distribution depend on the researcher’s speciﬁcation
of representative utility; it is not deﬁned by the choice situation per
se. In this light, the assumption of independence obtains a diﬀerent
stature. Under independence, the error for one alternative provides
no information to the researcher about the error for another alternative. Stated equivalently, the researcher has speciﬁed Vnj suﬃciently
that the remaining, unobserved portion of utility is essentially “white
noise.” In a deep sense, the ultimate goal of the researcher is to represent utility so well that the only remaining aspects constitute simply
white noise. That is: the goal is to specify utility well enough that
a logit model is appropriate. Seen in this way, the logit model is the
ideal rather than a restriction.
If the researcher thinks that the unobserved portion of utility is correlated over alternatives given his speciﬁcation of representative utility,
then she has three options (1) use a diﬀerent model that allows for correlated errors, such as those described in Chapters 4-6, (2) re-specify
representative utility so that the source of the correlation is captured
explicitly such that the remaining errors are independent, or (3) use
the logit model under the current speciﬁcation of representative utility
considering the model to be an approximation. The viability of the
last option depends, of course, on the goals of the research. Violations
of the logit assumptions seem to have less impact when estimating average preferences than when forecasting substitution patterns. These
issues are discussed in subsequence sections.
We now derive the logit choice probabilities, following McFadden
(1974). The probability that decision-maker n chooses alternative i is
Pni = P rob(Vni + εni > Vnj + εnj ∀ j = i)
= P rob(εnj < εni + Vni − Vnj ∀ j = i)

(3.4)

If εni is considered given, this expression is the cumulative distribution
for each εnj evaluated at εni + Vni − Vnj , which, according to (3.2), is
exp(−exp − (εni + Vni − Vnj ))). Since the ε’s are independent, this
cumulative distribution over all j = i is the product of the individual

CHAPTER 3. LOGIT

44
cumulative distributions:

−(εni +Vni −Vnj )

e−e

Pni | εni =

.

j=i

Of course, εni is not given, and so the choice probability is the integral
of Pni | εni over all values of εni weighted by its density (3.1):


Pni =




−(εni +Vni −Vnj )

e−e



−εni

 e−εni e−e

dεni .

(3.5)

j=i

Some algebraic manipulation of this integral results in a succinct,
closed-form expression:
eVni
(3.6)
Pni =  Vnj
je
which is the logit choice probability. The algebra that obtains (3.6)
from (3.5) is given in the last section of this chapter, for readers who
are interested.
Representative utility is usually speciﬁed to be linear in parameters:
Vnj = β  xnj where xnj is a vector of observed variables relating to
alternative j. With this speciﬁcation, the logit probabilities become:


eβ xni
Pni =  β  x .
nj
je
Under fairly general conditions, any function can be approximated
arbitrarily closely by one that is linear in parameters. The assumption is therefore fairly benign. Importantly, McFadden (1974) demonstrated that the log-likelihood function with these choice probabilities
is globally concave in parameters β, which helps in the numerical maximization procedures (as discussed in Chapter 8.) Numerous computer
packages contain routines for estimation of logit models with linear-inparameters representative utility.
The logit probabilities exhibit several desirable properties. First,
Pni is necessarily between zero and one, as required for a probability.
When Vni rises, reﬂecting an improvement in the observed attributes
of the alternative, with Vnj ∀ j = i held constant, Pni approaches one.
And Pni approaches zero when Vni decreases, since the exponential in
the numerator of (3.6) approaches zero as Vni approaches −∞. The
logit probability for an alternative is never exactly zero. If the research

3.1. CHOICE PROBABILITIES

45

believes that an alternative has actually no chance of being chosen by
a decision-maker, the researcher can exclude that alternative from the
choice set. A probability of exactly 1 is obtained only if the choice set
consists of a single alternative.
Second, the choice probabilities for all alternatives sum to one:
J


i=1 Pni =
i exp(Vni )/
j exp(Vnj ) = 1. The decision-maker necessarily chooses one of the alternatives. The denominator in (3.6) is
simply the sum of the numerator over all alternatives, which gives this
summing-up property automatically. With logit, as well as with some
more complex models such as the nested logit models of Chapter 4, interpretation of the choice probabilities is facilitated by recognition that
the denominator serves to assure that the probabilities sum to one. In
other models, such as mixed logit and probit, there is no denominator
per se to interpret in this way.
The relation of the logit probability to representative utility is sigmoid, or S-shaped, as shown in Figure 3.1. This shape has implications for the impact of changes in explanatory variables. If the representative utility of an alternative is very low compared with other
alternatives, a small increase in the utility of the alternative has little eﬀect on the probability of its being chosen: the other alternatives
are still suﬃciently better that this small improvement doesn’t help
much. Similarly, if one alternative is far superior to the others in observed attributes, a further increase in its representative utility has
little eﬀect on the choice probability. The point at which the increase
in representative utility has the greatest eﬀect on the probability of its
being chosen is when the probability is close to 0.5, meaning a 50-50
chance of the alternative being chosen. In this case, a small improvement “tips the balance” in people’s choices, inducing a large change
in probability. The sigmoid shape of logit probabilities is shared by
most discrete choice models and has important implications for policy
makers. For example, improving bus service in areas where the service
is so poor that few travelers take the bus would be less eﬀective, in
terms of transit ridership, than making the same improvement in areas where bus service is already suﬃciently good to induce a moderate
share of travelers to choose it (but not so good that nearly everyone
does.)
The logit probability formula is easily interpretable in the context
of an example. Consider a binary choice situation ﬁrst: a household’s
choice between a gas and electric heating system. Suppose that the

CHAPTER 3. LOGIT

46

Pni
1

0
Vni

Figure 3.1: Graph of logit curve.
utility the household obtains from each type of system depends only
on the purchase price, annual operating cost, and the household’s view
of the convenience and quality of heating with each type of system and
the relative aesthetics of the systems within the house. The ﬁrst two
of these factors can be observed by the researcher, but the researcher
cannot observe the others. If the researcher considers the observed part
of utility to be a linear function of the observed factors, then the utility
of each heating system can be written as: Ug = β1 P Pg + β2 OCg + εg
and Ue = β1 P Pe +β2 OCe +εe , where the subscripts g and e denote gas
and electric, P P and OC are the purchase price and operating cost,
β1 and β2 are scalar parameters, and the subscript n for the household
is suppressed. Since higher costs mean less money to spend on other
goods, we expect utility to drop as purchase price or operating cost
rises (with all else held constant): β1 < 0 and β2 < 0.
The unobserved component of utility for each alternative, εg and
εe , varies over households depending on how each household views the
quality, convenience and aesthetics of each type of system. If these
unobserved components are distributed iid extreme value, then the
probability that the household will choose gas heating is
Pg =

eβ1 P Pg +β2 OCg
eβ1 P Pg +β2 OCg + eβ1 P Pe +β2 OCe

(3.7)

3.1. CHOICE PROBABILITIES

47

and the probability of electric heating is the same but with exp(β1 P Pe +
β2 OCe ) as the numerator. The probability of choosing a gas system
decreases if its purchase price or operating cost rises while that of the
electric system remains the same (assuming that β1 and β2 are negative
as expected.)
As in most discrete choice models, the ratio of coeﬃcients in this example has economic meaning. In particular, the ratio β2 /β1 represents
the household’s willingness to pay for operating cost reductions. If β1
were estimated as −0.20 and β2 as −1.14, these estimates would imply
that households are willing to pay up to −1.14/ − 0.20 = 5.70 dollars
more for a system whose annual operating costs are one dollar less.
This relation is derived as follows. By deﬁnition, a household’s willingness to pay for operating cost reductions is the increase in purchase
price that keeps the household’s utility constant given a reduction in
operating costs. We take the total derivative of utility with respect to
purchase price and operating cost and set this derivative to zero so that
utility doesn’t change: ∂U = β1 ∂P P + β2 ∂OC = 0. We then solve for
the change in purchase price that keeps utility constant (i.e., satisﬁes
this equation) for a change in operating costs: ∂P P/∂OC = −β2 /β1 .
The negative sign indicates that the two changes are in the opposite
direction: to keep utility constant, purchase price rises when operating
cost decreases.
In this binary choice situation, the choice probabilities can be expressed in another, even more succinct form. Dividing the numerator and denominator of (3.7) by the numerator, and recognizing that
exp(a)/exp(b) = exp(a − b), we have
Pg =

1
1 + e(β1 P Pe +β2 OCe )−(β1 P Pg +β2 OCg )

.

In general, binary logit probabilities with representative utilities Vn1
and Vn2 can be written Pn1 = 1/(1 + exp(Vn2 − Vn1 )) and Pn2 =
1/(1 + exp(Vn1 − Vn2 )). If only demographics of the decision-maker,
sn , enter the model, and the coeﬃcients of these demographic variables
are normalized to zero for the ﬁrst alternative (as described in Chapter

2), the probability of the ﬁrst alternative is Pn1 = 1/(1 + eα sn ), which
is the form that is used in most textbooks and computer manuals for
binary logit.
Multinomial choice is a simple extension. Suppose there is a third
type of heating system, namely oil-fueled. The utility of the oil system

CHAPTER 3. LOGIT

48

is speciﬁed as the same form as for the electric and gas systems: Uo =
β1 P Po + β2 OCo + εo . With this extra option being available, the
probability that the household chooses a gas system is:
Pg =

eβ1 P Pg +β2 OCg
eβ1 P Pg +β2 OCg + eβ1 P Pe +β2 OCe + eβ1 P Po +β2 OCo

which is the same as (3.7) except that an extra term is included in
the denominator to represent the oil heater. Since the denominator is
larger while the numerator is the same, the probability of choosing a
gas system is smaller when an oil system is an option than when not,
as one would expect in the real world.

3.2

The scale parameter

In the previous section we derived the logit formula under the assumption that the unobserved factors are distributed extreme value with
variance π 2 /6. Setting the variance to π 2 /6 is equivalent to normalizing the model for the scale of utility, as discussed in section 2.5. It is
useful to make these concepts more explicit, to show the role that the
variance of the unobserved factors plays in logit models.
∗ = V
∗
In general, utility can be expressed as Unj
nj + εnj where the
2
2
unobserved portion has variance σ ∗ (π /6). That is, the variance is
any number, re-expressed as a multiple of π 2 /6. Since the scale of
utility is irrelevant to behavior, utility can be divided by σ without
changing behavior. Utility becomes Unj = Vnj /σ + εnj where εnj =
ε∗nj /σ. Now the unobserved portion has variance π 2 /6: V ar(εnj ) =
V ar(ε∗nj /σ) = (1/σ 2 )V ar(ε∗nj ) = (1/σ 2 ) ∗ σ 2 ∗ (π 2 /6) = π 2 /6. The
choice probability is
eVni /σ
Pni =  V /σ
nj
je
which is the same formula as in equation 3.6 but with representative
utility divided by σ. If Vnj is linear in parameters with coeﬃcient β ∗ ,
the choice probabilities become:
∗



e(β /σ) xni
Pni =  (β ∗ /σ) x
nj
je
Each of the coeﬃcients is scaled by 1/σ. The parameter σ is called the
scale parameter, because it scales the coeﬃcients to reﬂect the variance
of the unobserved portion of utility.

3.2. THE SCALE PARAMETER

49

Only the ratio β ∗ /σ can be estimated; β ∗ and σ are not separately
identiﬁed. Usually, the model is expressed in its scaled form, with
β = β ∗ /σ, which gives the standard logit expression


eβ xni
Pni =  β  x
nj
je
The parameters β are estimated, but for interpretation it is useful to
recognize that these estimated parameters are actually estimates of
the “original” coeﬃcients β ∗ divided by the scale parameter σ. The
coeﬃcients that are estimated indicate the impact of each observed
variable relative to the variance of the unobserved factors. A larger
variance in unobserved factors leads to lower coeﬃcients, even if the
observed factors have the same impact on utility (i.e., higher σ means
lower β even if β ∗ is the same.)
The scale parameter does not aﬀect the ratio of any two coeﬃcients,
since it drops out of the ratio; for example, β1 /β2 = (β1∗ /σ)/(β2∗ /σ) =
β1∗ /β2∗ , where the subscripts refer to the ﬁrst and second coeﬃcients.
Willingness to pay, values of time, and other measures of marginal
rates of substitution are not aﬀected by the scale parameter. Only the
interpretation of the magnitudes of all coeﬃcients is aﬀected.
So far we have assumed that the variance of the unobserved factors
is the same for all decision-makers, since the same σ is used for all n.
Suppose instead that the unobserved factors have greater variance for
some decision-makers than others. In section 2.5, we discuss a situation
where the variance of unobserved factors is diﬀerent in Boston than
Chicago. Denote the variance for all decision-makers in Boston as
(σ B )2 (π 2 /6) and that for decision-makers in Chicago as (σ C )2 (π 2 /6).
The ratio of variance in Chicago to that in Boston is k = (σ C /σ B )2 .
The choice probabilities for people in Boston become


eβ xni
Pni =  β  x
nj
je
and for people in Chicago are
√



e(β/ k) xni

Pni = 

j

√

e(β/ k) xnj

where β = β ∗ /σ B . The ratio of variances k is estimated along with
the coeﬃcients β. The estimated β’s are interpreted as being relative

CHAPTER 3. LOGIT

50

to the variance of unobserved factors in Boston, and the estimated
k provides information on the variance in Chicago relative to that
in Boston. More complex relations can be obtained by allowing the
variance for an observation to dependent on more factors. Also, data
from diﬀerent data sets can often be expected to have diﬀerent variance
for unobserved factors, giving a diﬀerent scale parameter for each data
set. Ben-Akiva and Morikawa (1990) and Swait and Louviere (1993)
discuss these issues and provide more examples.

3.3

Power and limitations of logit

Three topics elucidate the power of logit models to represent choice
behavior, as well as delineating the limits to that power. These topics
are: taste variation, substitution patterns, and repeated choices over
time. The applicability of logit models can be summarized as follows:
1. Logit can represent systematic taste variation (that is, taste
variation that relates to observed characteristics of the decisionmaker) but not random taste variation (diﬀerences in tastes that
cannot be linked to observed characteristics).
2. The logit model implies proportional substitution across alternatives, given the researcher’s speciﬁcation of representative utility.
To capture more ﬂexible forms of substitution, other models are
needed.
3. If unobserved factors are independent over time in repeated choice
situations, then logit can capture the dynamics of repeated choice,
including state-dependence. However, logit cannot handle situations where unobserved factors are correlated over time.
We elaborate each of these statements in the next three subsections.

3.3.1

Taste variation

The value or importance that decision-makers place on each attribute
of the alternatives varies, in general, over decision-makers. For example, the size of a car is probably more important to households with
many members than to smaller households. Low-income households
are probably more concerned about the purchase price of a good, relative to its other characteristics, than higher-income households. In

3.3. POWER AND LIMITATIONS OF LOGIT

51

choosing which neighborhood to live in, households with young children will be more concerned about the quality of schools than those
without children. And so on. Decision-makers’ tastes also vary for
reasons that are not linked to observed demographic characteristics,
just because diﬀerent people are diﬀerent. Two people who have the
same income, education, etc., will make diﬀerent choices, reﬂecting
their individual preferences and concerns.
Logit models can capture taste variations, but only within limits.
In particular, tastes that vary systematically with respect to observed
variables can be incorporated in logit models, while tastes that vary
with unobserved variables or purely randomly cannot be handled. The
following example illustrates the distinction.
Consider households’ choice among makes and models of cars to
buy. Suppose for simplicity that the only two attributes of cars that
the researcher observes are the purchase price, P Pj for make/model j,
and inches of shoulder room, SRj , which is a measure of the interior
size of a car. The value that households place on these two attributes
varies over households, and so utility is written as
Unj = αn SRj + βn P Pj + εnj ,

(3.8)

where αn and βn are parameters speciﬁc to household n.
The parameters vary over households reﬂecting diﬀerences in taste.
Suppose for example that the value of shoulder room varies with the
number of members in the households, Mn , but nothing else:
αn = ρMn ,
so that as Mn increases, the value of shoulder room, αn , also increases.
Similarly, suppose the importance of purchase price is inversely related
to income, In , so that low income households place more importance
on purchase price:
βn = θ/In .
Substituting these relations into (3.8) produces
Unj = ρ(Mn SRj ) + θ(P Pj /In ) + εnj .
Under the assumption that each εnj is iid extreme value, a standard
logit model obtains with two variables entering representative utility,
both of which are an interaction of a vehicle attribute with a household
characteristic.

CHAPTER 3. LOGIT

52

Other speciﬁcations for the variation in tastes can be substituted.
For example, the value of shoulder room might be assumed to increase
with household size, but at a decreasing rate, so that αn = ρMn +
φMn2 where ρ is expected to be positive and φ negative. Then Unj =
ρ(Mn SRj ) + φ(Mn2 SRj ) + θ(P Pj /In ) + εnj , which results in a logit
model with three variables entering representative utility.
The limitation of the logit model arises when we attempt to allow tastes to vary with respect to unobserved variables or purely randomly. Suppose for example that the value of shoulder room varied
with household size plus some other factors (e.g., size of the people
themselves, or frequency with which the household travels together)
that are unobserved by the researcher and hence considered random:
αn = ρMn + µn ,
where µn is a random variable. Similarly, the importance of purchase
price consists of its observed and unobserved components:
βn = θ/In + ηn .
Substituting into (3.8) produces
Unj = ρ(Mn SRj ) + µn SRj + θ(P Pj /In ) + ηn P Pj + εnj .
Since µn and ηn are not observed, the terms µn SRj and ηn P Pj become
part of the unobserved component of utility,
Unj = ρ(Mn SRj ) + θ(P Pj /In ) + ε̃nj ,
where ε̃nj = µn SRj +ηn P Pj +εnj . The new error terms ε̃nj cannot possibly be distributed independently and identically as required for the
logit formulation. Since µn and ηn enter each alternative, ε̃nj is necessarily correlated over alternatives: Cov(ε̃nj , ε̃nk ) = V ar(µn )SRj SRk +
V ar(ηn )P Pj P Pk = 0 for any two cars j and k. Furthermore, since
SRj and P Pj vary over alternatives, the variance of ε̃nj varies over
alternatives, violating the assumption of identically distributed errors:
V ar(ε̃nj ) = V ar(µn )SRj2 + V ar(ηn )P Pj2 + V ar(εnj ), which is diﬀerent
for diﬀerent j.
This example illustrates the general point that when tastes vary
systematically in the population in relation to observed variables, the
variation can be incorporated into logit models. However, if taste

3.3. POWER AND LIMITATIONS OF LOGIT

53

variation is at least partly random, logit is a misspeciﬁcation. As an
approximation, logit might be able to capture the average tastes fairly
well even when tastes are random, since the logit formula seems to
be fairly robust to misspeciﬁcations. The researcher might therefore
choose to use logit even when she knows that tastes have a random
component, for the sake of simplicity. However, there is no guarantee
that a logit model will approximate the average tastes. And, even
if it does, logit does not provide information on the distribution of
tastes around the average. This distribution can be important in many
situations, such as forecasting the penetration of a new product that
appeals to a minority of people rather than to the average tastes. To
incorporate random taste variation appropriately and fully, a probit or
mixed logit model can be used instead.

3.3.2

Substitution patterns

When the attributes of one alternative improve (e.g., its price drops),
the probability of its being chosen rises. Some of the people who
would have chosen other alternatives under the original attributes now
choose this alternative instead. Since probabilities sum to one over alternatives, an increase in the probability of one alternative necessarily
means a decrease in probability for other alternatives. The pattern of
substitution among alternatives has important implications in many
situations. For example, when a cell phone manufacturer launches a
new product with extra features, the ﬁrm is vitally interested in knowing the extent to which the new product will draw customers away from
its other cell phones rather than from competitors’ phones, since the
ﬁrm makes more proﬁt from the later than the former. Also, as we will
see, the pattern of substitution aﬀects the demand for a product and
the change in demand when attributes change. Substitution patterns
are therefore important even when the researcher is only interested in
market share without being concerned about where the share comes
from.
The logit model implies a certain pattern of substitution across
alternatives. If substitution actually occurs in this way given the researcher’s speciﬁcation of representative utility, then the logit model
is appropriate. However, to allow for more general patterns of substitution and to investigate which pattern is most accurate, more ﬂexible
models are needed. The issue can be seen in either of two ways, as a

CHAPTER 3. LOGIT

54

restriction on the ratios of probabilities and/or as a restriction on the
cross-elasticities of probabilities. We present each way of characterizing the issue below.
The independence from irrelevant alternatives (IIA) property
For any two alternatives i and k, the ratio of the logit probabilities is
Pni
Pnk



=

eVni / j eVnj

eVnk / j eVnj

=

eVni
= eVni −Vnk .
eVnk

This ratio does not depend on any alternatives other than i and k.
That is, the relative odds of choosing i over k is the same no matter what other alternatives are available or what the attributes of the
other alternatives are. Since the ratio is independent from alternatives
other than i and k, it is said to be independent from “irrelevant” alternatives. The logit model exhibits this “independence from irrelevant
alternatives,” or IIA, property.
In many settings, choice probabilities that exhibit IIA provide an
accurate representation of reality. In fact, Luce (1959) considered IIA
to be a property of appropriately speciﬁed choice probabilities. He
derived the logit model directly from an assumption that choice probabilities exhibit IIA, rather than (as we have done) derive the logit
formula from an assumption about the distribution of unobserved utility and then observe that IIA is a resulting property.
While the IIA property is realistic in some choice situations, it is
clearly inappropriate in others, as ﬁrst pointed out by Chipman (1960)
and Debreu (1960). Consider the famous red bus/blue bus problem. A
traveler has a choice of going to work by car or taking a blue bus. For
simplicity assume that the representative utility of the two modes are
the same, such that the choice probabilities are equal: Pc = Pbb = 1/2,
where c is car and bb is blue bus. In this case, the ratio of probabilities
is one: Pc /Pbb = 1.
Now suppose that a red bus is introduced and that the traveler
considers the red bus to be exactly like the blue bus. The probability
that the traveler will take the red bus is therefore the same as for the
blue bus, such that the ratio of their probabilities is one: Prb /Pbb = 1.
However, in the logit model the ratio Pc /Pbb is the same whether or

3.3. POWER AND LIMITATIONS OF LOGIT

55

not another alternative, in this case the red bus, exists. This ratio
therefore remains at one. The only probabilities for which Pc /Pbb = 1
and Prb /Pbb = 1 are Pc = Pbb = Prb = 1/3, which are the probabilities
that the logit model predicts.
In real life, however, we would expect the probability of taking a
car to remain the same when a new bus is introduced that is exactly
the same as the old bus. We would also expect the original probability
of taking bus to be split between the two buses after the second one is
introduced. That is, we would expect Pc = 1/2 and Pbb = Prb = 1/4.
In this case, the logit model, because of its IIA property, overestimates
the probability of taking either of the buses and underestimates the
probability of taking a car. The ratio of probabilities of car and blue
bus, Pc /Pbb , actually changes with the introduction of the red bus,
rather than remaining constant as required by the logit model.
This red bus/blue bus example is rather stark and unlikely to be
encountered in the real world. However, the same kind of misprediction arises with logit models whenever the ratio of probabilities for
two alternatives changes with the introduction or change in another
alternative. For example, suppose a new transit mode is added that
is similar, but not exactly like, the existing modes, such as an express
bus along a line that already has standard bus service. This new mode
might be expected to reduce the probability of regular bus by a greater
proportion than it reduces the probability of car, such that ratio of
probabilities for car and regular bus does not remain constant. The
logit model would overpredict demand for the two bus modes in this
situation. Other examples are given by, for example, Ortuzar (1983)
and Brownstone and Train (1999).
Proportional substitution
The same issue can be expressed in terms of the cross-elasticities of
logit probabilities. Let us consider changing an attribute of alternative
j. We want to know the eﬀect of this change on the probabilities for
all the other alternatives. Section (3.6) derives the formula for the
elasticity of Pni with respect to a variable that enters the representative
utility of alternative j:
Eiznj = −βz znj Pnj
where znj is the attribute of alternative j as faced by person n and βz
is its coeﬃcient (or, if the variable enters representative utility non-

CHAPTER 3. LOGIT

56

linearly, then βz is the derivative of Vnj with respect to znj ).
This cross-elasticity is the same for all i: i does not enter the
formula. An improvement in the attributes of an alternative reduces
the probabilities for all the other alternatives by the same percent. If
one alternative’s probability drops by ten percent, then all the other
alternatives’ probabilities also drop by ten percent (except of course
the alternative whose attribute changed; its probability rises due to the
improvement.) A way of stating this phenomenon succinctly is that an
improvement in one alternative draws proportionately from the other
alternatives. Similarly for a decrease in the representative utility of an
alternative: the probabilities for all other alternatives rise by the same
percent.
This pattern of substitution, which can be called “proportionate
shifting,” is a manifestation of the IIA property. The ratio of probabilities for alternatives i and k stays constant when an attribute of alternative j changes only if the two probabilities change by the same proportion. With superscript 0 denoting probabilities before the change
and 1 after, the IIA property requires that
1
0
Pni
Pni
=
1
0
Pnk
Pnk

when an attribute of alternative j changes. This equality can only
be maintained if each probability changes by the same proportion:
1 = λP 0 and P 1 = λP 0 where both λ’s are the same.
Pni
ni
nk
nk
Proportionate substitution can be realistic for some situations, in
which case the logit model is appropriate. In many settings, however,
other patterns of substitution can be expected, and imposing proportionate substitution through the logit model can lead to unrealistic
forecasts. Consider a situation that is important to the California Energy Commission (CEC), which has the responsibility of investigating
policies to promote energy eﬃcient vehicles in California and reducing the state’s reliance on gasoline for cars. Suppose for the sake of
illustration that there are three kinds of vehicles: large gas cars, small
gas cars, and small electric cars. Suppose also that under current conditions the probabilities that a household will choose each of these
vehicles are .66, .33, and .01, respectively. The CEC is interested in
knowing the impact of subsidizing the electric cars. Suppose the subsidy is suﬃcient to raise the probability for the electric car from .01 to
.10. By the logit model, the probability for each of the gas cars would

3.3. POWER AND LIMITATIONS OF LOGIT

57

be predicted to drop by the same percent. The large gas car would
drop by ten percent from .66 to .60 and the probability for the small
gas car would drop by the same ten percent from .33 to .30. In terms
of absolute numbers, the increased probability for the small electric
car (.09) is predicted by the logit model to come twice as much from
large gas cars (.06) as from small gas cars (0.03).
This pattern of substitution is clearly unrealistic. Since the electric
car is small, subsidizing it can be expected to draw more from small
gas cars than from large gas cars. In terms of cross-elasticities, we
would expect the cross-elasticity for small gas cars with respect to an
improvement in small electric cars to be higher than that for large
gas cars. This diﬀerence is important in the CEC’s policy analysis.
The logit model will over-predict the gas savings that result from the
subsidy, since it over-predicts the substitution away from large gas cars
(the “gas guzzlers”) and under-predicts the substitution away from
small “gas-sipper” cars. From a policy perspective, this misprediction
can be critical, causing a subsidy program to seem more beneﬁcial than
it actually is. This is the reason that the CEC uses models that are
more general than logit to represent substitution across vehicles. The
nested logit, probit and mixed logit models of Chapters 4-6 provide
viable options for the researcher.
Advantages of IIA
As just discussed, the IIA property of logit can be unrealistic in many
settings. However, when the IIA property reﬂects reality (or an adequate approximation to reality), considerable advantages are gained
by its employment. First, because of the IIA property, it is possible
to estimate model parameters consistently on a subset of alternatives
for each sampled decision-maker. For example, in a situation with 100
alternatives, the researcher might, so as to reduce computer time, estimate on a subset of 10 alternatives for each sampled person, with the
person’s chosen alternative included as well as 9 alternatives randomly
selected from the remaining 99. Since relative probabilities within a
subset of alternatives are unaﬀected by the attributes or existence of
alternatives not in the subset, exclusion of alternatives in estimation
does not aﬀect the consistency of the estimator. Details of this type of
estimation are given in section (3.7.1). This fact has considerable practical importance. In analyzing choice situations for which the number

58

CHAPTER 3. LOGIT

of alternatives is large, estimation on a subset of alternatives can save
substantial amounts of computer time. At an extreme, the number of
alternatives might be so large as to preclude estimation altogether if
it were not possible to utilize a subset of alternatives.
Another practical use of the IIA property arises when the researcher
is only interested in examining choices among a subset of alternatives
and not among all alternatives. For example, consider a researcher who
is interested in understanding the factors that aﬀect workers’ choice between car and bus modes for travel to work. The full set of alternative
modes includes walking, bicycling, motor-biking, skate-boarding, etc.
If the researcher believed that the IIA property holds adequately well
in this case, she could estimate a model with only car and bus as the
alternatives and exclude from the analysis sampled workers who used
other modes. This strategy would save the researcher considerable time
and expense developing data on the other modes without hampering
her ability to examine the factors related to car and bus.
Tests of IIA
Whether IIA holds in a particular setting is an empirical question,
amenable to statistical investigation. Tests of IIA were ﬁrst developed
by McFadden, Train and Tye (1978). Two types of tests are suggested.
First, the model can be re-estimated on a subset of the alternatives.
Under IIA, the ratio of probabilities for any two alternatives is the
same whether or not other alternatives are available. As a result, if
IIA holds in reality, then the parameter estimates obtained on the subset of alternatives will not be signiﬁcantly diﬀerent from those obtained
on the full set of alternatives. A test of the hypothesis that the parameters on the subset are the same as the parameters on the full set
constitutes a test of IIA. Hausman and McFadden (1984) provide an
appropriate statistic for this type of test. Second, the model can be reestimated with new, cross-alternative variables, that is, with variables
from one alternative entering the utility of another alternative. If the
ratio of probabilities for alternatives i and k actually depends on the
attributes and existence of a third alternative j (in violation of IIA),
then the attributes of alternative j will enter signiﬁcantly the utility of
alternatives i or k within a logit speciﬁcation. A test of whether crossalternative variables enter the model therefore constitutes a test of
IIA. McFadden (1987) developed a procedure for performing this kind

3.3. POWER AND LIMITATIONS OF LOGIT

59

of test with regressions: with the dependent variable being the residuals of the original logit model and the explanatory variables being
appropriately speciﬁed cross-alternative variables. Train, Ben-Akiva
and Atherton (1989) show how this procedure can be performed conveniently within the logit model itself.
The advent of models that do not exhibit IIA, and especially the
development of software for estimating these models, makes testing
IIA easier than before. For more ﬂexible speciﬁcations, such as GEV
and mixed logit, the simple logit model with IIA is a special case that
arises under certain constraints on the parameters of the more ﬂexible
model. In these cases, IIA can be tested by testing these constraints.
For example, a mixed logit model becomes a simple logit if the mixing
distribution has zero variance. IIA can be tested by estimating a mixed
logit and testing whether the variance of the mixing distribution is in
fact zero.
A test of IIA as a constraint on a more general model necessarily operates under the maintained assumption that the more general model
is itself an appropriate speciﬁcation. The tests on subsets of alternatives (Hausman and McFadden, 1984) and cross-alternative variables
(McFadden, 1987; Train et al., 1989), while more diﬃcult to perform,
operate under less restrictive maintained hypotheses. The counterpoint to this advantage, of course, is that, when IIA fails, these tests
do not provide as much guidance on the correct speciﬁcation to use
instead of logit.

3.3.3

Panel data

In many settings, the researcher can observe numerous choices made
by each decision-maker. For example, in labor studies, sampled people
are observed to work or not work in each month over several years.
Data on the current and past vehicle purchases of sampled households
might be obtained by a researcher who is interested in the dynamics of
car choice. In market research surveys, respondents are often asked a
series of hypothetical choice questions, called “stated preference” experiments. For each experiment, a set of alternative products with
diﬀerent attributes are described and the respondent is asked to state
which product he would choose. A series of such questions is asked,
with the attributes of the products varying so as to determine how
the respondent’s choice changes when the attributes change. The re-

60

CHAPTER 3. LOGIT

searcher therefore observes the sequence of choices by each respondent.
Data that represent repeated choices like these are called panel data.
If the unobserved factors that aﬀect decision-makers are independent over the repeated choices, then logit can be used to examine panel
data in the same way as purely cross-sectional data. Any dynamics related to observed factors that enter the decision-process, such as statedependence (by which the person’s past choices inﬂuence their current
choices) or lagged response to changes in attributes, can be accommodated. However, dynamics associated with unobserved factors cannot
be handled, since the unobserved factors are assumed to be unrelated
over choices.
The utility that decision-maker n obtains from alternative j in
period or choice situation t is
Unjt = Vnjt + εnjt ∀ j, t.
If εnjt is distributed extreme value, independent over n, j, and, importantly, t, then, using the same proof as for (3.6), the choice probabilities
are:
eVnit
(3.9)
Pnit =  Vnjt .
je
Each choice situation by each decision-maker becomes a separate observation. If representative utility for each period is speciﬁed to depend
only on variables for that period, e.g., Vnjt = β  xnjt where xnjt is a
vector of variables describing alternative j as faced by n in period t,
then there is essentially no diﬀerence in the logit model with panel
data than with purely cross-sectional data.
Dynamic aspects of behavior can be captured by specifying representative utility in each period to depend on observed variables from
other periods. For example, a lagged price response is represented
by entering the price in period t − 1 as an explanatory variable in
the utility for period t. Prices in future periods can be entered, as
by Adamowicz (1994), to capture consumers’ anticipation of future
price changes. Under the assumptions of the logit model, the dependent variable in previous periods can also be entered as an explanatory
variable. Suppose for example that there is inertia, or habit formation,
in people’s choices such that they tend to stay with the alternative that
they have previously chosen unless another alternative provides suﬃciently higher utility to warrant a switch. This behavior is captured
as Vnjt = αynj(t−1) + βxnjt where ynjt = 1 if n chose j in period t and

3.4. NON-LINEAR REPRESENTATIVE UTILITY

61

zero otherwise. With α > 0, the utility of alternative j in the current
period is higher if alternative j was consumed in the previous period.
The same speciﬁcation can also capture a type of variety seeking. If α
is negative, the consumer obtains higher utility from not choosing the
same alternative that he chose in the last period. Numerous variations
on these concepts are possible. Adamowicz (1994) enters the number of times the alternative has been chosen previously, rather than
simply a dummy for the immediately previous choice. Erdem (1996)
enters the attributes of previously chosen alternatives, with the utility
of each alternative in the current period depending on the similarity
of its attributes to these previously experienced attributes.
The inclusion of the lagged dependent variable does not induce
inconsistency in estimation since, for a logit model, the errors are assumed to be independent over time. The lagged dependent variable
ynj(t−1) is uncorrelated with the current error εnjt due to this independence. The situation is analogous to linear regression models, where a
lagged dependent variable can be added without inducing bias as long
as the errors are independent over time.
Of course, the assumption of independent errors over time is severe. Usually, one would expect that there are some factors that are
not observed by the researcher that aﬀect each of the decision-makers’
choices. In particular, if there are dynamics in the observed factors,
then the researcher might expect there to be dynamics in the unobserved factors as well. In these situations, the researcher can either use
a model such as probit or mixed logit that allows unobserved factors
to be correlated over time, or re-specify representative utility to bring
the sources of the unobserved dynamics into the model explicitly such
that the remaining errors are independent over time.

3.4

Non-linear representative utility

In some contexts, the researcher will ﬁnd it useful to allow parameters
to enter representative utility nonlinearly. Estimation is more diﬃcult since the log-likelihood function might not be globally concave,
and computer routines are not as widely available as for logit models with linear-in-parameters utility. However, the aspects of behavior
that the researcher is investigating might include parameters that are
interpretable only when they enter utility non-linearly. In these cases,
the eﬀort of writing one’s own code can be warranted. Two examples

CHAPTER 3. LOGIT

62
illustrate this point.
Example 1: the goods/leisure trade-oﬀ

Consider a workers’ choice of mode (car or bus) for trips to work.
Suppose that workers also choose the number of hours to work based on
the standard trade-oﬀ between goods and leisure. Train and McFadden
(1978) developed a procedure for examining these interrelated choices.
As we see below, the parameters of the workers’ utility function over
goods and leisure enter non-linearly in the utility for modes of travel.
Assume that workers’ preferences regarding goods G and leisure L
are represented by a Cobb-Douglas utility function of the form:
U = (1 − β)lnG + βlnL.
The parameter β reﬂects the worker’s relative preference for goods and
leisure, with higher β implying greater preference for leisure relative
to goods. Each worker has a ﬁxed amount of time (24 hours a day)
and faces a ﬁxed wage rate, w. In the standard goods-leisure model,
the worker chooses the number of hours to work that maximizes U
subject to the constraints that (1) the number of hours worked plus
the number of leisure hours equals the number of hours available, and
(2) the value of goods consumed equals the wage rate times the number
of hours worked.
When mode choice is added to the model, the constraints on time
and money change. Each mode takes a certain amount of time and
costs a certain amount of money. Conditional on choosing car, the
worker maximizes U subject to the constrain that (1) the number of
hours worked plus the number of leisure hours equals the number of
hours available after the time spent driving to work in the car is subtracted and (2) the value of goods consumed equals the wage rate times
the number of hours worked minus the cost of driving to work. The
utility associated with choosing to travel by car is the highest value of
U that can be attained under these constraints. Similarly, the utility
of taking the bus to work is the maximum value of U that can be obtained given the time and money that is left after the bus time and cost
are subtracted. Train and McFadden derived the maximizing values of
U conditional on each mode. For the U given above, these values are
Uj = −α((cj /wβ ) + w1−β tj ) for j = car and bus

3.4. NON-LINEAR REPRESENTATIVE UTILITY

63

The cost of travel is divided by wβ and travel time is multiplied by
w1−β . The parameter β, which denotes workers’ relative preference for
goods and leisure, enters the mode choice utility non-linearly. Since
this parameter has meaning, the researcher might want to estimate
it within this non-linear utility rather than use a linear-in-parameters
approximation.
Example 2: geographic aggregation
Models have been developed and widely used for travelers’ choice of
destination for various types of trips, such as shopping trips, within a
metropolitan area. Usually, the metropolitan area is partitioned into
“zones,” and the models give the probability that a person will choose
to travel to a particular zone. Representative utility for each zone
depends on the time and cost of travel to the zone plus a variety of
variables, such as residential population and retail employment, that
reﬂect reasons that people might want to visit the zone. These latter
variables are called “attraction” variables; label them by the vector aj
for zone j. Since it is these attraction variables that give rise to parameters entering non-linearity, assume for simplicity that representative
utility depends only on these variables.
The diﬃculty in specifying representative utility comes in recognizing that the researcher’s decision of how large an area to include in
each zone is fairly arbitrary. It would be useful to have a model that
is not sensitive to the level of aggregation in the zonal deﬁnitions. If
two zones are combined, it would be useful for the model to give a
probability of traveling to the combined zone that is the same as the
sum of the probabilities of traveling to the two original zones. This
consideration places restrictions on the form of representative utility.
Consider zones j and k which, when combined, are labeled zone c.
Population and employment in the combined zone are necessarily the
sum of that in the two original zones: aj + ak = ac . In order for the
models to give the same probability for choosing these zones before
and after their merger, the model must satisfy:
Pnj + Pnk = Pnc
which for logit models takes the form
eVnc
eVnj + eVnk


=
eVnc + =j,k eVn
eVnj + eVnk + =j,k eVn

CHAPTER 3. LOGIT

64

This equality holds only when exp(Vnj ) + exp(Vnk ) = exp(Vnc ). If
representative utility is speciﬁed as Vn = ln(β  a ) for all zones , then
the inequality holds: exp(ln(β  aj )) + exp(ln(β  ak )) = β  aj + β  ak =
β  ac = exp(ln(β  ac )). Therefore, to specify a destination choice model
that is not sensitive to the level of zonal aggregation, representative
utility needs to be speciﬁed with parameters inside a log operation.

3.5

Consumer Surplus

For policy analysis, the researcher is often interested in measuring the
change in consumer surplus that is associated with a particular policy.
For example, if a new alternative is being considered, such as building a
light rail system in a city, then it is important to measure the beneﬁts
of the project to see if they warrant the costs. Similarly, a change
in the attributes of an alternative can have an impact on consumer
surplus that is important to assess. Degradation of the water quality
of rivers harms the anglers who can no longer ﬁsh as eﬀectively at the
damaged sites. Measuring this harm in monetary terms is a central
element of legal action against the polluter. Often the distributional
impacts of a policy are important to assess, such as how the burden of
a tax is borne by diﬀerent population groups.
Under the logit assumptions, the consumer surplus associated with
a set of alternatives takes a closed form that is easy to calculate. By
deﬁnition, a person’s consumer surplus is the utility, in dollar terms,
that the person receives in the choice situation. The decision-maker
chooses the alternative that provides the greatest utility. Consumer
surplus is therefore CSn = (1/αn )maxj (Unj ∀ j), where αn is the
marginal utility of income: dUn /dYn = αn with Yn being the income
of person n. The division by αn translates utility into dollars since
1/αn = dYn /dUn . The researcher does not observe Unj and therefore
cannot use this expression to calculate the decision-maker’s consumer
surplus. Instead, the researcher observes Vnj and knows the distribution of the remaining portion of utility. With this information, the
researcher is able to calculate the expected consumer surplus:
E(CSn ) =

1
E[max(Vnj + εnj ∀ j)],
αn

where the expectation is over all possible values of the εnj ’s. Williams
(1977) and Small and Rosen (1981) show that, if each εnj is iid extreme

3.5. CONSUMER SURPLUS

65

value and utility is linear in income (such that αn is constant with
respect to income), then this expectation becomes:
E(CSn ) =

J
1
ln(
eVnj ) + C.
αn j=1

(3.10)

where C is an unknown constant that represents the fact that the
absolute level of utility cannot be measured. As we see below, this
constant is irrelevant from a policy perspective and can be ignored.
Note that the term in parentheses in this expression is the denominator of the logit choice probability (3.6). Aside from the division and
addition of constants, expected consumer surplus in a logit model is
simply the log of the denominator of the choice probability. It is often
called “the log-sum term.” This relation between the two formulas
has no economic meaning, in the sense that there is nothing about a
denominator in a choice probability that makes it necessarily related
to consumer surplus. It is simply the outcome of the mathematical
form of the extreme value distribution. However, the relation makes
calculation of expected consumer surplus very easy, which is another
of the many conveniences of logit.
Under the standard interpretation for the distribution of errors, as
described in the last paragraph of 2.3, E(CSn ) is the average consumer
surplus in the subpopulation of people who have the same representative utilities as person n. Total consumer surplus in the population is
calculated as the weighted sum of E(CSn ) over a sample of decisionmakers, with the weights reﬂecting the number of people in the population who face the same representative utilities as the sampled person.
The change in consumer surplus that results from a change in the
alternatives and/or the choice set is calculated from (3.10). In particular, E(CSn ) is calculated twice: ﬁrst under the conditions before the
change and again under the conditions after the change. The diﬀerence
between the two results is the change in consumer surplus:
1

0

J
J
1
0
1
[ln(
eVnj ) − ln(
eVnj )],
∆E(CSn ) =
αn
j=1
j=1

where the superscripts 0 and 1 refer to before and after the change.
The number of alternatives can change (e.g., a new alternative added)
as well as the attributes of the alternatives. Since the unknown constant C enters expected consumer surplus both before and after the

66

CHAPTER 3. LOGIT

change, it drops out of the diﬀerence and can therefore be ignored
when calculating changes in consumer surplus.
To calculate the change in consumer surplus, the researcher must
know or have estimated the marginal utility of income αn . Usually
a price or cost variable enters representative utility, in which case the
negative of its coeﬃcient is αn by deﬁnition. (A price or cost coeﬃcient
is negative; the negative of a negative coeﬃcient gives a positive αn ).
For example, in the choice between car and bus, utility is Unj = β1 tnj +
β2 cnj where t is time, c is cost, and both β1 and β2 are negative,
indicating that utility decreases as the time or cost for a trip increases.
The negative of the cost coeﬃcient, −β2 , is the amount that utility
rises due to a one-dollar decrease in costs. A one-dollar reduction in
costs is equivalent to a one-dollar increase in income, since the person
gets to spend the dollar that he saves in travel costs just the same as
if he got the extra dollar in income. The amount −β2 is therefore the
increase in utility from a one-dollar increase in income: the marginal
utility of income. It is the same amount in this case for all n. If cnj
entered representative utility interacting with characteristics of the
person other than income, such as cnj Hn where Hn is household size,
then the marginal utility of income would be −β2 Hn , which varies over
n.
Throughout this discussion, αn has been assumed to be ﬁxed for
a given person independent of their income. The formula (3.10) for
expected consumer surplus depends critically on the assumption that
the marginal utility of income is constant with respect to income. If
the marginal utility of income changes with income, then a more complicated formula is needed, since αn itself becomes a function of the
change in attributes. McFadden (1999) and Karlstrom (2000) provide
procedures for calculating changes in consumer surplus under these
conditions.
The conditions for using expression (3.10) are actually less severe
than stated. Since only changes in consumer surplus are relevant for
policy analysis, formula (3.10) can be used if the marginal utility of
income is constant over the range of implicit income changes that are
considered by the policy. Thus, for policy changes that change consumer surplus by small amounts per person relative to their income,
the formula can be used even though the marginal utility of income in
reality varies with income.
The assumption that αn does not depend on income has implication

3.6. DERIVATIVES AND ELASTICITIES

67

for the speciﬁcation of representative utility. As discussed above, αn
is usually taken as the absolute value of the coeﬃcient of price or
cost. Therefore, if the researcher plans to use her model to estimate
changes in consumer surplus and wants to apply formula (3.10), this
coeﬃcient cannot be speciﬁed to depend on income. In the mode
choice example, cost can be multiplied by household size such that
the cost coeﬃcient, and hence the marginal utility of income, varies
over households of diﬀerent size. However, if cost is divided by the
household’s income, then the coeﬃcient of cost depends on income,
violating the assumption needed for expression (3.10). This violation
might not be important for small changes in consumer surplus, but
certainly becomes important for large changes.

3.6

Derivatives and Elasticities

Since choice probabilities are a function of observed variables, it is often useful to know the extent to which these probabilities change in
response to a change in some observed factor. For example, in a household’s choice of make and model of car to buy, a natural question is: to
what extent will the probability of choosing a given car increase if the
vehicle’s fuel eﬃciency is improved? From competing manufacturers
points of view, a related question is: to what extent will the probability of households’ choosing, say, a Toyota decrease if the fuel eﬃciency
of a Honda improves.
To address these questions, derivatives of the choice probabilities
are calculated. The change in the probability that decision-maker n
chooses alternative i given a change in an observed factor, zni , entering the representative utility of that alternative (and holding the
representative utility of other alternatives constant) is
∂Pni
∂zni



=
=
=
=

∂[(eVni )/( j eVnj )]
∂zni
∂Vni
[eVni /
eVnj ](
) − [eVni /(
∂zni
∂Vni
2
(Pni − Pni
)
∂zni
∂Vni
Pni (1 − Pni ).
∂zni

eVnj )2 ](eVni )(

∂Vni
)
∂zni

If representative utility is linear in zni with coeﬃcient βz , the derivative

CHAPTER 3. LOGIT

68

becomes βz Pni (1 − Pni ). This derivative is largest when Pni = 1 − Pni ,
which occurs when Pni = .5. It becomes smaller as Pni approaches zero
or one. The sigmoid probability curve in Figure 3.1 is consistent with
these facts. Stated intuitively, the eﬀect of a change in an observed
variable is highest when the choice probabilities indicate a high degree
of uncertainty regarding the choice. As the choice becomes more certain (i.e., the probabilities approach zero or one), the eﬀect of a change
in an observed variable lessens.
One can also determine the extent to which the probability of
choosing a particular alternative changes when an observed variable
relating to another alternative changes. Let znj denote an attribute
of alternative j. How does the probability of choosing alternative i
change as znj increases?
∂Pni
∂znj



=

∂[(eVni )/( k eVnk )]
∂znj

= −[(eVni )/(
= −

eVnk )2 ](eVnj )(

∂Vnj
)
∂znj

∂Vnj
Pni Pnj .
∂znj

When Vnj is linear in znj with coeﬃcient βz , then this crossderivative becomes −βz Pni Pnj . If znj is a desirable attribute such that
βz is positive, then raising znj decreases the probability of choosing
each alternative other than j. Furthermore, the decrease in probability is proportional to the value of the probability before znj was
changed.
A logically necessary aspect of derivatives of choice probabilities
is that, when an observed variable changes, the changes in the choice
probabilities sum to zero. This is a consequence of the fact that the
probabilities must sum to one before and after the change; it is demonstrated for logit models as follows:
J

∂Pni
∂znj
i=1

= (

∂Vnj
∂Vnj
)Pnj (1 − Pnj ) +
(−
)Pnj Pni
∂znj
∂z
nj
i=j




= (

∂Vnj
)Pnj (1 − Pnj ) −
Pni 
∂znj
i=j

= (

∂Vnj
)Pnj [(1 − Pnj ) − (1 − Pnj )]
∂znj

3.6. DERIVATIVES AND ELASTICITIES

69

= 0.
In practical terms, if one alternative is improved so that the probability
of its being chosen increases, the additional probability is necessarily
“drawn” from other alternatives. To increase the probability of one
alternative necessitates decreasing the probability of another alternative. While obvious, this fact is often forgotten by planners who want
to improve demand for one alternative without reducing demand for
other alternatives.
Economists often measure response by elasticities rather than derivatives, since elasticities are normalized for the variables’ units. An elasticity is the percent change in one variable that is associated with a
percent change in another variable. The elasticity of Pni with respect
to zni , a variable entering the utility of alternative i, is
Eizni

= (∂Pni /∂zni )(zni /Pni )
=

∂Vni
Pni (1 − Pni )(zni /Pni )
∂zni

=

∂Vni
zni (1 − Pni ).
∂zni

If representative utility is linear in zni with coeﬃcient βz , then Eizni =
βz zni (1 − Pni ).
The cross-elasticity of Pni with respect to a variable entering alternative j is
Eiznj

= (∂Pni /∂znj )(znj /Pni )
= −

∂Vnj
znj Pnj .
∂znj

which in the case of linear utility reduces to Eiznj = −βz znj Pnj . As
discussed in section (3.3.2), this cross elasticity is the same for all
i: a change in an attribute of alternative j changes the probabilities
for all other alternatives by the same percent. This property of the
logit cross-elasticities is a manifestation, or re-statement, of the IIA
property of the logit choice probabilities.

CHAPTER 3. LOGIT

70

3.7

Estimation

Manski and McFadden (1981) and Cosslett (1981) describe estimation methods under a variety of sampling procedures. We discuss in
this section estimation under the most prominent of these sampling
schemes. We ﬁrst describe estimation when the sample is exogenous
and all alternatives are used in estimation. We then discuss estimation
on a subset of alternatives and with certain types of choice-based (i.e.,
non-exogenous) samples.

3.7.1

Exogenous sample

Consider ﬁrst the situation in which the sample is exogenously drawn,
that is, is either random or stratiﬁed random with the strata deﬁned
on factors that are exogenous to the choice being analyzed. If the sampling procedure is related to the choice being analyzed (for example,
if mode choice is being examined and the sample is drawn by selecting
people on buses and pooling them with people selected at toll booths),
then more complex estimation procedures are generally required, as
discussed in the next section. We also assume that the explanatory
variables are exogenous to the choice situation. That is, the variables
entering representative utility are independent of the unobserved component of utility.
A sample of N decision-makers is obtained for the purposes of
estimation. Since the logit probabilities take a closed form, the traditional maximum likelihood procedures can be applied. The probability
of person n choosing the alternative that he was actually observed to
choose can be expressed as
(Pni )yni ,
i

where yni = 1 if person n chose i and zero otherwise. Note that since
yni = 0 for all nonchosen alternatives and Pni raised to the power of
zero is 1, this term is simply the probability of the chosen alternative.
Assuming that each decision-maker’s choice is independent of that
of other decision-makers, the probability of each person in the sample
choosing the alternative that he was observed actually to choose is
N

(Pni )yni

L(β) =
n=1 i

3.7. ESTIMATION

71

where β is a vector containing the parameters of the model. The loglikelihood function is then
N

yni ln(Pni )

LL(β) =

(3.11)

n=1 i

and the estimator is the value of β that maximizes this function.
McFadden (1974) shows that LL(β) is globally concave for linear-inparameters utility, and many statistical packages are available for estimation of these models. When parameters enter representative utility
non-linearly, the researcher might need to write her own estimation
code using the procedures described in Chapter 8.
Maximum likelihood estimation in this situation can be re-expressed
and re-interpreted in a way that assists in understanding the nature of
the estimates. At the maximum of the likelihood function, its derivative with respect to each of the parameters is zero:
dLL(β)
= 0.
dβ

(3.12)

The maximum likelihood estimates are therefore the values of β that
satisfy this ﬁrst-order condition. For convenience, let representative
utility be linear in parameters: Vnj = β  xnj . This speciﬁcation is not
required, but makes the notation and discussion more succinct. Using
(3.11) and the formula for the logit probabilities, we show at the end
of this subsection that the ﬁrst order condition (3.12) becomes:
(yni − Pni )xni = 0.
n

(3.13)

i

Rearranging and dividing both sides by N, we have
1
N

yni xni =
n

i

1
N

Pni xni
n

(3.14)

i

This expression is readily interpretable. Let x̄ denote the average
of x over the chosen alternatives by the sampled individuals: x̄ =
 
(1/N ) n i yni xni . Let x̂ be the average of x over the predicted
 
choices of the sampled decision-makers: x̂ = (1/N ) n i Pni xni . The
observed average of x in the sample is x̄, while x̂ is the predicted average. By (3.14), these two averages equal each other at the maximum
likelihood estimates. That is: the maximum likelihood estimates of β

CHAPTER 3. LOGIT

72

are those that make the predicted average of each explanatory variable equal to the observed average in the sample. In this sense, the
estimates induce the model to reproduce the observed averages in the
sample.
This property of the maximum likelihood estimator for logit models takes a special meaning for the alternative-speciﬁc constants. An
alternative-speciﬁc constant is the coeﬃcient of a dummy variable that
identiﬁes an alternative. A dummy for alternative j is a variable whose
value in the representative utility of alternative i is dji = 1 for i = j
and zero otherwise. By (3.14), the estimated constant is the one that
gives
1
N

yni dji
n

i

Sj

=

1
N

Pni dji
n

i

= Ŝj

where Sj is the share of people in the sample who chose alternative
j and Ŝj is the predicted share for alternative j. With alternativespeciﬁc constants, the predicted shares for the sample equal the observed shares. The estimated model is therefore correct on average
within the sample. This feature is similar to the function of a constant
in a linear regression model, where the constant assures that the average of the predicted value of the dependent variable equals its observed
average in the sample.
The ﬁrst-order condition (3.13) provides yet another important interpretation. The diﬀerence between a person’s actual choice, yni , and
the probability of that choice, Pni , is a modeling error, or residual.
The left hand side of (3.13) is the sample covariance of the residuals
with the explanatory variables. The maximum likelihood estimates are
therefore the values of the β’s that make this covariance zero, that is,
make the residuals uncorrelated with the explanatory variables. This
condition for logit estimates is the same as applies in linear regression
models. For a regression model yn = β  xn + εn , the ordinary least

squares estimates are the values of β that set n (yn − β  xn )xn = 0.


This fact is veriﬁed by solving for β: β = ( n xn xn )−1 ( n xn yn ),
which is the formula for the ordinary least squares estimator. Since
yn − β  xn is the residual in the regression model, the estimates make
the residuals uncorrelated with the explanatory variables.
Under this interpretation, the estimates can be motivated as providing a sample-analog to population characteristics. We have assumed

3.7. ESTIMATION

73

that the explanatory variables are exogenous, meaning that they are
uncorrelated in the population with the model errors. Since the variables and errors are uncorrelated in the population, it makes sense to
choose estimates that make the variables and residuals uncorrelated
in the sample. The estimates do exactly that: they provide a model
that reproduces in the sample the zero covariances that occur in the
population.
Estimators that solve equations of the form (3.13) are called methodof-moments estimators, since they use moment conditions (correlations
in this case) between residuals and variables to deﬁne the estimator.
We will return to these estimators when discussing simulation-assisted
estimation in Chapter 10.
We asserted without proof that (3.13) is the ﬁrst-order condition
for the maximum likelihood estimator of the logit model. We give that
proof now. The log-likelihood function (3.11) can be re-expressed as
yni ln(Pni )

LL(β) =
n

i

n

eβ xni
yni ln(  β  x )
nj
je
i



=

yni (β  xni ) −

=
n



eβ xnj ).

yni ln(
n

i

i

j

The derivative of the log-likelihood function then becomes
dLL(β)
dβ

 
n

=


i yni (β xni )

dβ

 
n

−

n

i

n

i

n

i

n

i

yni
n

yni xni −

=

(

yni xni −

=

i

n

Pnj xnj
j

Pnj xnj )
j

(
n

β  xnj )
je

dβ

yni xni −

=



i yni ln(

yni
i

Pnj xnj )
j

(yni − Pni )xni

=

Setting this derivative to zero gives the ﬁrst-order condition (3.13).

CHAPTER 3. LOGIT

74
Estimation on a subset of alternatives

In some situations, the number of alternatives facing the decisionmaker is so large that estimating model parameters is very expensive
or even impossible. With a logit model, estimation can be performed
on a subset of alternatives without inducing inconsistency. For example, a researcher examining a choice situation that involves 100 alternatives can estimate on a subset of 10 alternatives for each sampled
decision-maker, with the person’s chosen alternative included as well
as 9 alternatives randomly selected from the remaining 99. If all alternatives have the same chance of being selected into the subset, then
estimation proceeds on the subset of alternatives as if it were the full
set. If alternatives have unequal probability of being selected, more
complicated estimation procedures may be required. The procedure is
described as follows.
Suppose that the researcher has used some speciﬁc method for randomly selecting alternatives into the subset that is used in estimation
for each sampled decision-maker. Denote the full set of alternatives as
F and a subset of alternatives as K. Let q(K | i) be the probability
under the researcher’s selection method that subset K is selected given
that the decision-maker chose alternative i. Assuming that the subset
necessarily includes the chosen alternative, q(K | i) = 0 for any K
that does not include i. The probability that person n chooses alternative i from the full set is Pni . Our goal is to derive a formula for
the probability that the person chooses alternative i conditional on the
researcher selecting subset K for him. This conditional probability is
denoted Pn (i | K).
This conditional probability is derived as follows. The joint probability that the researcher selects subset K and the decision-maker
chooses alternative i is P rob(K, i) = q(K | i)Pni . The joint probability
can also be expressed with the opposite conditioning as P rob(K, i) =

Pn (i | K)Q(K) where Q(K) = j∈F Pnj q(K | j) is the probability of
the researcher selecting subset K marginal over all the alternatives that
the person could choose. Equating these two expressions and solving
for Pn (i | K), we have
Pni q(K | i)
j∈F Pnj q(K | j)

Pn (i | K) =



=



eVni q(K | i)
Vnj q(K | j)
j∈F e

3.7. ESTIMATION

75
=

eVni q(K | i)
Vnk q(K | j)
k∈K e



(3.15)

where the second line has canceled out the denominators of Pni and
Pnj ∀ j, and the third equality uses the fact that q(K | j) = 0 for any
j not in K.
Suppose that the researcher has designed the selection procedure
such that q(K | j) is the same for all j ∈ K. This property occurs if,
for example, the researcher assigns an equal probability of selection to
all non-chosen alternatives, such that the probability of selecting j into
the subset when i is chosen by the decision-maker is the same as for
selecting i into the subset when j is chosen. McFadden (1978) calls this
the “uniform conditioning property” since the subset of alternatives
has a uniform (equal) probability of being selected conditional on any of
its members being chosen by the decision-maker. When this property
is satisﬁed, q(K | j) cancels out of the above expression, and the
probability becomes
eVni
Vnj
j∈K e

Pn (i | K) = 

which is simply the logit formula for a person who faces the alternatives
in subset K.
The conditional likelihood function under the uniform conditioning
property is
yni ln 

CLL(β) =
n i∈Kn

eVni
Vnj
j∈Kn e

where Kn is the subset selected for person n. This function is the same
as the log-likelihood function given in (3.11) except that the subset of
alternatives Kn replaces, for each sampled person, the complete set.
Maximization of CLL provides a consistent estimator of β. However,
since information is excluded from CLL that LL incorporates (i.e.,
information on alternatives not in each subset), the estimator based
on CLL is not eﬃcient.
Suppose that the researcher designs a selection process that does
not exhibit the uniform conditioning property. In this case, the probability q(K | i) can be incorporated into the model as a separate variable. The expression in (3.15) can be re-written as
Pn (i | K) = 

eVni +ln(q(K|i))
.
Vnj +ln(q(K|j))
j∈K e

CHAPTER 3. LOGIT

76

A variable znj calculated as ln(q(Kn | j)) is added to the representative
utility of each alternative. The coeﬃcient of this variable is constrained
to 1 in estimation.
The question arises, why would a researcher ever want to design
a selection procedure that does not satisfy the uniform conditioning
property, since satisfying the property makes estimation so straightforward? An illustration of the potential beneﬁt of non-uniform conditioning is provided by Train, McFadden and Ben-Akiva (1987) in
their study of telecommunications demand. The choice situation in
their application included an enormous number of alternatives representing portfolios of calls by time of day, distance and duration. The
vast majority of alternatives were hardly ever chosen by anyone in the
population. If alternatives had been selected with equal probability for
each alternative, it was quite likely than the resulting subsets would
consist nearly entirely of alternatives that were hardly ever chosen,
coupled with the person’s chosen alternative. Comparing a person’s
chosen alternative to a group of highly undesirable alternatives provides little information about the reasons for a person’s choice. To
avoid this potential problem, alternatives were selected in proportion
to the shares for the alternatives in the population (or, to be precise, estimates of the population shares). This procedure increased the
chance that relatively desirable alternatives would be in each subset of
alternatives that was used in estimation.

3.7.2

Choice-based samples

In some situations, a sample drawn on the basis of exogenous factors
would include few people who have chosen particular alternatives. For
example, in the choice of water heaters, a random sample of households
in most areas would include only a small number who had chosen solar
water heating systems. If the researcher is particularly interested in
factors that aﬀect the penetration of solar devices, a random sample
would need to be very large to assure a reasonable number of households with solar heat.
In situations such as these, the researcher might instead select the
sample, or part of the sample, on the basis of the choice being analyzed. For example, the researcher examining water heaters might
supplement a random sample of households with households that are
known (perhaps through sales records at stores if the researcher has

3.7. ESTIMATION

77

access to these records) to have recently installed solar water heaters.
Samples selected on the basis of decision-makers’ choices can be
purely choice-based or a hybrid of choice-based and exogenous. In
a purely choice-based sample, the population is divided into those
that choose each alternative and decision-makers are drawn randomly
within each group, though at diﬀerent rates. For example, a researcher
who is examining the choice of home location and is interested in identifying the factors that contribute to people choosing one particular
community might draw randomly from within that community at the
rate of one out of L households, and draw randomly from all other
communities at a rate of one out of M , where M is larger than L.
This procedure assures that the researcher has an adequate number of
people in the sample from the area of interest. A hybrid sample is like
the one drawn by the researcher interested in solar water heating, in
which an exogenous sample is supplemented with a sample drawn on
the basis of the households’ choices.
Estimation of model parameters with samples drawn at least partially on the basis of the decision-maker’s choice is fairly complex in
general, and varies with the exact form of the sampling procedure.
For interested readers, Ben-Akiva and Lerman (1985, pp.234-244) provide a useful discussion. One result is particularly signiﬁcant, since
it allows researchers to estimate logit models on choice-based samples
without becoming involved in complex estimation procedures. This
result, due to Manski and Lerman (1977), can be stated as follows. If
the researcher is using a purely choice-based sample and includes an
alternative-speciﬁc constant in the representative utility for each alternative, then estimating a logit model as if the sample were exogenous
produces consistent estimates for all the model parameters except the
alternative-speciﬁc constants. Furthermore, these constants are biased
by a known factor and can therefore be adjusted so that the adjusted
constants are consistent. In particular, the expectation of the estimated constant for alternative j, labeled α̂j , is related to the true
constant αj∗ ,
E(α̂j ) = αj∗ − ln(Aj /Sj )
where Aj is the share of decision-makers in the population who chose
alternative j and Sj is the share in the choice-based sample who chose
alternative j. Consequently, if Aj is known (that is, if population
shares are known for each alternative), then a consistent estimate of
the alternative-speciﬁc constant is the constant α̂j that is estimated

CHAPTER 3. LOGIT

78

on the choice-based sample plus the log of the ratio of the population
share to the sample share.

3.8

Goodness of Fit and Hypothesis Testing

We discuss goodness of ﬁt and hypothesis testing in the context of logit
models, where the log likelihood function is calculated exactly. The
concepts apply to other models, with appropriate adjustment for simulation variance, when the log likelihood function is simulated rather
than calculated exactly.

3.8.1

Goodness of ﬁt

A statistic called the “likelihood ratio index” is often used with discrete
choice models to measure how well the models ﬁt the data. Stated
more precisely, the statistic measures how well the model, with its
estimated parameters, performs compared with a model in which all
the parameters are zero (which is usually equivalent to having no model
at all). This comparison is made on the basis of the log likelihood
function, evaluated at both the estimated parameters and at zero for
all parameters.
The likelihood ratio index is deﬁned as
ρ=1−

LL(β̂)
,
LL(0)

where LL(β̂) is the value of the log likelihood function at the estimated
parameters and LL(0) is its value when all the parameters are set
equal to zero. If the estimated parameters do no better, in terms of
the likelihood function, than zero parameters (that is, if the estimated
model is no better than no model), then LL(β̂) = LL(0) and so ρ = 0.
This is the lowest value that ρ can take (since if LL(β̂) is less than
LL(0), then β̂ would not be the maximum likelihood estimate).
At the other extreme, suppose the estimated model were so good
that each sampled decision-maker’s choice could be predicted perfectly.
In this case, the likelihood function at the estimated parameters would
be one, since the probability of observing the choices that were actually made is one. And, since the log of one is zero, the log likelihood
function would be zero at the estimated parameters. With LL(β̂) = 0,

3.8. GOODNESS OF FIT AND HYPOTHESIS TESTING

79

ρ = 1. This is the highest value that ρ can take. In summary, the likelihood ratio index ranges from zero, when the estimated parameters are
no better than zero parameters, to one, when the estimated parameters
perfectly predict the choices of the sampled decision-makers.
It is important to note that the likelihood ratio index is not at all
similar in its interpretation to the R-squared used in regression, despite
both statistics having the same range. R-squared indicates the percent
of the variation in the dependent variable that is ”explained” by the
estimated model. The likelihood ratio has no intuitively interpretable
meaning for values between the extremes of zero and one. It is the percent increase in the log likelihood function above the value taken at zero
parameters (since ρ = 1 − (LL(β̂)/LL(0)) = (LL(0) − LL(β̂))/LL(0).)
However, the meaning of such a percent increase is not clear. In comparing two models estimated on the same data and with the same set
of alternatives (such that LL(0) is the same for both models), it is usually valid to say that the model with the higher ρ ﬁts the data better.
But this is saying no more than that increasing the value of the log
likelihood function is preferable. Two models estimated on samples
that are not identical or with a diﬀerent set of alternatives for any
sampled decision maker cannot be compared via their likelihood ratio
index values.
Another goodness-of-ﬁt statistic that is sometimes used, but should
actually be avoided, is the “percent correctly predicted.” This statistic
is calculated by identifying for each sampled decision-maker the alternative with the highest probability, based on the estimated model, and
determining whether or not this was the alternative that the decisionmaker actually chose. The percent of sampled decision-makers for
which the highest probability alternative and the chosen alternative
are the same is called the percent correctly predicted.
This statistic incorporates a notion that is opposed to the meaning
of probabilities and the purpose of specifying choice probabilities. The
statistic is based on the idea that the decision-maker is predicted by
the researcher to choose the alternative for which the model gives the
highest probability. However, as discussed in the derivation of choice
probabilities in Chapter 2, the researcher does not have enough information to predict the decision-maker’s choice. The researcher has only
enough information to state the probability that the decision-maker
will choose each alternative. In stating choice probabilities, the researcher is saying that if the choice situation were repeated numerous

CHAPTER 3. LOGIT

80

times (or faced by numerous people with the same attributes), each
alternative would be chosen a certain proportion of the time. This is
quite diﬀerent from saying that the alternative with the highest probability will be chosen each time.
An example might be useful. Suppose an estimated model predicts
choice probabilities of .75 and .25 in a two-alternative situation. Those
probabilities mean that if 100 people faced the representative utilities
that gave these probabilities (or one person faced these representative
utilities 100 times), the researcher’s best prediction of how many people would choose each alternative are 75 and 25. However, the percent
correctly predicted statistic is based on the notion that the best prediction for each person is the alternative with the highest probability.
This notion would predict that one alternative would be chosen by all
100 people while the other alternative would never be chosen. The
procedure misses the point of probabilities, gives obviously inaccurate
markets shares, and seems to imply that the researcher has perfect
information.

3.8.2

Hypothesis testing

As with regressions, standard t-statistics are used to test hypotheses
about individual parameters in discrete choice models, such as whether
the parameter is zero. For more complex hypotheses, a likelihood ratio
test can nearly always be used, as follows. Consider a null hypothesis
H that can be expressed as constraints on the values of the parameters.
Two of the most common hypotheses are (1) several parameters are
zero, and (2) two or more parameters are equal to each other. The
constrained maximum likelihood estimate of the parameters (labeled
β̂ H ) is that value of β that gives the highest value of LL without
violating the constraints of the null hypothesis H. Deﬁne the ratio of
likelihoods, R = L(β̂ H )/L(β̂) where β̂ H is the (constrained) maximum
value of the likelihood function (not logged) under the null hypothesis
H and β̂ is the unconstrained maximum of the likelihood function.
As in likelihood ratio tests for models other than those of discrete
choice, the test statistic deﬁned as −2logR is distributed chi-squared
with degrees of freedom equal to the number of restrictions implied
by the null hypothesis. Therefore, the test statistic is −2(LL(β̂ H ) −
LL(β̂)). Since the log likelihood is always negative, this is simply two
times the (magnitude of the) diﬀerence between the constrained and

3.9. CASE STUDY

81

unconstrained maximums of the log likelihood function. If this value
exceeds the critical value of chi-squared with the appropriate degrees
of freedom, then the null hypothesis is rejected.
Examples
Null Hypothesis I: The Coeﬃcients of Several Explanatory
Variables are Zero
To test this hypothesis, estimate the model twice: once with these
explanatory variables included and a second time without them (since
excluding the variables forces their coeﬃcients to be zero). Observe
the maximum value of the log likelihood function for each estimation;
two times the diﬀerence in these maximum values is the value of the
test statistic. Compare the test statistic with the critical value of chisquared with degrees of freedom equal to the number of explanatory
variables excluded from the second estimation.
Null Hypothesis II: The Coeﬃcients of the First Two Variables are the Same
To test this hypothesis, estimate the model twice: once with each of the
explanatory variables entered separately including the ﬁrst two; then
with the ﬁrst two variables replaced by one variable that is the sum of
the two variables (since summing the variables forces their coeﬃcients
to be equal). Observe the maximum value of the log likelihood function
for each of the estimations. Multiply the diﬀerence in these maximum
values by two and compare this ﬁgure with the critical value of chisquared with one degree of freedom.

3.9

Case Study: Forecasting for a new transit
system

One of the earliest applications of logit models, and a prominent test
of their capabilities, arose in the mid 1970’s in the San Francisco Bay
Area. A new rail system, called the Bay Area Rapid Transit (BART),
had been built. Daniel McFadden obtained a grant from the National
Science Foundation to apply logit models to commuters’ mode choices
in the Bay Area and to use the models to predict BART ridership. I
was lucky enough to serve as his research assistant on this project. A

82

CHAPTER 3. LOGIT

sample of commuters was taken before BART was open for service.
Mode choice models were estimated on this sample. These estimates
provided important information on the factors that enter commuters’
decisions, including their value of time savings. The models were then
used to forecast the choices that the sampled commuters would make
once BART became available. After BART had opened, the commuters were re-contacted and their mode choices were observed. The
predicted share taking BART was compared with the observed share.
The models predicted quite well, far more accurately than the procedures used by the BART consultants, who had not used discrete choice
models.
The project team collected data on 771 commuters before BART
was opened. Four modes were considered to be available for the trip
to work: (1) driving a car by oneself, (2) taking the bus and walking
to the bus stop, (3) taking the bus and driving to the bus stop, and
(4) carpool. The time and cost of travel on each mode was determined
for each commuter, based on the location of the person’s home and
work. Travel time was diﬀerentiated as walk time (for the bus/walk
mode), wait time (for both bus modes), and on-vehicle time (for all the
modes.) Characteristics of the commuter were also collected, including
income, household size, number of cars and drivers in the household,
and whether the commuter was the head of the household. A logit
model with linear-in-parameters utility was estimated on these data.
The estimated model is shown in Table 3.1, which is reproduced
from Train (1978). The cost of travel was divided by the commuter’s
wage to reﬂect the expectation that workers with lower wages are more
concerned about cost than higher-paid workers. On-vehicle time enters
separately for car and bus travel to indicate that commuters might ﬁnd
time spent on the bus to be more, or less, bothersome than time spent
driving in a car. Bus travel often involves transfers, and these transfers
can be onerous for travelers. The model therefore includes the number
of transfers and the expected wait time at the transfers. The headway
(i.e., the time between scheduled buses) for the ﬁrst bus line that the
commuter would take is included as a measure of the maximum amount
of time that the person would need to wait for this bus.
The estimated coeﬃcients of cost and the various time components
provide information on the value of time. By deﬁnition, the value of
time is the extra cost that a person would be willing to incur to save
time. Utility takes the form: Unj = αcnj /wn + βtnj + . . . where c is

3.9. CASE STUDY

83

Table 3.1: Logit Model of Work Trip Mode Choice
Modes: 1. Auto alone, 2. Bus with walk access, 3. Bus with auto access, 4. Carpool
Explanatory variable
Coeﬃcient t-statistic
(Variable enters modes in parentheses and is zero in other modes.)
Cost divided by post-tax wage, in cents per minute (1-4)
-.0284
4.31
Auto on-vehicle time, in minutes (1,3,4)
-.0644
5.65
Transit on-vehicle time, in minutes (2,3)
-.0259
2.94
Walk time, in minutes (2,3)
-.0689
5.28
Transfer wait time, in minutes (2,3)
-.0538
2.30
Number of transfers (2,3)
-.1050
0.78
Headway of ﬁrst bus, in minutes (2,3)
-.0318
3.18
Family income with ceiling of 7500 (1)
.00000454
0.05
Family income minus 7500 with ﬂoor of 0 and ceiling of 3000 (1)
-.0000572
0.43
Family income minus 10,500 with ﬂoor of 0 and ceiling of 5000 (1)
-.0000543
0.91
Number of drivers in household (1)
1.02
4.81
Number of drivers in household (3)
.990
3.29
Number of drivers in household (4)
.872
4.25
Dummy if worker is head of household (1)
.627
3.37
Employment density at work location (1)
-.0016
2.27
Home location in or near central business district (1)
-.502
4.18
Autos per driver with a ceiling of one (1)
5.00
9.65
Autos per driver with a ceiling of one (3)
2.33
2.74
Autos per driver with a ceiling of one (4)
2.38
5.28
Auto alone dummy (1)
-5.26
5.93
Bus with auto access dummy (1)
-5.49
5.33
Carpool dummy (1)
-3.84
6.36
Likelihood ratio index
0.4426
Log likelihood at convergence
-595.8
Number of observations
771
Value of time saved as a percent of wage:
t-statistic
Auto on-vehicle time
227
3.20
Transit on-vehicle time
91
2.43
Walk time
243
3.10
Transfer wait time
190
2.01

84

CHAPTER 3. LOGIT

cost and t is time. The total derivative with respect to changes in time
and cost is dUnj = α/wn dcnj + βdtnj , which we set to zero and solve
for dc/dt to ﬁnd the change in cost that keeps utility unchanged for
a change in time: dc/dt = −(β/α)wn . The value of time is therefore
β/α proportion of the person’s wage. The estimated values of time are
reported at the bottom of Table 3.1. Time saved from riding on the
bus is valued at 91 percent of wage ((−.0259/ − .0284) · 100), while
time saved from driving in a car is worth more than twice as much:
227 percent of wage. This diﬀerence suggests that commuters consider
the hassles of driving to be considerably more onerous than riding the
bus, when evaluated on a per-minute basis. Commuters apparently
choose cars not because they like driving per se but because driving is
usually quicker. Walking is considered more bothersome than waiting
for a bus (243 percent of wage versus 190 percent), and waiting for a
bus is more bothersome than riding the bus.
Income enters the representative utility of the auto-alone alternative. It enters in a piece-wise linear fashion to allow for the possibility
that additional income has a diﬀerent impact depending on the overall level of income. None of the income variables enters signiﬁcantly.
Apparently dividing travel cost by wage picks up whatever eﬀect income might have on the mode choice of a commuter. That is: higher
wages induce the commuter to be less concerned about travel costs but
does not induce a predilection for driving beyond the impact through
cost. The number of people and the number of vehicles per driver in
the household have a signiﬁcant impact on mode choice, as expected.
Alternative-speciﬁc constants are included, with the constant for the
bus/walk alternative normalized to zero.
The model in Table 3.1 was used to predict the mode choices of
the commuters after BART was open for service. The choice set was
considered to be the four modes listed above plus two BART modes,
diﬀerentiated by whether the person takes the bus or drives to the
BART station. Table 3.2 presents the forecasted and actual shares
for each mode. BART demand was forecast to be 6.3 percent compared with an actual share of 6.2 percent. This close correspondence
is remarkable.
The ﬁgures in Table 3.2 tend to mask several complications that
arose in the forecasting. For example, walking to the BART station
was originally included as a separate mode. The model forecasted this
option very poorly, over-predicting the number of people who would

3.10. DERIVATION OF LOGIT PROBABILITIES

85

Table 3.2: Predictions for after BART opened
Actual share Predicted share
Auto alone
59.90
55.84
Bus with walk access
10.78
12.51
Bus with auto access
1.426
2.411
BART with bus access
0.951
1.053
BART with auto access
5.230
5.286
Carpool
21.71
22.89
walk to BART by a factor of twelve. The problem was investigated and
found to be primarily due to diﬀerences in the experience of walking
to BART stations compared to walking to the bus, given the neighborhoods in which the BART stations are located. These issues are
discussed at greater length by McFadden et al. (1977).

3.10

Derivation of Logit Probabilities

It was stated without proof in section (3.1) that if the unobserved component of utility is distributed iid extreme value for each alternative,
then the choice probabilities take the form of equation (3.6). We now
derive this result. From (3.5) we have
 ∞

Pni =




−e−(s+Vni −Vnj )  −s −e−s



s=−∞

e

e

e

ds

j=i

where s is εni . Our task is to evaluate this integral. Noting that
Vni − Vni = 0 and then collecting terms in the exponent of e, we have:
 ∞

Pni =

s=−∞

 ∞

=
s=−∞

 ∞

=
s=−∞





−(s+Vni −Vnj )

e−e


j





e−(s+Vni −Vnj )  e−s ds

exp −


 e−s ds

j



exp −e−s

e−(Vni −Vnj )  e−s ds
j

Deﬁne t = exp(−s) such that −exp(−s)ds = dt. Note that as s approaches inﬁnity, t approaches zero, and as s approaches negative in-

CHAPTER 3. LOGIT

86

ﬁnity, t becomes inﬁnitely large. Using this new term,
 0

Pni =

∞



=
=
as required.

0

e−(Vni −Vnj )  (−dt)

exp −t

 ∞

=


j





e−(Vni −Vnj )  dt

exp −t


exp −t
−





j

−(Vni −Vnj )
je

−(Vni −Vnj )
je



∞





eVni
 −(V −V ) =  Vnj ,
ni
nj
je
je
1

0

Chapter 4

GEV
4.1

Introduction

The standard logit model exhibits the independence from irrelevant
alternatives (IIA) property, which implies proportional substitution
across alternatives. As we discussed in Chapter 3, this property can
be seen either as a restriction imposed by the model or as the natural
outcome of a well-speciﬁed model that captures all sources of correlation over alternatives into representative utility such that only white
noise remains. Often the researcher is unable to capture all sources of
correlation explicitly, such that the unobserved portions of utility are
correlated and IIA does not hold. In these cases, a more general model
than standard logit is needed.
Generalized extreme value (GEV) models constitute a large class
of models that exhibit a variety of substitution patterns. The unifying
attribute of these models is that the unobserved portions of utility for
all alternatives are jointly distributed as a generalized extreme value.
This distribution allows for correlations over alternatives and, as its
name implies, is a generalization of the univariate extreme value distribution that is used for standard logit models. When all correlations
are zero, the generalized extreme value distribution becomes the product of independent extreme value distributions and the GEV model
becomes standard logit. The class therefore includes logit but also includes a variety of other models. Hypothesis tests on the correlations
within a GEV model can be used to examine whether the correlations
are zero, which is equivalent to testing whether standard logit provides
an accurate representation of the substitution patterns.
87

CHAPTER 4. GEV

88

The most widely used member of the GEV family is called “nested
logit.” This model has been applied by many researchers in a variety
of situations, including energy, transportation, housing, telecommunications and a host of other ﬁelds; see, for example, Ben-Akiva (1972),
Train (1986, Ch. 8), Train, McFadden and Ben-Akiva (1987), Forinash and Koppelman (1993), and Lee (1999). Its functional form is
relatively simple compared to other types of GEV models, and it provides a rich set of possible substitution patterns. Sections 4.2 and 4.3
describe the speciﬁcation and estimation of nested logit models. This
description is useful in itself, since nested logit models are so prominent, but also as background for understanding more complex GEV
models. In section 4.4, we turn to other GEV models that researchers
have implemented, with special emphasis on one of the most promising
of these, namely, the paired combinatorial logit (PCL) and generalized
nested logit (GNL). The chapter’s ﬁnal section describes the entire
class of GEV models and how new speciﬁcations within the class are
generated.
Only a small portion of the possible models within the GEV class
have ever been implemented. This means that the full capabilities of
this class have not yet been fully exploited and that new research in this
area has the potential to ﬁnd even more powerful models than those
already used. An example of this potential is evidenced by Karlstrom
(2001), who speciﬁed a GEV model of a diﬀerent form than had ever
been used before and found that it ﬁt his data better than previously
implemented types of GEV models. GEV models have the advantage
that the choice probabilities usually take a closed form such that they
can be estimated without resorting to simulation. For this reason
alone, GEV models will continue to be the source of new and powerful
speciﬁcations to meet researchers’ needs.

4.2

Nested logit

4.2.1

Substitution patterns

A nested logit model is appropriate when the set of alternatives faced
by a decision-maker can be partitioned into subsets, called “nests,”
in such a way that the following properties hold. (1) For any two
alternatives that are in the same nest, the ratio of probabilities is
independent of the attributes or existence of all other alternatives.

4.2. NESTED LOGIT

89

That is, IIA holds within each nest. (2) For any two alternatives in
diﬀerent nests, the ratio of probabilities can depend on the attributes
of other alternatives in the two nests. IIA does not hold in general for
alternatives in diﬀerent nests.
An example can best explain whether a set of alternatives can be
so partitioned. Suppose the set of alternatives available to a worker
for his commute to work consists of driving an auto alone, carpooling, taking the bus, and taking rail. If any alternative were removed,
the probabilities of the other alternatives would increase (e.g., if the
worker’s car was being repaired such that he could not drive to work
by himself, then the probability of carpool, bus, and rail). The relevant question in partitioning these alternatives is: by what proportion
would each probability increase when an alternative is removed? Suppose the changes in probabilities occur as set forth in Table 4.1. Note
that the probabilities for bus and rail always rise by the same proportion whenever one of the other alternatives is removed. IIA therefore
holds between these two alternatives. Let us put these alternatives in
a nest and call the nest “transit.” Similarly, the probability of auto
alone and carpool rise by the same proportion whenever one of the
other alternatives is removed. IIA holds between these two alternatives, and so we put them into a nest called “auto.” IIA does not
hold between either of the auto alternatives compared with either of
the transit alternatives. For example, when the auto alone alternative
is removed, the probability of carpool rises proportionately more than
the probability of bus or rail. With our two nests, we can state the
patterns of substitution succinctly as: IIA holds within each nest but
not across nests. A nested logit model with the two auto alternatives in
one nest and the two transit alternatives in another nest is appropriate
to represent this situation.
Table 4.1: Example of IIA holding within nests of alternatives.
Change in probabilities when one alternative is removed.
Original Alternative removed:
Auto alone
Carpool
Bus
Auto alone
.40
.45 (+12.5%) .52 (+30%)
Carpool
.10
.20 (+100%) .13 (+30%)
.30
.48 (+60%)
.33 (+10%)
Bus
Rail
.20
.32 (+60%)
.22 (+10%)
.35 (+70%)

Rail
.48 (+20%)
.12 (+20%)
.40 (+33%)
-

CHAPTER 4. GEV

90

A convenient way to picture the substitution patterns is with a tree
diagram. In such a tree, each branch denotes a subset of alternatives
within which IIA holds, and every leaf on each branch denotes an
alternative. For example, the tree diagram for the worker’s choice
of mode described above is given in Figure 4.1. The (upside down)
tree consists of two branches, labeled “auto” and “transit,” for the
two subsets of alternatives, and each of the branches contains two
twigs for the two alternatives with in the subset. There is proportional
substitution across twigs within a branch but not across branches.

Auto
alone

Auto

Transit

Carpool

Bus

Rail

Figure 4.1: Tree diagram for mode choice.

4.2.2

Choice probabilities

Daly and Zachary (1978), McFadden (1978), and Williams (1977)
showed, independently and using diﬀerent proofs, that the nested logit
model is consistent with utility maximization. Let the set of alternatives j be partitioned into K non-overlapping subsets denoted B1 , B2 , . . . , BK
and called nests. The utility that person n obtains from alternative
j in nest Bk is denoted, as usual, as Unj = Vnj + εnj , where Vnj is
observed by the researcher and εnj is a random variable whole value
is not observed by the researcher. The nested logit model is obtained
by assuming that the vector of unobserved utility, εn = εn1 , . . . , εnJ 

4.2. NESTED LOGIT

91

has cumulative distribution:



K

exp −

λk 

e−εnj /λk   .




(4.1)

j∈Bk

k=1

This distribution is a type of generalized extreme value (GEV) distribution. It is a generalization of the distribution that gives rise to
the logit model. For logit, each εnj is independent with a univariate
extreme value distribution. For this GEV, the marginal distribution
of each εnj is univariate extreme value. However, the εnj ’s are correlated within nests. For any two alternatives j and m in nest Bk , εnj
is correlated with εnm . For any two alternatives in diﬀerent nests, the
unobserved portion of utility is still uncorrelated: Cov(εnj , εnm ) = 0
for any j ∈ Bk and m ∈ B with = k.
The parameter λk is a measure of the degree of independence in
unobserved utility among the alternatives in nest k. A higher value
of λk means greater independence and less correlation. The statistic
(1 − λk ) is a measure of correlation, in the sense that as λk rises,
indicating less correlation, this statistic drops. As McFadden (1978)
points out, the correlation is actually more complex than (1 − λk ),
but (1 − λk ) can be used as an indication of correlation. A value
of λk = 1 indicates complete independence within nest k, that is,
no correlation. When λk = 1 for all k, representing independence
among all the alternatives in all nests, the GEV distribution becomes
the product of independent extreme value terms, whose distribution
is given in (3.2). In this case, the nested logit model reduces to the
standard logit model.
As shown by the authors cited above, this distribution for the unobserved components of utility gives rise to the following choice probability for alternative i ∈ Bk :
eVni /λk
Pni =



Vnj /λk
j∈Bk e

K 
=1

λk −1

Vnj /λ
j∈B e

λ

.

(4.2)

We can use this formula to show that IIA holds within each subset
of alternatives but not across subsets. Consider alternatives i ∈ Bk and
m ∈ B . Since the denominator of (4.2) is the same for all alternatives,

CHAPTER 4. GEV

92

the ratio of probabilities is the ratio of numerators:


λk −1

Vnj /λk
eVni /λk
j∈Bk e
Pni
=

λ −1 .
Pnm
eVnm /λ
eVnj /λ
j∈B

If k = (i.e., i and m are in the same nest) then the terms in parentheses cancel out and we have
eVni /λk
Pni
= V /λ
Pnm
e nm 
This ratio is independent of all other alternatives. For k = (i.e., i and
m are in diﬀerent nests), the terms in parentheses do not cancel out.
The ratio of probabilities depends on the attributes of all alternatives
in the nests that contain i and m. Note, however, that the ratio does
not depend on the attributes of alternatives in nests other those containing i and m. A form of IIA holds, therefore, even for alternatives
in diﬀerent nests. This form of IIA can be loosely described as “independence from irrelevant nests” or IIN. With a nested logit model, IIA
holds over alternatives in each nest and IIN holds over alternatives in
diﬀerent nests. This property of nested logit models is reinforced in
the next section when we decompose the nested logit probability into
two standard logit probabilities.
When λk = 1 for all k (and hence 1 − λk = 0), indicating no correlation among the unobserved components of utility for alternatives
within a nest, the choice probabilities become simply logit. The nested
logit model is a generalization of logit that allows for a particular pattern of correlation in unobserved utility.
The parameter λk can diﬀer over nests, reﬂecting diﬀerent correlation among unobserved factors within each nest. The researcher can
constrain the λk ’s to be the same for all (or some) nests, indicating
that the correlation is the same in each of these nests. Hypothesis
testing can be used to determine whether constraints on the λk ’s are
reasonable. Testing the constraint λk = 1 ∀ k is equivalent to testing
whether the standard logit model is a reasonable speciﬁcation against
the more general nested logit. These tests are performed most readily
with the likelihood ratio statistic described in section (3.8.2).
The value of λk must be within a particular range for the model
to be consistent with utility maximizing behavior. If λk ∀ k is between
zero and one, the model is consistent with utility maximization for

4.2. NESTED LOGIT

93

all possible values of the explanatory variables. For λk greater than
one, the model is consistent with utility maximizing behavior for some
range of the explanatory variables but not for all values. Kling and
Herriges (1995) and Herriges and Kling (1996) provide tests of consistency of nested logit with utility maximization when λk > 1, and Train,
McFadden and Ben-Akiva (1987) and Lee (1999) provide examples of
models for which λk > 1. A value of λk below zero is inconsistent
with utility maximization and implies that improving the attributes of
an alternative (such as lowering its price) can decrease the probability of the alternative being chosen. With positive λk , the nested logit
approaches the “elimination by aspects” model of Tversky (1972) as
λk → 0.
In the notation that we have been using, each λk is a ﬁxed parameter, which implies that all decision-makers have the same correlations
among unobserved factors. In reality, correlations might diﬀer over
decision-makers based on their observed characteristics. To accommodate this possibility, each λk can be speciﬁed to be a parametric
function of observed demographics or other variables, as long as the
function maintains a positive value. For example, Bhat (1997) speciﬁes
λ = exp(αzn ), where zn is a vector of characteristics of decision-maker
n and α is a vector of parameters to be estimated along with the parameters that enter representative utility. The exponential transformation
assures that λ is positive.

4.2.3

Decomposition into two logits

Expression (4.2) is not very illuminating as a formula. However, the
choice probabilities can be expressed in an alternative fashion that is
quite simple and readily interpretable. Without loss of generality, the
observed component of utility can be decomposed into two parts: (1) a
part labeled W that is constant for all alternatives within a nest, and
(2) a part labeled Y that varies over alternatives within a nest. Utility
is written as:
Unj = Wnk + Ynj + εnj

(4.3)

for j ∈ Bk , where:
Wnk depends only on variables that describe nest k. These variables
diﬀer over nests but not over alternatives within each nest.

CHAPTER 4. GEV

94

Ynj depends on variables that describe alternative j. These variables
vary over alternatives within nest k.
Note that this decomposition is fully general since for any Wnk , Ynj is
deﬁned as Vnj − Wnk .
With this decomposition of utility, the nested logit probability can
be written as the product of two standard logit probabilities. Let the
probability of choosing alternative i ∈ Bk be expressed as the product
of two probabilities, namely: the probability that an alternative within
nest Bk is chosen and the probability that the alternative i is chosen
given that an alternative in Bk is chosen. This is denoted as
Pni = Pni|Bk PnBk ,
where Pni|Bk is the conditional probability of choosing alternative i
given that an alternative in nest Bk is chosen, and PnBk is the marginal
probability of choosing an alternative in nest Bk (with the marginality
being over all alternatives in Bk .) This equality is exact since any probability can be written as the product of a marginal and a conditional
probability.
The reason for decomposing Pni into a marginal and a conditional
probability is that, with the nested logit formula for Pni , the marginal
and conditional probabilities take the form of logits. In particular, the
marginal and conditional probabilities can be expressed as
eWnk +λk Ink
Wn +λ In
=1 e

(4.4)

eYni /λk
Ynj /λk
j∈Bk e

(4.5)

PnBk

=

K

Pni|Bk

=



where
eYnj /λk

Ink = ln
j∈Bk

The derivation of these expressions from the choice probability (4.2)
simply involves algebraic rearrangement. For interested readers, it is
given in section (4.2.5).
Stated in words, the probability of choosing an alternative in Bk
takes the form of the logit formula, as if it were a model for a choice
among nests. This probability includes variables Wnk that vary over
nests but not over alternatives within each nest. It also includes a

4.2. NESTED LOGIT

95

term labeled Ink whose meaning we elucidate below. The conditional
probability of choosing i given that an alternative in Bk is chosen
is also a logit formula, as if it were a model for the choice among the
alternatives within the nest. This conditional probability includes variables Ynj that vary over alternatives within the nest. Note that these
terms are divided by λk such that, when Ynj is linear in parameters,
the coeﬃcients that enter this conditional probability are the original
coeﬃcients divided by λk . It is customary to refer to the marginal
probability (choice of nest) as the “upper model” and the conditional
probability (choice of alternative within the nest) as the “lower model,”
reﬂecting their relative positions in Figure 4.1.
The term Ink links the upper and lower models by bringing information from the lower model into the upper model. Ben-Akiva (1972)
ﬁrst identiﬁed the correct formula for this link. In particular, Ink is
the log of the denominator of the lower model. This formula has an
important meaning. Recall from the discussion of consumer surplus for
a logit model (section 3.5) that the log of the denominator of the logit
model is the expected utility that the decision-maker obtains from the
choice situation, as shown by Williams (1977) and Small and Rosen
(1981). The same interpretation applies here: λk Ink is the expected
utility that decision-maker n receives from the choice among the alternatives in nest Bk . The formula for expected utility is the same here
as for a logit model because, conditional on the nest, the choice of alternatives within the nest is indeed a logit, as given by equation (4.5).
Ink is often called the ”inclusive value” or ”inclusive utility” of nest
Bk . It is also called the ”log-sum term” because it is the log of a sum
(of exponentiated representative utilities). The term ”inclusive price”
is sometimes used; however the negative of Ink more closely resembles
a price.
The coeﬃcient of Ink in the upper model is λk , which is often called
the log-sum coeﬃcient. As discussed above, λk reﬂects the degree of
independence among the unobserved portions of utility for alternatives in nest Bk , with a lower λk indicating less indendendent (more
correlation.)
It is appropriate that the inclusive value term enters as an explanatory variable in the upper model. Stated loosely, the probability
of choosing nest Bk depends on the expected utility that the person
receives from that nest. This expected utility includes the utility that
he receives no matter which alternative he chooses in the nest, which

CHAPTER 4. GEV

96

is Wnk , plus the expected extra utility that he receives by being able
to choose the best alternative in the nest, which is λk Ink .
Recall that the coeﬃcients that enter the lower model are divided
by λk , as given in equation 4.5. Models have been speciﬁed and estimated without dividing by λk in the lower model. Daly (1987) and
Greene (2000) describes such a model, and the computer software
STATA includes it as their nested logit model in the nlogit command.
The package NLOGIT allows either speciﬁcation. If the coeﬃcients in
the lower model are not divided by λk , the choice probabilities are not
the same as those given in equation 4.2. As shown in the derivation
in section 4.2.5, the division by λk is needed for the product of the
conditional and marginal probabilities to equal the nested logit probabilities given by equation 4.2. However, the fact that the model does
not give the probabilities in equation 4.2 does not necessarily mean that
the model is inappropriate. Koppelman and Wen (1998) and Hensher
and Greene (forthcoming) compare the two approaches (dividing by
λk versus not) and show that the latter model is not consistent with
utility maximization when any coeﬃcients are common across nests
(such as a cost coeﬃcient that is the same for bus and car modes.)
Heiss (2002) points out the converse: if no coeﬃcients are common
over nests, then the latter model is consistent with utility maximization, since the necessary division by λk in each nest is accomplished
implicitly (rather than explicitly) by allowing separate coeﬃcients in
each nests such that the scale of coeﬃcients diﬀers over nests. When
coeﬃcients are common over nests, she found that not dividing by λk
provides counter-intuitive implications.

4.2.4

Estimation

The parameters of a nested model can be estimated by standard maximum likelihood techniques. Substituting the choice probabilities of
expression (4.2) into the log likelihood function gives an explicit function of the parameters of this model. The value of the parameters that
maximizes this function is, under fairly general conditions, consistent
and eﬃcient (Brownstone and Small, 1989).
Computer routines are available in commercial software packages
for estimating nested models by maximum likelihood. Hensher and
Greene (forthcoming) provide a guide for nested logits using available
software. Numerical maximization is sometimes diﬃcult since the log-

4.2. NESTED LOGIT

97

likelihood function is not globally concave and even in concave areas is
not close to a quadratic. The researcher might need to help the routines
by trying diﬀerent algorithms and/or starting values, as discussed in
Chapter 8.
Instead of performing maximum likelihood, nested logit models can
be estimated consistently (but not eﬃciently) in a sequential fashion,
exploiting the fact that the choice probabilities can be decomposed
into marginal and conditional probabilities that are logit. This sequential estimation is performed ”bottom up.” The lower models (for
the choice of alternative within a nest) are estimated ﬁrst. Using the
estimated coeﬃcients, the inclusive value term is calculated for each
lower model. Then the upper model (for choice of nest) is estimated,
with the inclusive value terms entering as explanatory variables.
Sequential estimation creates two diﬃculties that argue against its
use. First, the standard errors of the upper-model parameters are
biased downward, as Amemiya (1978) ﬁrst pointed out. This bias
arises because the variance of the inclusive value estimate that enters
the upper model is not incorporated into the calculation of standard
errors. With downwardly biased standard errors, smaller conﬁdence
bounds and larger t-statistics are estimated for the parameters than
are true, and the upper model will appear to be better than it actually
is. Ben-Akiva and Lerman (1985, p. 298) give a procedure for adjusting
the standard errors to eliminate the bias.
Second, it is usually the case that some parameters appear in several submodels. Estimating the various upper and lower models separately provides separate estimations of whatever common parameters
appear in the model. Simultaneous estimation by maximum likelihood
assures that the common parameters are constrained to be the same
wherever they appear in the model.
These two complications are symptoms of a more general circumstance, namely, that sequential estimation of nested logit models, while
consistent, is not as eﬃcient as simultaneous estimation by maximum
likelihood. With simultaneous estimation, all information is utilized
in the estimation of each parameter, and parameters that are common across components are necessarily constrained to be equal. Since
commercial software is available for simultaneous estimation, there is
little reason to estimate a nested logit sequentially. If problems arise
in simultaneous estimation, then the researcher might ﬁnd it useful to
estimate the model sequentially and then use the sequential estimates

CHAPTER 4. GEV

98

as starting values in the simultaneous estimation. The main value of
the decomposition of the nested logit into its upper and lower components comes not in its use as a estimation tool but rather as a heuristic
device: the decomposition helps greatly in understanding the meaning
and structure of the nested logit model.

4.2.5

Equivalence of nested logit formulas

We asserted in section (4.2.3) that the product of the marginal and
conditional probabilities in (4.4) and (4.5) equals the joint probability
in (4.2). We now verify this assertion.
eVni /λk
Pni =



K 
=1

=

=

=

Vnj /λk
j∈Bk e





λk −1

Vnj /λ
j∈B e



eVni /λk

λ

by eq (4.2)

Vnj /λk
j∈Bk e

λk

λ
Vnj /λk K 
Vnj /λ 
j∈Bk e
e
=1
j∈B

e(Wnk +Yni )/λk



(Wnk +Ynj )/λk
j∈Bk e

λk

λ
(Wnk +Ynj )/λk K 
(Wn +Ynj )/λ 
j∈Bk e
=1
j∈B e

eWnk /λk eYni /λk
eWnk /λk



eWnk



Ynj /λk
j∈Bk e

using (4.3)

λk


λ
Ynj /λk K
Ynj /λ 
Wn
j∈Bk e
=1 e
j∈B e

eYni /λk
eWnk +λk Ink

K
Ynj /λk
Wn +λ In
j∈Bk e
=1 e
= Pni|Bk PnBk .
=



where the next to last equality is because Ink = ln
recognizing that ex bc = ex+cln(b) .

4.3



Ynj /λk ,
j∈Bk e

Three-Level Nested Logit

The nested logit model that we have discussed up this this point is
called a two-level nested logit model because there are two levels of
modeling: the marginal probabilities (upper model) and the conditional probabilities (lower models.) In the case of the mode choice,

4.3. THREE-LEVEL NESTED LOGIT

99

the two levels are the marginal model of auto versus transit and the
conditional models of type of auto or transit (auto alone or carpool
given auto, and bus or rail given transit).
In some situations, three- or higher level nested logit models are
appropriate. Three-level models are obtained by partitioning the set of
alternatives into nests and then partitioning each nest into subnests.
The probability formula is a generalization of (4.2) with extra sums
for the subnests within the sums for nests. See McFadden (1978) or
Ben-Akiva and Lerman (1985) for the formula.
As with a two-level nested logit, the choice probabilities for a threelevel model can be expressed as a series of logits. The top model
describes the choice of nest; the middle models describe the choice of
subnest within each nest; and the bottom models describe the choice of
alternative within each subnest. The top model includes an inclusive
value term for each nest. This term represents the expected utility
that the decision-maker can obtain from the subnests within the nest.
It is calculated as the log of the denominator of the middle model
for that nest. Similarly, the middle models include an inclusive value
term for each subnest that represents the expected utility that the
decision-maker can obtain from the alternatives within the subnest. It
is calculated as the log of the denominator of the bottom model for
the subnest.
As an example, consider a household’s choice of housing unit within
a metropolitan area. The household has a choice among all the available housing units in the city. The housing units are available in diﬀerent neighborhoods in the city and with diﬀerent numbers of bedrooms.
It is reasonable to assume that there are unobserved factors that are
common to all units in the same neighborhood, such as the proximity to shopping and entertainment. The unobserved portion of utility
is therefore expected to be correlated over all units in a given neighborhood. There are also unobserved factors that are common to all
units with the same number of bedrooms, such as the convenience of
working at home. We therefore expect the unobserved utility to be
even more highly correlated among units of the same size in the same
neighborhood than between units of diﬀerent size in the same neighborhood. This pattern of correlation can be represented by nesting
the units by neighborhood and then subnesting them by number of
bedrooms. A tree diagram depicting this situation is given in Figure
4.2 for San Francisco. There are three levels of submodels: the proba-

CHAPTER 4. GEV

100

bility for choice of neighborhood, the probability for choice of number
of bedrooms given the neighborhood, and the choice of unit given the
neighborhood and number of bedrooms.

Nob
Hill

Neighborhood

Number of
bedrooms

1

2

Haight
Ashbury

3+

1

2

3+

Mission
District

Telegraph
Hill

1

2

3+

1

2

3+

Housing unit

Figure 4.2: Three-level nested logit.
A nested logit model with this nesting structure embodies IIA in
the following ways. (1) The ratio of probabilities of two housing units
in the same neighborhood and with the same number of bedrooms is
independent of the characteristics of all other units. For example, lowering the price of a two-bedroom apartment in Paciﬁc Heights draws
proportionately from all one-bedroom units on Russian Hill. (2) The
ratio of probabilities of two housing units in the same neighborhood
but with diﬀerent numbers of bedrooms is independent of the characteristics of units in other neighborhoods but depends on the characteristics of units in the same neighborhood that have the same number
of bedrooms as either of these units. Lowering the price of a twobedroom apartment in Paciﬁc Heights draws proportionately from oneand two-bedroom units on Russian Hill, but draws disproportionately
from two-bedroom units in Paciﬁc Heights relative to one-bedroom
units in Paciﬁc Heights. (3) The ratio of probabilities of two housing
units in diﬀerent neighborhoods depends on the characteristics of all
the other housing units in those neighborhoods but not on the characteristics of units in other neighborhoods. Lowering the price of a
two-bedroom apartment in Paciﬁc Heights draws proportionately from
all units outside of Paciﬁc Heights but draws disproportionately from

4.4. OVERLAPPING NESTS

101

units in Paciﬁc Heights relative to units outside of Paciﬁc Heights.
Each layer of a nesting in a nested logit introduces parameters that
represent the degree of correlation among alternatives within the nests.
With the full set of alternatives partitioned into nests, the parameter
λk is introduced for nest k, as described for two-level models. If the
nests are further partitioned into subnests, then a parameter σmk is
introduced for subnest m of nest k. Using the decomposition of the
probability into a series of logit models, σmk is the coeﬃcient of the
inclusive value term in the middle model, and λk σmk is the coeﬃcient of
the inclusive value term in the top model. Just as for a two-level nested
logit, the value of these parameters must be in certain ranges to be
consistent with utility maximization. If 0 < λk < 1 and 0 < σmk < 1,
then the model is consistent with utility maximization for all levels
of the explanatory variables. A negative value for either parameter is
inconsistent with utility maximization. And values greater than one
are consistent for a range of explanatory variables.

4.4

Overlapping Nests

For the nested logit models that we have considered, each alternative
is a member of only one nest (and, for three-level models, only one subnest.) This aspect of nested logit models is a restriction that is sometimes inappropriate. For example, in our example of mode choice, we
put carpool and auto alone into a nest because they have some similar
unobserved attributes. However, carpooling also has some unobserved
attributes that are similar to bus and rail, such as a lack of ﬂexibility in
scheduling (the worker cannot go to work whenever he wants each day
but rather has to go at the time that the carpool has decided, similar
to taking a bus or rail line with ﬁxed departure times.) It would be
useful to have a model in which the unobserved utility for the carpool
alternative could be correlated with that of auto alone and also correlated, though to a diﬀerent degree, with that of bus and rail. Stated
equivalently, it would be useful for the carpool alternative to be in two
nests: one with auto alone and another with bus and rail.
Several kinds of GEV models have been speciﬁed with overlapping
nests, such that an alternative can be a member of more than one nest.
Vovsha (1997), Bierlaire (1998), and Ben-Akiva and Bierlaire (1999)
have proposed various models called cross-nested logits (CNL) that
contain multiple overlapping nests. Small (1987) considered a situa-

CHAPTER 4. GEV

102

tion where the alternatives have a natural order, such as the number
of cars that a household owns (0, 1, 2, 3, and so on) or the destination
for shopping trips, with the shopping areas ordered by distance from
the household’s home. He speciﬁed a model called ordered generalized
extreme value (OGEV) in which the correlation in unobserved utility
between any two alternatives depends on their proximity in the ordering. This model has overlapping nests like the cross-nested logits,
but each nest consists of two alternatives and a pattern is imposed
on the correlations (higher correlation for closer pairs). Small (1994)
and Bhat (1998b) described a nested version of the OGEV, which is
similar to a nested logit except that the lower models (for the alternatives given the nests) are OGEV rather than standard logit. Chu
(1981, 1989) proposed a model called the paired combinatorial logit
(PCL) in which each pair of alternatives constitutes a nest with its
own correlation. With J alternatives, each alternative is a member of
J −1 nests and the correlation of its unobserved utility with each other
alternative is estimated. Wen and Koppelman (2001) have developed
a “generalized nested logit” (GNL) model that includes the PCL and
other cross-nested models as special cases. I describe below the PCL
and GNL, the former because of its simplicity and the later because of
its generality.

4.4.1

Paired combinatorial logit

Each pair of alternatives is considered to be a nest. Since each alternative is paired with each of the other alternative, each alternative is
member of J − 1 nests. A parameter labeled λij indicates the degree
of independence between alternatives i and j. Stated equivalently:
(1 − λij ) is a measure of the correlation between the unobserved utility
of alternative i and that of alternative j. This parameter is analogous
to the λk in a nested logit model, where λk indicates the degree of
independence of alternatives within the nest and 1 − λk is a measure of
correlation within the nest. And as with nested logit, the PCL model
becomes a standard logit when λij = 1 for all pairs of alternatives.
The choice probabilities for the PCL model are




Vni /λij eVni /λij + eVnj /λij
j=i e

Pni = 

λij −1



J−1 J
Vnk /λk + eVn /λk λk
=k+1 e
k=1

(4.6)

The sum in the numerator is over all J − 1 nests that alternative i

4.4. OVERLAPPING NESTS

103

is in. For each of these nests, the term being added is the same as
the numerator of the nested logit probability (4.2). In this sense, the
PCL is like the nested logit except that it allows i to be in more
than one nest. The denominator in the PCL also take the same form
as in a nested logit: it is the sum over all nests of the sum of the
exp(V /λ)’s within the nest, raised to the appropriate power λ. If λij
is between zero and one for all ij pairs, then the model is consistent
with utility maximization for all levels of the data. It is easy to verify
that Pni becomes the standard logit formula when λij = 1 ∀ i, j. In
their application, Koppelman and Wen (2000) found PCL to perform
better than nested logit or standard logit.
The researcher can test the hypothesis that λij = 1 for some or all
of the pairs, using the likelihood ratio test of section (3.8.2). Acceptance of the hypothesis for a pair of alternatives implies that there is
no signiﬁcant correlation in the unobserved utility for that pair. The
researcher can also place structure on the pattern of correlation. For
example, correlations can be assumed to be the same among a group
of alternatives; this assumption is imposed by setting λij = λk for all
i, j, k, and in the group. Small’s OGEV model is a PCL model in
which λij is speciﬁed to be a function of the proximity between i and
j. With a large number of alternatives, the researcher will probably
need to impose some form of structure on the λij ’s , simply to avoid
the proliferation of parameters that arises with large J. This proliferation of parameters, one for each pair of alternatives, is what makes
the PCL so ﬂexible. The researcher’s goal is to apply this ﬂexibility
meaningfully for his particular situation.
As discussed near the end of section (2.5), since the scale and level
of utility is immaterial, at most J(J − 1)/2 − 1 covariance parameters
can be estimated in a discrete choice model. A PCL model contains
J(J − 1)/2 λ’s: one for each alternative paired with each other alternative, recognizing that i paired with j is the same as j paired with i.
The number of λ s exceeds the number of identiﬁable covariance parameters by exactly one. The researcher must therefore place at least
one constraint on the λ’s. This can be accomplished by normalizing
one of the λ to 1. If structure is placed on the pattern of correlation,
as described in the previous paragraph, then this structure will usually
impose the normalization automatically.

CHAPTER 4. GEV

104

4.4.2

Generalized nested logit

Nests of alternatives are labeled B1 , B2 , . . . , BK . Each alternative can
be a member of more than one nest. Importantly, an alternative can
be in a nest to varying degrees. Stated diﬀerently, an alternative is
allocated among the nests, with the alternative being in some nests
more than other nests. An “allocation” parameter αjk reﬂects the
extent to which alternative j is a member of nest k. This parameter
must be non-negative: αjk ≥ 0 ∀j, k. A value of zero means that
the alternative is not in the nest at all. Interpretation is facilitated
by having the allocation parameters sum to one over nests for any

alternative:
k αjk = 1 ∀j. Under this condition, αjk reﬂects the
portion of the alternative that is allocated to each nest.
A parameter λk is deﬁned for each nest and serves the same function
as in nested logit models, namely to indicate the degree of independence among alternatives within the nest: higher λk translates into
greater independence and less correlation.
The probability that person n chooses alternative i is


Pni =



Vni )1/λk
k (αik e

K  

Vnj )1/λk
j∈Bk (αjk e

j∈B (αj

=1

eVnj )1/λ

λ

λk −1

.

(4.7)

This formula is similar to the nested logit probability given in equation
4.2, except that the numerator is a sum over all the nests that contains
alternative i, with weights applied to these nests. If each alternative
enters only one nest, with αjk = 1 for j ∈ Bk and zero otherwise, the
model becomes a nested logit model. And if, in addition, λk = 1 for all
nests, then the model becomes standard logit. Wen and Koppelman
(2001) derive various cross-nested models as special cases of the GNL.
To facilitate interpretation, the GNL probability can be decomposed as:
Pni =

Pni|Bk Pnk ,
k

where the probability of nest k is


Pnk = 

K
=1

Vnj )1/λk
j (αjk e



Vnj )1/λ
j∈B (αj e

λ

4.5. HETEROSKEDASTIC LOGIT

105

and the probability of alternative i given nest k is
(αik eVni )1/λk
.
Pni|Bk = 
Vnj )1/λk
j (αjk e

4.5

Heteroskedastic Logit

Instead of capturing correlations among alternatives, the researcher
may simply want to allow the variance of unobserved factors to diﬀer
over alternatives. Steckel and Vanhonacker (1988), Bhat (1995), and
Recker (1995) describe a type of GEV model, called “heteroskedastic
extreme value” (HEV), that is the same as logit except with diﬀerent
variance for each alternative. Utility is speciﬁed as Unj = Vnj + εnj
where εnj is distributed independently extreme value with variance
(θj π)2 /6. There is no correlation in unobserved factors over alternatives; however, the variance of the unobserved factors is diﬀerent for
diﬀerent alternatives. To set the overall scale of utility, the variance
for one alternative is normalized to π 2 /6, which is the variance of the
standardized extreme value distribution. The variances for the other
alternatives are then estimated relative to the normalized variance.
The choice probabilities for this heteroskedastic logit are ((Bhat,
1995)):


Pni =






−(Vni −Vnj +θi w)/θj

e−e

−w

 e−e

e−w dw

j=i

where w = εni /θi . The integral does not take a closed form; however, it
can be approximated by simulation. Note that exp(−exp(−w))exp(−w)
is the extreme value density, given in section 3.1. Pni is therefore
the integral of the term in square brackets over the extreme value
density. It can be simulated as follows. (1) Take a draw from the
extreme value distribution, using the procedure described in section
9.2.3. (2) For this draw of w, calculate the term in brackets, namely:

j=i exp(−exp(−(vni −Vnj +θi w)/θj )). (3) Repeat steps 1 and 2 many
times and average the results. This average is an approximation to Pni .
Bhat (1995) shows that, since the integral is only one-dimensional, the
heteroskedastic logit probabilities can be calculated eﬀectively with
quadrature rather than simulation.

CHAPTER 4. GEV

106

4.6

The GEV family

We now describe the processs that McFadden (1978) developed to generate GEV models. Using this process, the researcher is able to develop
new GEV models that best ﬁt the speciﬁc circumstances of his choice
situation. As illustration, we show how the procedure is used to generate models that we have already discussed, namely logit, nested logit,
and paired combinatorial logits. The same procedure can be applied
by a researcher to generate new models with properties that meet his
research needs.
For notational simplicity, we will omit the subscript n denoting the
decision-maker. Also, since we will be using exp(Vj ) repeatedly, let’s
denote it more compactly by Yj . That is, let Yj ≡ exp(Vj ). Note that
Yj is necessarily positive.
Consider a function G that depends on Yj for all j. We denote
this function G = G(Y1 , . . . , YJ ). Let Gi be the derivative of G with
respect to Yi : Gi = ∂G/∂Yi . If this function meets certain conditions,
then a discrete choice model can be based upon it. In particular, if G
satisﬁes the conditions that are listed below, then
Yi Gi
(4.8)
G
is the choice probability for a discrete choice model that is consistent
with utility maximization. Any model that can be derived in this way
is a GEV model. This formula therefore deﬁnes the family of GEV
models.
The properties that the function must exhibit are the following.
Pi =

1. G ≥ 0 for all positive values of Yj ∀ j.
2. G is homogeneous of degree one. That is, if each Yj is raised by
some proportion ρ, G rises by proportion ρ also: G(ρY1 , . . . , ρYJ ) =
ρG(Y1 , . . . , YJ ). Actually, Ben-Akiva and Francois (1983) showed
that this condition can be relaxed to allow any degree of homogeneity. We retain the usage of degree one since doing makes the
condition easier to interpret and is consistent with McFadden’s
original description.
3. G → ∞ as Yj → ∞ for any j.
4. The cross partial derivatives of G change signs in a particular
way. That is: Gi ≥ 0 for all i, Gij = ∂Gi /∂Yj ≤ 0 for all j = i,

4.6. THE GEV FAMILY

107

Gijk = ∂Gij /∂Yk ≥ 0 for any distinct i, j, and k, and so on for
higher order cross-partials.
There is little economic intuition to motivate these properties, particularly the last one. However, it is easy to verify whether a function
exhibits these properties. The lack of intuition behind the properties
is a blessing and a curse. The disadvantage is that the researcher has
little guidance on how to specify a G that provides a model that meets
the needs of his research. The advantage is that the purely mathematical approach allows the researcher to generate models that he might
not have developed while relying only on his economic intuition. Karlstrom (2001) provides an example: he arbitrarily speciﬁed a G (in the
sense that it was not based on behavioral concepts) and found that
the resulting probability formula ﬁt his data better than logit, nested
logit, and PCL.
We can now show how logit, nested logit, and PCL models are
obtained under appropriate speciﬁcations of G.

Logit


Let G = Jj=1 Yj . This G exhibits the four required properties. (1)
The sum of positive Yj ’s is positive. (2) If all Yj ’s are raised by a factor
ρ, G rises by that same factor. (3) If any Yj rises without bound, then
G does also. (4) The ﬁrst partial derivative is Gi = ∂G/∂Yi = 1 which
meets the criterion that Gi ≥ 0. And the higher-order derivatives are
all zero, which clearly meets the criterion since they are ≥ 0 or ≤ 0 as
required.
Inserting this G and its ﬁrst derivative Gi into (4.8), the resulting
choice probability is:
Pi =

which is the logit formula.

Yi Gi
G
Yi

=

J

=

J

j=1 Yj
eVi
Vj
j=1 e

CHAPTER 4. GEV

108
Nested Logit

The J alternatives are partitioned into K nests labeled B1 , . . . , BK .
Let


K

G=

λ
(1/λ ) 
Yj
.


j∈B

=1

with each λk between zero and one. The ﬁrst three properties are
easy to verify. For the fourth property, we calculate the ﬁrst partial
derivative


λk −1
j∈Bk

=

Yj

1 (1/λk )−1
Y
λk i



λk −1

(1/λk ) 

Gi = λ k 

(1/λ )−1 
(1/λ )
Yi k
Yj k 
j∈Bk

.

for i ∈ Bk . Since Yj ≥ 0 ∀ j, Gi ≥ 0, as required. The second crosspartial derivative is
Gim =

∂Gi
∂Ym



λk −2

(1/λk )−1 
j∈Bk



=

Yj

1 (1/λk )−1
Y
λk m



λk −2

(1/λk ) 

= (λk − 1)Yi


λk − 1
(1/λ )
(Yi Ym )(1/λk )−1 
Yj k 
λk
j∈B
k

for m ∈ Bk and m = i. With λk ≤ 1, Gij ≤ 0, as required. For
j in a diﬀerent nest than i, Gij = 0 which also meets the criterion.
Higher cross-partials are calculated similarly; they exhibit the required
property if 0 < λk ≤ 1.
The choice probability becomes:
Pi =

Yi Gi
G
(1/λk )−1

=

Yi Yi



K 
=1


(1/λ ) λk −1

j∈Bk Yj


(1/λ ) λ

j∈B Yj

4.6. THE GEV FAMILY

109



(1/λ ) λk −1
j∈Bk Yj

K  
(1/λ ) λ
=1
j∈B Yj

(1/λk )

Yi

=

(eVi )(1/λk )



K 

=

=1

eVi /λk



Vj (1/λ )
j∈Bk (e )

Vj (1/λ )
j∈B (e )

Vj /λ
j∈Bk e

K  

=

λ

λk −1

Vj /λ
j∈B e

=1

λk −1

λ

which is the nested logit formula (4.2).
Paired combinatorial logit
Let

J−1



J

G=

(1/λk )

Yk


(1/λk ) λk

+ Y

.

k=1 =k+1

The required properties are veriﬁed in the same way as for the nested
logit. We have


(1/λ )
(1/λ ) λij −1 1
(1/λ )−1
Gi =
λji Yi ij + Yj ij
Yi ij
λ
ij
j=i
(1/λij )−1

=



Yi

(1/λij )

Yi


(1/λij ) λij −1

+ Yj

.

j=i

And so the choice probability is:
Pi =
=

Yi Gi
G

(1/λij )−1
j=i Yi

(1/λij )
j=i Yi





Vi /λij
j=i e




(1/λk ) λk

+ Y


(1/λij ) λij −1

(1/λk ) λk

+ Y

eVi /λij + eVj /λij

J−1 J
k=1

+ Yj

+ Yj

(1/λk )

Yk

=k+1

(1/λk )

(1/λij )

Yi

J−1 J
k=1

=




(1/λij ) λij −1

(1/λij )

Yi
Yk

=k+1

k=1

=



J−1 J






Yi



=k+1

which is the PCL formula (4.6).

λij −1

eVk /λk + eV /λk

λk

CHAPTER 4. GEV

110
Generalized nest logit

The reader can verify that the GNL probabilities in equation 4.7 are
derived from


K

G=
k=1

λk



(1/λk ) 

(αjk Yj )

.

j∈Bk

Using the same process, researchers can generate other GEV models.

Chapter 5

Probit
5.1

Choice probabilities

The logit model is limited in three important ways. It cannot represent
random taste variation. It exhibits restrictive substitution patterns
due to the IIA property. And it cannot be used with panel data when
unobserved factors are correlated over time for each decision-maker.
GEV models relax the second of these restrictions, but not the other
two. Probit models solve all three issues. They can handle random
taste variation, they allow any pattern of substitution, and they are
applicable to panel data with temporally correlated errors.
The only limitation of probit models is that they require normal distributions for all unobserved components of utility. In many, perhaps
most situations, normal distributions provide an adequate representation of the random components. However, in some situations, normal
distributions are inappropriate and can lead to perverse forecasts. A
prominent example relates to price coeﬃcients. For a probit model
with random taste variation, the coeﬃcient of price is assumed to be
normally distributed in the population. Since the normal distribution
has density on both sides of zero, the model necessarily implies that
some people have a positive price coeﬃcient. The use of a distribution that has density only on one side of zero, such as the log-normal,
is more appropriate and yet cannot be accommodated within probit.
Other than this restriction, the probit model is quite general.
The probit model is derived under the assumption of jointly normal unobserved utility components. The ﬁrst derivation, by Thurstone
(1927) for a binary probit, used the terminology of psychological stim111

CHAPTER 5. PROBIT

112

uli, which Marschak (1960) translated into economic terms as utility.
Hausman and Wise (1978) and Daganzo (1979) elucidated the generality of the speciﬁcation for representing various aspects of choice
behavior. Utility is decomposed into observed and unobserved parts:
Unj = Vnj + εnj ∀ j. Consider the vector composed of each εnj , labeled
εn = εn1 , . . . , εnJ . We assume that εn is distributed normal with a
mean vector of zero and covariance matrix Ω. The density of εn is
φ(εn ) =

1
J
2

(2π) |Ω|

1 

1
2

e− 2 εn Ω

−1 ε
n

.

The covariance Ω can depend on variables faced by decision-maker n,
such that Ωn is the more appropriate notation; however, we omit the
subscript for the sake of simplicity.
The choice probability is
Pni = P rob(Vni + εni > Vnj + εnj ∀ j = i)


=

I(Vni + εni > Vnj + εnj ∀ j = i)φ(εn )dεn

(5.1)

where I(·) is an indicator of whether the statement in parentheses holds
and the integral is over all values of εn . This integral does not have a
closed form. It must be evaluated numerically through simulation.
The choice probabilities can be expressed in a couple of other ways
that are useful for simulating the integral. Let Bni be the set of error
terms εn that result in the decision-maker choosing alternative i: Bni =
{εn s.t. Vni + εni > Vnj + εnj ∀ j = i}. Then


Pni =

εn ∈Bni

φ(εn )dεn

(5.2)

which is an integral over only some of the values of εn rather than all
possible values, namely, the εn ’s in Bni .
Expressions (5.1) and (5.2) are J dimensional integrals over the
J errors εnj , j = 1, . . . , J. Since only diﬀerences in utility matter,
the choice probabilities can be equivalently expressed as J − 1 dimensional integrals over the diﬀerences between the errors. Let us
diﬀerence against alternative i, the alternative for which we are calculating the probability. Deﬁne Ũnji = Unj − Uni , Ṽnji = Vnj − Vni ,
and ε̃nji = εnj − εni . Then Pni = P rob(Ũnji < 0 ∀ j = i). That is,
the probability of choosing alternative i is the probability that all the

5.1. CHOICE PROBABILITIES

113

utility diﬀerences, when diﬀerenced against i, are negative. Deﬁne the
vector ε̃ni = ε̃n1i , . . . , ε̃nJ1  where the “. . .” is over all alternatives except i, such that ε̃ni has dimension J − 1. Since the diﬀerence between
two normals is normal, the density of the error diﬀerences is
φ(ε̃ni ) =

1

1 

− 12 (J−1)

(2π)

|Ω̃i |

1
2

e− 2 ε̃ni Ω̃i ε̃ni

where Ω̃i is the covariance of ε̃ni , derived from Ω. Then the choice
probability expressed in utility diﬀerences is:


Pni =

I(Ṽnji + ε̃nji < 0 ∀ j = i)φ(ε̃ni )dε̃ni

(5.3)

which is a J − 1 dimensional integral over all possible values of the
error diﬀerences. An equivalent expression is:


Pni =

ε̃ni ∈B̃ni

φ(ε̃ni )dε̃ni

(5.4)

where B̃ni = {ε̃ni s.t. Ṽnji + ε̃nji < 0 ∀ j = i}, which is a J − 1
dimensional integral over the error diﬀerences in B̃ni .
Expressions (5.3) and (5.4) utilize the covariance matrix Ω̃i of the
error diﬀerences. There is a straightforward way to derive Ω̃i from the
covariance of the errors themselves, Ω. Let Mi be the J − 1 identity
matrix with an extra column of −1’s added as the i-th column. The
extra column makes the matrix have size J − 1 by J. For example,
with J = 4 alternatives and i = 3, Mi is




1 0 −1 0


Mi =  0 1 −1 0  .
0 0 −1 1
This matrix can be used to transform the covariance matrix of
errors into the covariance matrix of error diﬀerences: Ω̃i = Mi ΩMi .
Note that Ω̃i is (J − 1) × (J − 1) while Ω is J × J, since Mi is (J − 1) ×
J. As illustration, consider a three-alternative situation with errors
εn1 , εn2 , εn3  that have covariance




σ11 σ12 σ13


Ω =  σ12 σ22 σ23  .
σ13 σ23 σ33

CHAPTER 5. PROBIT

114

Suppose we takes diﬀerences against alternative 2. We know from ﬁrst
principles that the error diﬀerences ε̃n12 , ε̃n32  have covariance


Ω̃2 = Cov

εn1 − εn2
εn3 − εn2





=

σ11 + σ22 − 2σ12
σ13 + σ22 − σ12 − σ23
σ13 + σ22 − σ12 − σ23
σ33 + σ22 − 2σ23

This covariance matrix can also be derived by the transformation Ω̃2 =
M2 ΩM2 :


Ω̃n =


=


=


=

1 −1 0
0 −1 1









σ11 σ12 σ13
1
0



 σ12 σ22 σ23   −1 −1 
σ13 σ23 σ33
0
1

σ11 − σ12
σ12 − σ22
σ13 − σ23
−σ12 + σ13 −σ22 + σ23 −σ23 + σ33







1
0


 −1 −1 
0
1

σ11 − σ12 − σ12 + σ22 −σ12 + σ22 + σ13 − σ23
−σ12 + σ13 + σ22 − σ23 σ22 − σ23 − σ23 + σ33
σ11 + σ22 − 2σ12
σ13 + σ22 − σ12 − σ23
σ13 + σ22 − σ12 − σ23
σ33 + σ22 − 2σ23





As we will see, this transformation by Mi comes in handy when simulating probit probabilities.

5.2

Identiﬁcation

As described in section (2.5), any discrete choice model must be normalized to account for the fact that the level and scale of utility is irrelevant. The level of utility is immaterial since a constant can be added
to the utility of all alternatives without changing which alternative has
the highest utility: the alternative with the highest utility before the
constant is added still has the highest utility after the constant is added
to all utilities. Similarly, the scale of utility doesn’t matter since the
utility of each alternative can be multiplied by a (positive) constant
without changing which alternative has the highest utility. In logit and
nested logit models, the normalization for scale and level occurs automatically with the distributional assumptions that are placed on the
error terms. As a result, normalization does not need to be considered



.

5.2. IDENTIFICATION

115

explicitly for these models. With probit models, however, normalization for scale and level does not occur automatically. The researcher
must normalize the model directly.
Normalization of the model is related to parameter identiﬁcation.
A parameter is “identiﬁed” if it can be estimated and is “unidentiﬁed”
if it cannot be estimated. An example of an unidentiﬁed parameter is
k in the utility speciﬁcation Unj = Vnj + k + εnj . While the researcher
might write utility in this way, and might want to estimate k to obtain
a measure of the overall level of utility, doing so is impossible. The
behavior of the decision-maker is unaﬀected by k, and so the researcher
cannot infer the value of k from the choices that decision-makers have
made. Stated directly: parameters that do not aﬀect the behavior of
decision-makers cannot be estimated. In an unnormalized model, parameters can appear that are not identiﬁed; these parameters relate to
the scale and level of utility, which do not aﬀect behavior. Once the
model is normalized, these parameters disappear. The diﬃculty arises
because it is not always obvious which parameters relate to scale and
level. In the above example, the fact that k is unidentiﬁed is fairly
obvious. In many cases, it is not at all obvious which parameters are
identiﬁed. Bunch and Kitamura (1989) have shown that the probit
models in several published articles are not normalized and contain
unidentiﬁed parameters. The fact that neither the authors nor the reviewers of these articles could tell that the models were un-normalized
is a testament to the complexity of the issue.
I provide below a procedure that can always be used to normalize
a probit model and assure that all parameters are identiﬁed. It is not
the only procedure that can be used; see, for example, Bunch (1991).
In some cases a researcher might ﬁnd other normalization procedures
more convenient. However, the procedure I give can always be used,
either by itself or as a check on whatever other procedure the researcher
uses for normalization.
I describe the procedure in terms of a four-alternative model. Generalization to more alternatives is obvious. As usual, utility is expressed as Unj = Vnj + εnj j = 1, . . . , 4. The vector of errors is
εn = εn1 , . . . , εn4 . The error vector is normally distributed with

CHAPTER 5. PROBIT

116

zero mean and a covariance matrix that can be expressed explicitly as:


σ11 σ12 σ13
 ·
σ22 σ23

Ω=
 ·
· σ33
·
·
·



σ14
σ24 


σ34 
σ44

(5.5)

where the dots refer to the corresponding elements on the upper part
of the matrix. Note that there are 10 elements in this matrix, that is,
10 distinct σ’s representing the variances and covariances among the 4
errors. In general, a model with J alternatives has J(J + 1)/2 distinct
elements in the covariance matrix of the errors.
To account for the fact that the level of utility is irrelevant, we
take utility diﬀerences. In my procedure, I always take diﬀerences
with respect to the ﬁrst alternative, since that simpliﬁes the analysis
in a way that we will see. Deﬁne error diﬀerences as ε̃nj1 = εnj − εn1
for j = 2, 3, 4, and deﬁne the vector of error diﬀerences as ε̃n1 =
ε̃n21 , ε̃n31 , ε̃n41 . Note that the subscript 1 in ε̃n1 means that the error
diﬀerences are against the ﬁrst alternative, rather than that the errors
are for the ﬁrst alternative. The covariance matrix for the vector of
error diﬀerences takes the form




θ22 θ23 θ24


Ω̃1 =  · θ33 θ34 
·
· θ44
where the θ’s relate to the original σ’s as follows:
θ22 = σ22 + σ11 − 2σ12
θ33 = σ33 + σ11 − 2σ13
θ44 = σ44 + σ11 − 2σ14
θ23 = σ23 + σ11 − σ12 − σ13
θ24 = σ24 + σ11 − σ12 − σ14
θ34 = σ34 + σ11 − σ13 − σ14 .
Computationally, this matrix can be obtained using the transformation
matrix Mi deﬁned in section (5.1), as Ω̃1 = M1 ΩM1 .
To set the scale of utility, one of the diagonal elements is normalized. I set the top-left element of Ω̃1 , which is the variance of ε̃n21 , to 1.

5.2. IDENTIFICATION

117

This normalization for scale gives us the following covariance matrix:




∗
∗
1 θ23
θ24

∗
∗ 
θ34
Ω̃∗1 =  · θ33

∗ .
·
· θ44

(5.6)

The θ∗ ’s relate to the original σ’s as follows:
∗
θ33
=
∗
θ44
=
∗
θ23
=
∗
θ24
=
∗
θ34
=

σ33 + σ11 − 2σ13
σ22 + σ11 − 2σ12
σ44 + σ11 − 2σ14
σ22 + σ11 − 2σ12
σ23 + σ11 − σ12 − σ13
σ22 + σ11 − 2σ12
σ24 + σ11 − σ12 − σ14
σ22 + σ11 − 2σ12
σ34 + σ11 − σ13 − σ14
.
σ22 + σ11 − 2σ12

There are 5 elements in Ω̃∗1 . These are the only identiﬁed parameters in the model. This number is less than the 10 elements that enter
Ω. Each θ∗ is a function of the σ’s. Since there are 5 θ∗ ’s and 10 σ’s,
it is not possible to solve for all the σ’s from estimated values of the
θ∗ ’s. It is therefore not possible to obtain estimates of all the σ’s.
In general, a model with J alternatives and an unrestricted covariance matrix will have [(J −1)J/2]−1 covariance parameters when normalized, compared to the J(J + 1)/2 parameters when un-normalized.
Only [(J − 1)J/2] − 1 parameters are identiﬁed. This reduction in the
number of parameters is not a restriction. The reduction in the number of parameters is a normalization that simply eliminates irrelevant
aspects of the original covariance matrix, namely the scale and level
of utility. The 10 elements in Ω allow for variance and covariance that
is due simply to scale and level, which has no relevance for behavior.
Only the 5 elements in Ω̃∗1 contain information about the variance and
covariance of errors independent of scale and level. In this sense, only
the 5 parameters have economic content, and only the 5 parameters
can be estimated.
Suppose now that the researcher places structure on the covariance
matrix. That is, instead of allowing a full covariance matrix for the
errors, the researcher believes that the errors follow a pattern that
implies particular values for, or relations among, the elements in the

118

CHAPTER 5. PROBIT

covariance matrix. The researcher restricts the covariance matrix to
incorporate this pattern. Imposing these restrictions is called “placing
structure on the covariance matrix.”
The structure can take various forms, depending on the application.
Yai, Iwakura and Morichi (1997) estimate a probit model of route
choice where the covariance between any two routes depends only on
the length of shared route segments; this structure reduces the number
of covariance parameters to only one, which captures the relation of
the covariance to shared length. Bolduc, Fortin and Fournier (1996)
estimate a model of physicians’ choice of location where the covariance
among locations is a function of their proximity to one another, using
what Bolduc (1992) has called a “generalized autoregressive” structure.
Haaijer et al. (1998) place a factor-analytic structure that arises from
random coeﬃcients of explanatory variables; this type of structure is
described in detail in section 5.3 below. Elrod and Keane (1995) place
a factor-analytic structure, but one that arises from error components
rather than random coeﬃcients per se.
Often the structure that is placed will be suﬃcient to normalize
the model. That is, the restrictions that the researcher imposes on
the covariance matrix to ﬁt her beliefs about the way the errors relate
to each other will also serve to normalize the model. However, this
is not always the case. The examples cited by Bunch and Kitamura
(1989) are cases where the restrictions that the researcher placed on
the covariance matrix seemed suﬃcient to normalize the model but
actually were not.
The procedure that I give above can be used to determine whether
the restrictions that a researcher places on the covariance matrix are
suﬃcient to normalize the model. The researcher speciﬁes Ω with
her restrictions on its elements. Then the procedure above is used
to derive Ω̃∗1 , which is normalized for scale and level. We know that
each element of Ω̃∗1 is identiﬁed. If each of the restricted elements of
Ω can be calculated from the elements of Ω̃∗1 , then the restrictions are
suﬃcient to normalize the model. In this case, each parameter in the
restricted Ω is identiﬁed. On the other hand, if the elements of Ω
cannot be calculated from the elements of Ω̃∗1 , then the restrictions are
not suﬃcient to normalize the model and the parameters in Ω are not
identiﬁed.
To illustrate this approach, suppose the researcher is estimating a
four-alternative model and assumes that the covariance matrix for the

5.2. IDENTIFICATION

119

errors has the following form:




1+ρ
ρ
0
0

·
1+ρ
0
0 


Ω=
.

·
·
1+ρ
ρ 
·
·
·
1+ρ
This covariance matrix allows the ﬁrst and second errors to be correlated, the same as the third and fourth alternatives, but allows no
other correlation. The correlation between the appropriate pairs is
ρ/(1 + ρ). Note that by specifying the diagonal elements as 1 + ρ,
the researcher assures that the correlation is between -1 and 1 for any
value of ρ, as required for a correlation. Is this model, as speciﬁed,
normalized for scale and level? To answer the question, we apply the
procedure described above. First, we take diﬀerences with respect to
the ﬁrst alternative. The covariance matrix of error diﬀerences is:




θ22 θ23 θ24


Ω̃1 =  · θ33 θ34 
·
· θ44
where the θ’s relate to the original σ’s as follows:
θ22 = 2
θ33 = 2 + 2ρ
θ44 = 2 + 2ρ
θ23 = 1
θ24 = 1
θ34 = 1 + 2ρ.
We then normalize for scale by setting the top-left element to 1. The
normalized covariance matrix is




∗
∗
1 θ23
θ24

∗
∗
∗ 
Ω̃1 =  · θ33 θ34

∗
·
· θ44

where the θ∗ ’s relate to the original σ’s as follows:
∗
= 1+ρ
θ33

∗
θ44
= 1+ρ

CHAPTER 5. PROBIT

120
∗
= 1/2
θ23

∗
θ24
= 1/2

∗
= 1/2 + ρ.
θ34
∗ = θ ∗ = θ ∗ − 1/2 and that the other θ ∗ ’s have ﬁxed
Note that θ33
44
34
values. There is one parameter in Ω̃∗1 , as there is in Ω. Deﬁne θ=1 + ρ.
Then Ω̃∗1 is


1
1 12
2


Ω̃∗1 =  · θ θ − 12  .
· ·
θ

The original ρ can be calculated directly from θ. For example, if θ
is estimated to be 2.4, then the estimate of ρ is θ − 1 = 1.4 and the
correlation is 1.4/2.4 = .58. The fact that the parameters that enter
Ω can be calculated from the parameters that enter the normalized
covariance matrix Ω̃∗1 means that the original model is normalized for
scale and level. That is, the restrictions that the researcher placed on
Ω also provided the needed normalization.
Sometimes restrictions on the original covariance matrix can appear to be suﬃcient to normalize the model when in fact they do not.
Applying our procedure will determine whether this is the case. Consider the same model as above, but now suppose that the researcher
allows a diﬀerent correlation between the ﬁrst and second errors than
between the third and fourth errors. The covariance matrix of errors
is speciﬁed to be:




1 + ρ1
ρ1
0
0


0
0
·
1
+
ρ


1
Ω=
.

·
·
1 + ρ2
ρ2 
·
·
·
1 + ρ2
The correlation between the ﬁrst and second errors is ρ1 /(1 + ρ1 ) and
the correlation between the third and fourth errors is ρ2 /(1 + ρ2 ). We
can derive Ω̃1 for error diﬀerences and then derive Ω̃∗1 by setting the
top-left element of Ω̃1 to 1. The resulting matrix is:




1
1 12
2


∗
Ω̃1 =  · θ θ − 12 
· ·
θ

where now θ = 1+(ρ1 +ρ2 )/2. The values of ρ1 and ρ2 cannot be calculated from a value of θ. The original model is therefore not normalized

5.3. TASTE VARIATION

121

for scale and level, and the parameters ρ1 and ρ2 are not identiﬁed.
This fact is somewhat surprising, since only two parameters enter the
original covariance matrix Ω. It would seem, unless the researcher explicitly tested in the manner we have just done, that restricting the
covariance matrix to consist of only two elements would be suﬃcient
to normalize the model. In this case, however, it is not.
In the normalized model, only the average of the ρ’s appears:
(ρ1 + ρ2 )/2. It is possible to calculate the average ρ from θ, simply as θ − 1. This means that the average ρ is identiﬁed, but not
the individual values. When ρ1 = ρ2 , as in the previous example, the
model is normalized because each ρ is equal to the average ρ. However, as we now see, any model with the same average ρ’s is equivalent,
after normalizing for scale and level. Hence, assuming that ρ1 = ρ2 is
no diﬀerent than assuming that ρ1 = 3ρ2 , or any other relation. All
that matters for behavior is the average of these parameters, not their
values relative to each other. This fact is fairly surprising and would
be hard to realize without using our procedure for normalization.
Now that we know how to assure that a probit model is normalized
for level and scale, and hence contains only economically meaningful
information, we can examine how the probit model is used to represent
various types of choice situations. We look at the three issues for which
logit models are limited and show how the limitation is overcome with
probit. These issues are: taste variation, substitution patterns, and
repeated choices over time.

5.3

Taste variation

Probit is particularly well-suited for incorporating random coeﬃcients,
provided that the coeﬃcients are normally distributed. Hausman and
Wise (1978) were the ﬁrst, to my knowledge, to give this derivation.
Haaijer, Wedel, Vriens and Wansbeek (1998) provide a compelling application. Assume that representative utility is linear in parameters
and that the coeﬃcients vary randomly over decision-makers instead
of being ﬁxed as we have assumed so far in this book. Utility is:
Unj = βn xnj + εnj where βn is the vector of coeﬃcients for decisionmaker n representing that person’s tastes. Suppose the βn is normally distributed in the population with mean b and covariance W :
βn ∼ N (b, W ). The goal of the research is to estimate parameters b
and W .

CHAPTER 5. PROBIT

122

Utility can be rewritten with βn decomposed into its mean and
deviations from its mean: Unj = b xnj + β̃n xnj +εnj , where β̃n = b−βn .
The last two terms in utility are random; denote their sum as ηnj to
obtain Unj = b xnj + ηnj . The covariance of the ηnj ’s depends on W as
well as the xnj ’s, such that the covariance diﬀers over decision-makers.
The covariance of the ηnj ’s can be described easily for a twoalternative model with one explanatory variable. In this case, utility
is
Un1 = βn xn1 + εn1
Un2 = βn xn2 + εn2 .
Assume that βn is normally distributed with mean b and variance
σβ . Assume that εn1 and εn2 are identically normally distributed with
variance σε . The assumption of independence is for this example and
is not needed in general. Utility is then rewritten as
Un1 = bxn1 + ηn1
Un2 = bxn2 + ηn2 .
where ηn1 and ηn2 are jointly normally distributed. Each has zero
mean: E(ηnj ) = E(β̃n xnj + εnj ) = 0. The covariance is determined as
follows. The variance of each is V (ηnj ) = V (β̃n xnj +εnj ) = x2nj σβ +σε .
Their covariance is
Cov(ηn1 , ηn2 ) = E[(β̃n xn1 + εn1 )(β̃n xn2 + εn2 )]
= E(β̃n2 xn1 xn2 + εn1 εn2 + εn1 β̃b xn2 + εn2 β̃n xn1 )
= xn1 xn2 σβ .
The covariance matrix is


Ω =

x2n1 σβ + σε xn1 xn2 σβ
xn1 xn2 σβ x2n2 σβ + σε


= σβ

x2n1
xn1 xn2
xn1 xn2
x2n2







+ σε



1 0
0 1

.

One last step is required for estimation. Recall that behavior is not
aﬀected by a multiplicative transformation of utility. We therefore
need to set the scale of utility. A convenient normalization for this
case is σε = 1. Under this normalization,


Ω = σβ

x2n1
xn1 xn2
xn1 xn2
x2n2





+

1 0
0 1



.

5.4. SUBSTITUTION PATTERNS/NON-IIA

123

The values of xn1 and xn2 are observed by the researcher, and the
parameters b and σβ are estimated. Thus, the researcher learns both
the mean and variance of the random coeﬃcient in the population.
Generalization to more than one explanatory variable and more than
two alternatives is straightforward.

5.4

Substitution patterns/non-IIA

Probit can represent any substitution pattern. The probit probabilities
do not exhibit the IIA property that gives rise to the proportional
substitution of logit. Diﬀerent covariance matrices Ω provide diﬀerent
substitution patterns, and by estimating the covariance matrix, the
researcher determines the substitution pattern that is most appropriate
for the data.
A full covariance matrix can be estimated, or the researcher can
place structure on the covariance matrix to represent particular sources
of non-independence. This structure usually reduces the number of parameters and facilitates interpretation of the parameters. We consider
ﬁrst the situation where the researcher estimates a full covariance matrix, and then turn to a situation where the researcher places structure
on the covariance matrix.
Full covariance: unrestricted substitution patterns
For notational simplicity, consider a probit model with four alternatives. A full covariance matrix for the unobserved components of utility
takes the form of Ω in (5.5). When normalized for scale and level, the
covariance matrix becomes Ω̃∗1 in (5.6). The elements of Ω̃∗1 are estimated. The estimated values can represent any substitution pattern;
importantly, the normalization for scale and level does not restrict the
substitution patterns. The normalization only eliminates aspects of Ω
that are irrelevant to behavior.
Note, however, that the estimated values of the θ∗ ’s provide essentially no interpretable information in themselves (Horowitz, 1991).
∗ is estimated to be larger than θ ∗ . It might
For example, suppose θ33
44
be tempting to interpret this result as indicating that the variance in
unobserved utility of the third alternative is greater than that for the
fourth alternative; that is, that σ33 > σ44 . However, this interpretation
∗ > θ ∗ and yet σ
is incorrect. It is quite possible that θ33
44 > σ33 , if
44

CHAPTER 5. PROBIT

124

covariance σ13 is suﬃciently greater than σ14 . Similarly, suppose that
θ23 is estimated to be negative. This does not mean that unobserved
utility for the second alternative is negatively correlated with unobserved utility for the third alternative (that is, σ23 < 0). It is possible
that σ23 is positive and yet σ12 and σ13 are suﬃciently large to make
∗ negative. The point here is: estimating a full covariance matrix
θ23
allows the model to represent any substitution pattern but renders the
estimated parameters essentially uninterpretable.

Structured covariance: restricted substitution patterns
By placing structure on the covariance matrix, the estimated parameters usually become more interpretable. The structure is a restriction
on the covariance matrix and, as such, reduces the ability of the model
to represent various substitution patterns. However, if the structure
is correct (that is, actually represents the behavior of the decisionmakers), then the true substitution pattern will be able to be represented by the restricted covariance matrix.
Structure is necessarily situation-dependent: an appropriate structure for a covariance matrix depends on the speciﬁcs of the situation
being modeled. Several studies using diﬀerent kinds of structure were
described above in section 5.2. As an example of how structure can be
placed on the covariance matrix and hence substitution patterns, consider a homebuyer’s choice among purchase-money mortgages. Suppose four mortgages are available to the homebuyer from four diﬀerent institutions: one with a ﬁxed rate, and three with variable rates.
Suppose the unobserved portion of utility consists of two parts: the
homebuyer’s concern about the risk of rising interest rates, labeled rn ,
which is common to all the variable rate loans, and all other unobserved factors, labeled collectively ηnj . The unobserved component of
utility is then
εnj = −rn dj + ηnj
where dj = 1 for the variable rate loans and zero for the ﬁxed rate loan,
and the negative sign indicates that utility decreases as concern about
risk rises. Assume that rn is normally distributed over homebuyers
with variance σ, and that ηnj ∀ j is iid normal with zero mean and

5.4. SUBSTITUTION PATTERNS/NON-IIA

125

variance ω. Then the covariance matrix for εn = εn1 , . . . , εn4  is








0 0 0 0
1 0 0 0
 · σ σ σ 
 · 1 0 0 




Ω=
+ω

 · · σ σ 
 · · 1 0 
· · · σ
· · · 1
The model needs to normalized for scale but, as we will see, is already
normalized for level. The covariance of error diﬀerences is








σ σ σ
2 1 1




Ω̃1 =  · σ σ  + ω  · 2 1  .
· · σ
· · 2
This matrix has no fewer parameters than Ω. In this sense, the model
was already normalized for level. To normalize for scale, set σ+2ω = 1.
Then the covariance matrix becomes:




1 θ θ


∗
Ω̃1 =  · 1 θ 
· · 1
where θ = (σ+ω)/(σ+2ω). The values of σ and ω cannot be calculated
from θ. However, the parameter θ provides information about the
variance in utility due to concern about risk relative to that due to all
other unobserved factors. For example, suppose θ is estimated to be
0.75. This estimate can be intrepreted as indicating that the variance
in utility attributable to concern about risk is twice as large as the
variance in utility attributable to all other factors:
θ = 0.75
σ+ω
= 0.75
σ + 2ω
σ + ω = 0.75σ + 1.5ω
.25σ = .5ω
σ = 2ω.
Stated equivalently, θ̂ = 0.75 means that concern about risk accounts
for two-thirds of the variance in the unobserved component of utility.
Since the original model was already normalized for level, the model
could be estimated without reexpressing the covariance matrix in terms
of error diﬀerences. The normalization for scale could be accomplished

CHAPTER 5. PROBIT

126

simply by setting ω = 1 in the original Ω. Under this procedure, the
parameter σ is estimated directly. Its value relative to 1 indicates
the variance due to concern about risk relative to the variance due to
perceptions about ease of dealing with each institution. An estimate
θ̂ = 0.75 corresponds to an estimate σ̂ = 2.

5.5

Panel data

Probit with repeated choices is similar to probit on one choice per
decision-maker. The only diﬀerence is that the dimension of the covariance matrix of the errors is expanded. Consider a decision-maker
who faces a choice among J alternatives in each of T time periods or
choices situations. The alternatives can change over time, and J and
T can diﬀer for diﬀerent decision-makers; however, we suppress the notation for these possibilities. The utility that decision-maker n obtains
from alternative j in period t is Unjt = Vnjt + εnjt . In general, one
would expect εnjt to be correlated over time as well as over alternatives,
since factors that are not observed by the researcher can persist over
time. Denote the vector of errors for all alternatives in all times periods as εn = εn11 , . . . , εnJ1 , εn12 , . . . , εnJ2 , . . . , εn1T , . . . , εnJT . The
covariance matrix of this vector is denoted Ω, which has dimension
JT × JT .
Consider a sequence of alternatives, one for each time period, i =
{i1 , . . . , iT }. The probability that the decision-maker makes this sequence of choices is
Pni = P rob(Unit t > Unjt ∀ j = it , ∀ t)
= P rob(Vnit t + εnit t > Vnjt + εnjt ∀ j = it , ∀ t)


=

εn ∈Bn

φ(εn )dεn .

where Bn = {εn s.t. Vnit t +εnit t > Vnjt +εnjt ∀ j = it , ∀ t} and φ(εn ) is
the joint normal density with zero mean and covariance Ω. Compared
to the probit probability for one choice situation, the integral is simply
expanded to be over JT dimensions rather than J.
It is often more convenient to work in utility diﬀerences. The probability of sequence i is the probability that the utility diﬀerences are
negative for each alternative in each time period, when the diﬀerences
in each time period are taken against the alternative identiﬁed by i for

5.5. PANEL DATA

127

that time period:
Pni = P rob(Ũnjit t < 0 ∀ j = it , ∀ t)


=

ε̃n ∈B̃n

φ(ε̃n )dε̃n .

where Ũnjit t = Unjt −Unit t ; ε̃n = (εn11 −εni1 1 ), . . . , (εnJ1 −εni1 1 ), . . . , (εn1T −
εniT T ), . . . , (εnJT − εniT T ) with each . . . being over all alternatives except it ; and the matrix B̃n is the set of ε̃n ’s for which Ũnjit t < 0 ∀ j =
it , ∀ t. This is a (J − 1)T dimensional integral. The density φ(ε̃n )
is joint normal with covariance matrix derived from Ω. Simulation of
the choice probability is the same as for situations with one choice per
decision-maker, which we describe in section (5.6), but with a larger
dimension for the covariance matrix and integral. Borsch-Supan et al.
(1991) provide an example of a multinomial probit on panel data that
allows covariance over time and over alternatives.
For binary choices, such as whether a person buys a particular
product in each time period or works at a paid job each month, the
probit model simpliﬁes considerably (Gourieroux and Monfort, 1993).
The net utility of taking the action (e.g., working) in period t is Unt =
Vnt + εnt , and the person takes the action if Unt > 0. This utility is
called net utility because it represents the diﬀerence between the utility
of taking the action compared to not taking the action. As such, it is
already expressed in diﬀerence terms. The errors are correlated over
time, and the covariance matrix for εn1 , . . . , εnT is Ω, which is T × T .
A sequence of binary choices is most easily represented by a set of
T dummy variables: dnt = 1 if person n took the action in period t
and dnt = −1 otherwise. The probability of the sequence of choices
dn = dn1 , . . . , dnT is
Pndn

= P rob(Unt dnt > 0 ∀ t)
= P rob(Vnt dnt + εnt dnt > 0 ∀ t)


=

εn ∈Bn

φ(εn )dεn

where Bn is the set of εn ’s for which Vnt dnt + εnt dnt > 0 ∀ t, and φ(εn )
is the joint normal density with covariance Ω.
Structure can be placed on the covariance of the errors over time.
Suppose in the binary case, for example, that the error consists of a
portion that is speciﬁc to the decision-maker reﬂecting his proclivity

CHAPTER 5. PROBIT

128

to take the action, and a part that varies over time for each decisionmaker: εnt = ηn + µnt where µnt is iid over time and people with
a standard normal density, and ηn is iid over people with a normal
density with zero mean and variance σ. The variance of the error in
each period is V (εnt ) = V (ηn + µnt ) = σ + 1. The covariance between
the errors in two diﬀerent periods t and s is Cov(εnt , εns ) = E(ηn +
µnt )(ηn + µns ) = σ. The covariance matrix therefore takes the form:




σ+1
σ
... ...
σ
 σ

σ
+
1
σ
.
.
.
σ


Ω=
.

·
·
·
·
· 
σ
... ... σ σ + 1
Only one parameter, σ, enters the covariance matrix. Its value indicates the variance in unobserved utility across individuals (the variance
of ηn ) relative to the variance across time for each individual (the variance of µnt ). It is often called “the cross-subject variance relative to
the within-subject variance.”
The choice probabilities under this structure on the errors can be
easily simulated using the concepts of convenient error partitioning
from section 1.2. Conditional on ηn , the probability of not taking
the action in period t is P rob(Vnt + ηn + µnt < 0) = P rob(µnt <
−(Vnt + ηn )) = Φ(−(Vnt + ηn )), where Φ(·) is the cumulative standard
normal function. Most software packages include routines to calculate
this function. The probability of taking the action, conditional on ηn , is
then 1−Φ(−(Vnt +ηn )) = Φ(Vnt +ηn ). The probability of the sequence

of choices dn , conditional on ηn , is therefore t Φ((Vnt + ηn )dnt ), which
we can label Hndn (ηn ). So far we have conditioned on ηn , when in fact
ηn is random. The unconditional probability is the integral of the
conditional probability Hndn (ηn ) over all possible values of ηn :


Pndn =

Hndn (ηn )φ(ηn )dηn

where φ(ηn ) is the normal density with zero mean and variance σ. This
probability can be simulated very simply as follows. (1) Take a draw
of from a standard normal density using a random number generator.
√
Multiply the draw by σ so that it becomes a draw of ηn from a normal
density with variance σ. (2) For this draw of ηn , calculate Hndn (ηn ).
(3) Repeat steps 1-2 many times and average the results. This average
is a simulated approximation to Pndn . This simulator is much easier

5.5. PANEL DATA

129

to calculate than the general probit simulators described in the next
section. The ability to use this simulator arises from the structure
that we placed on the model, namely that the time-dependence of the
unobserved factors is captured entirely by a random component ηn that
remains constant over time for each person. Gourieroux and Monfort
(1993) provide an example of the use of this simulator with a probit
model of this form.
The representative utility in one time period can include exogenous
variables for other time periods, the same as we discussed with respect
to logit models on panel data (section 3.3.3). That is, Vnt can include
exogenous variables that relate to periods other than t. For example,
a lagged response to price changes can be represented by including
prices from previous periods in the current period’s V . Anticipatory
behavior (by which, for example, a person buys a product now because
he correctly anticipates that the price will rise in the future) can be
represented by including prices in future periods in the current period’s
V.
Entering a lagged dependent variable is possible but introduces two
diﬃculties that the researcher must address. First, since the errors are
correlated over time, the choice in one period is correlated with the errors in subsequent periods. As a result, inclusion of a lagged dependent
variable without adjusting the estimation procedure appropriately results in inconsistent estimates. This issue is analogous to regression
analysis, where the ordinary least squares estimator is inconsistent
when a lagged dependent variable is included and the errors are serially correlated. To estimate a probit consistently in this situation, the
researcher must determine the distribution of each εnt conditional on
the value of the lagged dependent variables. The choice probability is
then based on this conditional distribution instead of the unconditional
distribution φ(·) that we use above. Second, often the researcher does
not observe the decision-makers’ choices from the very ﬁrst choice that
was available to them. For example, a researcher studying employment
patterns will perhaps observe a person’s employment status over a period of time (e.g., from 1998-2001), but usually will not observe the
person’s employment status starting with the very ﬁrst time the person could have taken a job (which might precede 1998 by many years).
In this case, the probability for the ﬁrst period that the researcher
observes depends on the choices of the person in the earlier periods
that the researcher does not observe. The researcher must determine

130

CHAPTER 5. PROBIT

a way to represent the ﬁrst choice probability that allows for consistent estimation in the face of missing data on earlier choices. This is
called the “initial conditions problem” of dynamic choice models. Both
of these issues, as well as potential approaches to dealing with them,
are addressed by Heckman (1981b, 1981a) and Heckman and Singer
(1986). Due to their complexity, I do not describe the procedures here
and refer interested and brave readers to these articles.
Papatla and Krishnamurthi (1992) avoid these issues in their probit model with lagged dependent variables by assuming that the unobserved factors are independent over time. As we discussed in relation
to logit on panel data (section 3.3.3), lagged dependent variables are
not correlated with the current errors when the errors are independent
over time and can therefore be entered without inducing inconsistency.
Of course, this procedure is only appropriate if the assumption of errors being independent over time is true in reality, rather than just by
assumption.

5.6

Simulation of the choice probabilities

The probit probabilities do not have a closed-form expression and must
be approximated numerically. Several non-simulation procedures have
been used and can be eﬀective in certain circumstances. Quadrature
methods approximate the integral by a weighted function of specially
chosen evaluation points. A good explanation for these procedures is
provided by Geweke (1996). Examples of their use for probit include
Butler and Moﬃtt (1982) and Guilkey and Murphy (1993). Quadrature operates eﬀectively when the dimension of the integral is small,
but not with higher dimensions. It can be used for probit if the number
of alternatives (or, with panel data, the number of alternatives times
the number of time periods) is no more than 4 or 5. It can also be
used if the researcher has speciﬁed an error-component structure with
no more than 4 or 5 terms. However, it is not eﬀective for general
probit models. And even with low-dimensional integration, simulation
is often easier. Another non-simulation procedure that has been suggested is the Clark algorithm, introduced by Daganzo, Bouthelier and
Sheﬃ (1977). This algorithm utilizes the fact, shown by Clark (1961),
that the maximum of several normally distributed variables is itself approximately normally distributed. Unfortunately, the approximation
can be highly inaccurate in some situations (as shown by Horowitz,

5.6. SIMULATION OF THE CHOICE PROBABILITIES

131

Sparmann and Daganzo (1982)), and the degree of accuracy is diﬃcult
to assess in any given setting.
Simulation has proven to be very general and useful for approximating probit probabilities. Numerous simulators have been proposed
for probit models; a summary is given by Hajivassiliou, McFadden
and Ruud (1996). In the section above, I described a simulator that
is appropriate for a probit model that has a particularly convenient
structure, namely a binary probit on panel data where the time dependence is captured by one random factor. In the current section, I
describe three simulators that are applicable for probits of any form:
accept-reject, smoothed accept-reject, and GHK. The GHK simulator
is by far the most widely used probit simulator, for reasons that we
discuss. The other two methods are valuable pedagogically. They also
have relevance beyond probit and can be applied in practically any
situation. They can be very useful when the researcher is developing
her own models rather than using probit or any other model in this
book.

5.6.1

Accept-reject simulator

Accept-reject (A-R) is the most straightforward of any simulator. Consider simulating Pni . Draws of the random terms are taken from their
distribution. For each draw, the researcher determines whether that
value of the errors, when combined with the observed variables as faced
by person n, would result in alternative i being chosen. If so, the draw
is called an “accept.” If the draw would result in some other alternative being chosen, the draw is a “reject”. The simulated probability is
the proportion of draws that are accepts. This procedure can be applied to any choice model with any distribution for the random terms.
It was originally proposed for probits (Manski and Lerman, 1981), and
we give the details of the approach in terms of the probit model. Its
use for other models is obvious.
We use expression (5.1) for the probit probabilities:


Pni =

I(Vni + εni > Vnj + εnj ∀ j = i)φ(εn )dεn

where I(·) is an indicator of whether the statement in parentheses holds
and φ(εn ) is the joint normal density with zero mean and covariance
Ω. The accept-reject simulator of this integral is calculated as follows.

CHAPTER 5. PROBIT

132

1. Draw a value of the J-dimensional vector of errors, εn , from a
normal density with zero mean and covariance Ω. Label the draw
εrn with r = 1 and the elements of the draw as εrn1 , . . . , εrnJ .
2. Using these values of the errors, calculate the utility that each
r =
alternative obtains with these errors. That is, calculate Unj
r
Vnj + εnj ∀ j.
3. Determine whether the utility of alternative i is greater than
r >
that for all other alternatives. That is, calculate I r = 1 if Uni
r , indicating an “accept”, and I r = 0 otherwise, indicating a
Unj
“reject.”
4. Repeat steps 1-3 many times. Label the number of repetitions
(including the ﬁrst) as R, such that r takes values of 1 through
R.
5. The simulated probability is the proportion of draws that are

r
accepts: P̌ni = R1 R
r=1 I .




The integral I(·)φ(εn )dε is approximated by the average R1
I r (·)
for draws from φ(·). Obviously, P̌ni is unbiased for Pni : E(P̌ni ) =

1 
E[I r (·)] = R1
Pni = Pni , where the expectation is over diﬀerent
R
sets of R draws. The variance of P̌ni over diﬀerent sets of draws diminishes as the number of draws rises. The simulator is often called
the “crude frequency simulator,” since it is the frequency of times that
draws of the errors result in the speciﬁed alternative being chosen. The
word “crude” distinguishes it from the “smoothed” frequency simulator that we describe in the next section.
The ﬁrst step of the A-R simulator for a probit model is to take a
draw from a joint normal density. The question arises: how are such
draws obtained? The most straightforward procedure is that described
in section (9.2.5) which uses the Choleski factor. The covariance matrix
for the errors is Ω. A Choleski factor of Ω is a lower-triangular matrix
L such that LL = Ω. It is sometimes called the generalized square root
of Ω. Most statistical software packages contain routines to calculate
the Choleski factor of any symmetric matrix. Now suppose that η is a
vector of J iid standard normal deviates, such that η ∼ N (0, I) where
I is the identity matrix. This vector can be obtained by taking J draws
from a random number generator for the standard normal and stacking
them into a vector. We can construct a vector ε that is distributed

5.6. SIMULATION OF THE CHOICE PROBABILITIES

133

N (O, Ω) by using the Choleski factor to tranform η. In particular,
calculate ε = Lη. Since the sum of normals is normal, ε is normally
distributed. Since η has zero mean, so does ε. The covariance of ε is
Cov(ε) = E(εε ) = E(Lη(Lη) ) = E(Lηη  L ) = LE(ηη  )L = LIL =
LL = Ω.
Using the Choleski factor L of Ω, the ﬁrst step of the A-R simulator
becomes two substeps:
1A Draw J values from a standard normal density using a random
number generator. Stack these values into a vector and label the
vector η r .
1B Calculate εrn = Lη r .
Then, using εrn , calculate the utility of each alternative and see whether
alternative i has the highest utility.
The procedure that we have described operates on utilities and expression (5.1), which is a J dimensional integral. The procedure can be
applied analogously to utility diﬀerences, which reduces the dimension
of the integral to J − 1. As given in (5.3), the choice probabilities can
be expressed in terms of utility diﬀerences:


Pni =

I(Ṽnji + ε̃nji < 0 ∀ j = i)φ(ε̃ni )dε̃ni

where φ(ε̃ni ) is the joint normal density with zero mean and covariance Ω̃i = Mi ΩMi . This integral can be simulated with accept-reject
methods through the following steps.
1. Draw ε̃rni = Li η r as follows:
(a) Draw J − 1 values from a standard normal density using a
random number generator. Stack these values into a vector
and label the vector η r .
(b) Calculate ε̃rni = Li η r , where Li is the Choleski factor of Ω̃i .
2. Using these values of the errors, calculate the utility diﬀerence
for each alternative, diﬀerenced against the utility of alternative
r = V − V + ε̃r
i. That is, calculate Ũnji
nj
ni
nji ∀ j = i.
3. Determine whether each utility diﬀerence is negative. That is,
r < 0 ∀ j = i, indicating an “accept”, and
calculate I r = 1 if Unji
r
I = 0 otherwise, indicating a “reject.”

134

CHAPTER 5. PROBIT

4. Repeat steps 1-3 R times.
5. The simulated probability is the number of accepts divided by

r
the number of repetitions: P̌ni = R1 R
r=1 I .
Using utility diﬀerences is slightly faster computationally than using the utilities themselves, since one dimension is eliminated. However, it is often easier conceptually to remain with utilities.
As stated above, the A-R simulator is very general. It can be applied to any model for which draws can be obtained for the random
terms and the behavior that the decision-maker would exhibit with
these draws can be determined. It is also very intuitive, which is an
advantage from a programming perspective since debugging becomes
comparatively easy. However, the A-R simulator has several disadvantages, particularly when used in the context of maximum likelihood
estimation.
 
Recall that the log-likelihood function is LL = n j dnj logPnj
where dnj = 1 if n chose j and 0 otherwise. When the probabilities
cannot be calculated exactly, as in the case of probit, the simulated loglikelihood function is used instead, with the true probabilities replaced
 
with the simulated probabilities: SLL = n j dnj log P̌nj . The value
of the parameters that maximizes SLL is called the maximum simulated likelihood estimator (MSLE). It is by far the most widely used
simulation-based estimation procedure. Its properties are described in
Chapter 8. Unfortunately, using the A-R simulator in SLL can be
problematic.
There are two issues. First, P̌ni can be zero for any ﬁnite number
of draws R. That is, it is possible that each of the R draws of the
error terms result in a “reject,” such that the simulated probability
is zero. Zero values for P̌ni are problematic because the log of P̌ni is
taken when it enters the log-likelihood function and the log of zero is
undeﬁned. SLL cannot be calculated if the simulated probability is
zero for any decision-maker in the sample.
The occurrence of a zero simulated probability is particularly likely
when the true probability is low. Often at least one decision-maker in
a sample will have made a choice that has a low probability. With
numerous alternatives (such as thousands of makes and models for the
choice of car) each alternative has a low probability. With repeated
choices, the probability for any sequence of choices can be extremely
small; for example, if the probability of choosing an alternative is 0.25

5.6. SIMULATION OF THE CHOICE PROBABILITIES

135

in each of 10 time periods, the probability of the sequence is (0.25)10 ,
which is less than 0.000001.
Furthermore, SLL needs to be calculated at each step in the search
for its maximum. Some of the parameters values at which SLL is calculated can be far from the true values. Low probabilities can occur at
these parameter values even when they do not occur at the maximizing
values.
Non-zero simulated probabilities can always be obtained by taking
enough draws. However, if the researcher continues taking draws until at least one “accept” is obtained for each decision-maker, then the
number of draws becomes a function of the probabilities. The simulation process is then not independent of the choice process that is being
modeled, and the properties of the estimator become more complex.
There is a second diﬃculty with the A-R simulator for MSLE.
The simulated probabilities are not smooth in the parameters; that
is, they are not twice diﬀerentiable. As explained in Chapter 8, the
numerical procedures that are used to locate the maximum of the loglikelihood function rely on the ﬁrst derivatives, and sometimes the
second derivatives, of the choice probabilities. If these derivatives do
not exist, or do not point toward the maximum, then the numerical
procedure will not perform eﬀectively.
The A-R simulated probability is a step function, as depicted in
Figure 5.1. P̌ni is the proportion of draws for which alternative i has
the highest utility. An inﬁnitesimally small change in a parameter will
usually not change any draw from being a reject to an accept, or vice
r is below U r for some j at a given level of the parameters,
versa. If Uni
nj
then it will also be below for an inﬁnitesimally small change in any
parameter. So, usually, P̌nj is constant with respect to small changes
in the parameters. Its derivative with respect to the parameters is
zero in this range. If the parameters change in a way that a reject
becomes an accept, then P̌nj rises by a discrete amount, from M/R to
(M +1)/R where M is the number of accepts at the original parameter
values. P̌nj is constant (zero slope) until an accept becomes a reject or
vice versa, at which point P̌nj jumps by 1/R. Its slope at this point is
undeﬁned. The ﬁrst derivative of P̌nj with respect to the parameters
is either zero or undeﬁned.
The fact that the slope is either zero or undeﬁned hinders the numerical procedures that are used to locate the maximum of SLL. As
discussed in Chapter 8, the maximization procedures use the gradient

CHAPTER 5. PROBIT

136

~

Pni

3/R
2/R
1/R

β

Figure 5.1: The A-R simulator is a step function in parameters.
at trial parameter values to determine the direction to move to ﬁnd parameters with higher SLL. With the slope P̌nj for each n either zero
or undeﬁned, the gradient of SLL is either zero or undeﬁned. This
gradient provides no help in ﬁnding the maximum.
This issue is not actually as drastic as it seems. The gradient of
SLL can be approximated as the change in SLL for a non-inﬁnitesimally
small change in the parameters. The parameters are changed by an
amount that is large enough to switch accepts to rejects and vice versa
for at least some of the observations. The approximate gradient, which
can be called an arc gradient, is calculated as the amount that SLL
changes divided by the change in the parameters. To be precise: for
parameter vector β of length K, the derivate of SLL with respect to
the k-th parameter is calculated as (SLL1 − SLL0 )/(βk1 − βk0 ), where
SLL0 is calculated at the original β with k-th element βk0 and SLL1
is calculated at βk1 with all the other parameters remaining at their
original values. The arc gradient calculated in this way is not zero or
undeﬁned, and provides information on the direction of rise. Nevertheless, the A-R simulated probability is diﬃcult because of its inherent
lack of a slope, coupled with the possibility of it being zero.

5.6.2

Smoothed A-R simulators

One way to mitigate the diﬃculties with the A-R simulator is to replace the 0-1 accept/reject indicator with a smooth, strictly positive
function. The simulation starts the same as with A-R, by taking draws

5.6. SIMULATION OF THE CHOICE PROBABILITIES

137

of the random terms and calculating the utility of each alternative for
r . Then instead of determining whether alternative i has
each draw: Unj
the highest utility (that is, instead of calculating the indicator function
r ∀ j are entered into a function. Any
I r ), the simulated utilities Unj
r
function can be used for simulating Pni as long as it rises when Uni
r rises, is strictly positive, and has deﬁned ﬁrst
rises, declines when Unj
r ∀ j. A function that is parand second derivatives with respect to Unj
ticularly convenient is the logit function, as suggested by McFadden
(1989). Use of this function gives the “logit smoothed A-R simulator.”
The simulator is implemented in the following steps, which are the
same as with the A-R simulator except for step 3.
1. Draw a value of the J-dimensional vector of errors, εn , from a
normal density with zero mean and covariance Ω. Label the draw
εrn with r = 1 and the elements of the draw as εrn1 , . . . , εrnJ .
2. Using these values of the errors, calculate the utility that each
r =
alternative obtains with these errors. That is, calculate Unj
r
Vnj + εnj ∀ j.
3. Put these utilities into the logit formula. That is, calculate
r

eUni /λ
Sr =  U r /λ
nj
je
where λ > 0 is a scale factor speciﬁed by the researcher and
discussed below.
4. Repeat steps 1-3 many times. Label the number of repetitions
(including the ﬁrst) as R, such that r takes values of 1 through
R.
5. The simulated probability is the number of accepts divided by

r
the number of repetitions: P̌ni = R1 R
r=1 S .
r , the simulated probability
Since S r > 0 for all ﬁnite values of Unj
r and
is strictly positive for any draws of the errors. It rises with Uni
r j = i rises. It is smooth (twice diﬀerentiable) since
declines when Unj
the logit formula itself is smooth.
The logit-smoothed A-R simulator can be applied to any choice
model, simply by simulating the utilities under any distributional assumptions about the errors and then inserting the utilities into the

CHAPTER 5. PROBIT

138

logit formula. When applied to probit, Ben-Akiva and Bolduc (1996)
have called it “logit-kernel probit.”
The scale factor λ determines the degree of smoothing. As λ → 0,
S r approaches the indicator function I r . Figure 5.2 illustrates the situation for a two-alternative case. For a given draw of εrn , the utility of
the two alternatives is calculated. Consider the simulated probability
r
for alternative 1. With A-R, the 0-1 indicator function is zero if Un1
r and one if U r exceeds U r . With logit-smoothing, the
is below Un2
n1
n2
step function is replaced by a smooth sigmoid curve. The factor λ determines the proximity of the sigmoid to the 0-1 indicator. Lowering
λ increases the scale of the utilities when they enter the logit function
(since the utilities are divided by λ.) Increasing the scale of utility
increases the absolute diﬀerence between the two utilities. The logit
formula gives probabilities that are closer to zero or one when the difference in utilities is larger. The logit-smoothed S r therefore becomes
closer to the step function as λ becomes closer to zero.
r

Pn1
1
Logit smoother
with higher λ
Logit smoother
with λ closer to 0
0-1 Indicator, I

0

r

Un2

r

r

Un1

Figure 5.2: A-R smoother.
The researcher needs to set the value of λ. A lower value of λ makes
the logit-smoother a better approximation to the indicator function.
However, this fact is a double-edge sword: if the logit-smoother approximates the indicator function too well, the numerical diﬃculties of
using the unsmoothed A-R simulator will simply be reproduced in the

5.6. SIMULATION OF THE CHOICE PROBABILITIES

139

logit-smoothed simulator. The researcher wants to set λ low enough
to obtain a good approximation but not so low as to re-introduce numerical diﬃculties. There is little guidance on the appropriate level of
λ. Perhaps the best approach is for the researcher to experiment with
diﬀerent λ’s. The same draws of εn should be used with each diﬀerent
λ, so as to assure that diﬀerences in results are due to the change in
the λ rather than to diﬀerences in the draws.
McFadden (1989) describes other smoothing functions. For all of
them, the researcher must specify the degree of smoothing. An advantage of the logit smoother is its simplicity. Also, we will see in Chapter
6 that the logit-smoother applied to a probit or any other model constitutes a type of mixed logit speciﬁcation. That is, instead of seeing
the logit smoother as providing an approximation that has no behavioral relation to the model (simply serving a numerical purpose), the
logit smoother can be seen as arising from a particular type of error
structure in the behavioral model itself. Under this interpretation, the
logit formula applied to simulated utilities is not an approximation but
actually represents the true model.

5.6.3

GHK simulator

The most widely used probit simulator is called GHK, after Geweke
(1989, 1991), Hajivassiliou (as reported in Hajivassiliou and McFadden,
1998), and Keane (1990 1994), who developed the procedure. In a
comparison of numerous probit simulators, Hajivassiliou et al. (1996)
found GHK to be the most accurate in the settings that they examined.
Geweke, Keane and Runkle (1994) found the GHK simulator works
better than smoothed A-R. Experience has conﬁrmed its usefulness
and relative accuracy (e.g., Borsch-Supan and Hajivassiliou (1993)).
The GHK simulator operates on utility diﬀerences. The simulation
of probability Pni starts by subtracting the utility of alternative i from
each other alternative’s utility. Importantly, the utility of a diﬀerent
alternative is subtracted depending on which probability is being simulated: for Pni , Uni is subtracted from the other utilities, while for
Pnj , Unj is subtracted. This fact is critical to the implementation of
the procedure.
I will explain the GHK procedure ﬁrst in terms of a three-alternative
case, since that situation can be depicted graphically in two dimensions
for utility diﬀerences. I will then describe the procedure in general for

CHAPTER 5. PROBIT

140

any number of alternatives. Bolduc (1993, 1999 provide an excellent
alternative description of the procedure, along with methods to simulate the analytic derivatives of the probit probabilities. Keane (1994)
provides a description of the use of GHK for transition probabilities.
Three alternatives
We start with a speciﬁcation of the behavioral model in utilities: Unj =
Vnj + εnj , j = 1, 2, 3. The vector εn = εn1 , εn2 , εn3  ∼ N (0, Ω). We
assume that the reseacher has normalized the model for scale and level
such that the parameters that enter Ω are identiﬁed. Also, Ω can be
a parametric function of data, as with random taste variation, though
we do not show this dependence in our notation.
Suppose we want to simulate the probability of the ﬁrst alternative,
Pn1 . We re-express the model in utility diﬀerences by subtracting the
utility of alternative 1:
(Unj − Un1 ) = (Vnj − Vn1 ) + (εnj − εn1 )
Ũnj1 = Ṽnj1 + ε̃nj1
for j = 2, 3. The vector ε̃n1 = ε̃n21 , ε̃n31  is distributed N (0, Ω̃1 ) where
Ω̃1 is derived from Ω.
We take one more transformation to make the model more convenient for simulation. In particular, let L1 be the Choleski factor of Ω̃1 .
Since Ω̃1 is 2 × 2 in our current illustration, L1 is a lower-triangular
matrix that takes the form:


L1 =

caa 0
cab cbb



.

Using this Choleski factor, the original error diﬀerences, which are correlated, can be re-written as linear functions of uncorrelated standard
normal deviates:
ε̃n21 = caa η1
ε̃n31 = cab η1 + cbb η2
where η1 and η2 are iid N (0, 1). The error diﬀerences ε̃n21 and ε̃n31
are correlated because both of them depend on η1 . With this way of
expressing the error diﬀerences, the utility diﬀerences can be written:
Ũn21 = Ṽn21 + caa η1
Ũn31 = Ṽn31 + cab η1 + cbb η2 .

5.6. SIMULATION OF THE CHOICE PROBABILITIES

141

The probability of alternative 1 is Pn1 = P rob(Ũn21 < 0 and Ũn31 <
0) = P rob(Ṽn21 + ε̃n21 < 0 and Ṽn31 + ε̃n31 < 0). This probability is
hard to evaluate numerically in terms of the ε̃’s because they are correlated. However, using the transformation based on the Choleski factor,
the probability can be written in a way that involves independent random terms. The probability becomes a function of the one dimensional
standard cumulative normal distribution:
Pn1 = P rob(Ṽn21 + caa η1 < 0 and Ṽn31 + cab η1 + cbb η2 < 0)
= P rob(Ṽn21 + caa η1 < 0) × P rob(Ṽn31 + cab η1 + cbb η2 < 0 | Ṽn21 + caa η1 < 0)
= P rob(η1 < −Ṽn21 /caa ) × P rob(η2 < −(Ṽn31 + cab η1 )/cbb | η1 < −Ṽn21 /caa )
= Φ(−Ṽn21 /caa ) ×

 −Ṽn21 /caa
η1 =−∞

Φ(−(Ṽn31 + cab η1 )/cbb )φ(η1 )dη1

where Φ(·) is the standard normal cumulative distribution evaluated
at the point in the parentheses and φ(·) is the standard normal density. The ﬁrst term, Φ(−Ṽn21 /caa ) is easy to calculate: it is simply
the cumulative standard normal evaluated at −Ṽn21 /caa . Computer
packages contain fast routines for calculating the cumulative standard
normal. The second term is an integral. As we know, computers cannot integrate, and we use simulation to approximate integrals. This is
the heart of the GHK procedure: using simulation to approximate the
integral in the second term in Pn1 .
Let us examine this integral more closely. It is the integral over
a truncated normal, namely, over η1 up to −Ṽn21 /caa . The simulation proceeds as follows. Draw a value of η1 from a standard normal
density truncated above at −Ṽn21 /caa . For this draw, calculate the
term Φ(−(Ṽn31 + cab η1 )/cbb ). Repeat this process for many draws,
and average the results. This average is a simulated approximation
 Ṽn21 /caa
to η−1 =−∞
Φ(−(Ṽn31 + cab η1 )/cbb )φ(η1 )dη1 . The simulated probability is then obtained by multiplying this average by the value of
Φ(−Ṽn21 /caa), which is calculated exactly. Simple enough!
The question arises: how do we take a draw from a truncated
normal? We describe how to take draws from truncated univariate
distributions in section (9.2.4). The reader might want to jump ahead
and quickly review that section. For truncated normals, the process
is: Take a draw from a standard uniform, labeled µ. Then calculate
η = Φ−1 (µΦ(−Ṽn21 /caa )). The resulting η is a draw from a normal
density truncated from above at −Ṽn21 /caa .

CHAPTER 5. PROBIT

142

We can now put this all together to give the explicit steps that
are used for the GHK simulator in our three-alternative case. The
probability of alternative 1 is:
Pn1 = Φ(−Ṽn21 /caa ) ×

 −Ṽn21 /caa
η1 =−∞

Φ(−(Ṽn31 + cab η1 )/cbb )φ(η1 )dη1 .

This probability is simulated as follows:
1. Calculate k = Φ(−Ṽn21 /caa ).
2. Draw a value of η1 , labeled η1r , from a truncated standard normal
truncated at −Ṽn21 /caa . This is accomplished as follows:
(a) Draw a standard uniform µr .
(b) Calculate η1r = Φ−1 (µr Φ(−Ṽn21 /caa ).
3. Calculate g r = Φ(−(Ṽn31 + cab η1r )/cbb ).
r = k × gr .
4. The simulated probability for this draw is P̌n1

5. Repeat steps 1-4 R times and average the results. This average
 r
.
is the simulated probability: P̌n1 = (1/R) P̌n1
A graphical depiction is perhaps useful. Figure 5.3 shows the probability for alternative 1 in the space of independent errors η1 and η2 .
The x-axis is the value of η1 , and the y-axis is the value of η2 . The line
labeled A is where η1 is equal to −Ṽn21 /caa . The condition that η1 is
below −Ṽn21 /caa is met in the striped area to the left of line A. The line
labeled B is where η2 = −(Ṽn31 + cba η1 )/cbb . Note that the y-intercept
is where η1 = 0 such that η2 = −Ṽn31 /cbb at this point. The slope of
the line is −cba /cbb . The condition that η2 < −(Ṽn31 + cba η1 )/cbb is
satisﬁed below line B. The shaded area is where η1 is to the left of
line A and η2 is below line B. The mass of density in the shaded area
is therefore the probability that alternative 1 is chosen.
The probability (i.e., the shaded mass) is the mass of the striped
area times the proportion of this striped mass that is below line B.
The striped area has mass Φ(−Ṽn21 /caa ). This is easy to calculate.
For any given value of η1 , the portion of the striped mass that is below
line B is also easy to calculate. For example, in Figure 5.4, when
η1 takes the value η1r , then the probability that η2 is below line B is
the share of line C’s mass that is below line B. This share is simply

5.6. SIMULATION OF THE CHOICE PROBABILITIES

143

Figure 5.3: Probability of alternative 1.
Φ(−(Ṽn31 + cab η1r )/cbb ). The portion of the striped mass that is below
line B is therefore the average of Φ(−(Ṽn31 + cab η1r )/cbb ) over all values
of η1 that are to the left of line A. This average is simulated by taking
draws of η1 to the left of line A, calculating Φ(−(Ṽn31 + cab η1r )/cbb )
for each draw, and averaging the results. The probability is then this
average times the mass of the striped area, Φ(−Ṽn21 /caa ).
General model
We can now describe the GHK simulator in general terms quickly, since
the basic logic has already been discussed. This succinct expression
serves to reinforce the concept that the GHK simulator is actually
easier than it might at ﬁrst appear.
Utility is expressed as:
Unj = Vnj + εnj

j = 1, ..., J

εn =< εn1 , ..., εnJ >

εn : J × 1

εn ∼ N (0, Ω)
Transform to utility diﬀerences against alternative i:
Ũnji = Ṽnji + ε̃nji ,

j = i

144

CHAPTER 5. PROBIT

Figure 5.4: Probability that η2 is in the correct range given η1r .

5.6. SIMULATION OF THE CHOICE PROBABILITIES
ε̃ni =< ε̃n1 , ..., ε̃nJ >

145

where ... is over all except i

ε̃ni : (J − 1) × 1
ε̃ni ∼ N (0, Ω̃i )
where Ω̃i is derived from Ω.
Re-express the errors as a Choleski transformation of iid standard
normal deviates
Li s.t. Li Li = Ωi




c11 0 . . . . . . . . . 0


 c21 c22 0 . . . . . . 0 


Li =  c
c32 c33 0 . . . 0 
 31

..
.
·
Then stacking utilities Ũni = (Ũn1i , ..., ŨnJi ), we get the vector form of
the model
Ũni = Ṽni + Li ηn
where ηn =< η1n , ..., ηJ−1,n > is a vector of iid standard normal deviates: ηnj ∼ N (0, 1) ∀ j. Written explicitly the model is
Ũn1 = Ṽn1 + c11 η1
Ũn2 = Ṽn2 + c21 η1 + c22 η2
Ũn3 = Ṽn3 + c31 η1 + c32 η2 + c33 η3
and so on. The choice probabilities are
Pni = P rob(Ũnji < 0 ∀ j = i)


−Ṽn1i
= P rob η1 <
c11





−(Ṽn2i + c21 η1 )
−Ṽn1i
× P rob η2 <
| η1 <
c22
c11




−(Ṽn3i + c31 η1 + c32 η2 )
−Ṽn1i
−(Ṽn2i + c21 η1 )
× P rob η3 <
| η1 <
and η2 <
c33
c11
c22
×
and so on
The GHK simulator is calculated as follows:



CHAPTER 5. PROBIT

146
1. Calculate



−Ṽn1i
P rob η1 <
c11





−Ṽn1i
=Φ
c11



2. Draw a value of η1 , labeled η1r , from a truncated standard normal
truncated at −Ṽ1in /c11 .This draw is obtained as follows:
(a) Draw a standard uniform µr1
(b) Calculate η1r = Φ−1 (µr1 Φ(−Ṽn1i /c11 ))
3. Calculate


−(Ṽn2i + c21 η1 )
| η1 = η1r
P rob η2 <
c22





−(Ṽn2i + c21 η1r )
=Φ
c22



4. Draw a value of η2 , labeled η2r , from a truncated standard normal truncated at −(Ṽn2i + c21 η1r )/c22 . This draw is obtained as
follows:
(a) Draw a standard uniform µr1
(b) Calculate η2r = Φ−1 (µr2 Φ(−(Ṽn2i + c21 η1r )/c22 ))
5. Calculate


−(Ṽn3i + c31 η1 + c32η2 )
| η1 = η1r , η2 = η2r
P rob η3 <
c33





−(Ṽn3i + c31 η1r + c32 η2r )
=Φ
c33

6. And so on for all alternatives but i.
7. The simulated probability for this rth draw of η1 , η2 , ... is calculated as


r
P̌ni

−Ṽn1i
= Φ
c11




−(Ṽn2i + c21 η1r )
× Φ
c22





−(Ṽn3i + c31 η1r + c32 η2r )
× Φ
c33
× etc.
8. Repeat steps 1–7 many times, for r = 1, ..., R.





5.6. SIMULATION OF THE CHOICE PROBABILITIES

147

9. The simulated probability is
P̌in =

1
R

r
.
P̌in
r

GHK simulator with maximum likelihood estimation
There are several issues that need to be addressed when using the
GHK simulator in maximum likelihood estimation. First, in the loglikelihood function, we use the probability of the decision-maker’s chosen alternative. Since diﬀerent decision-makers choose diﬀerent alternatives, Pni must be calculated for diﬀerent i’s. The GHK simulator
takes utility diﬀerences against the alternative for which the probability is being calculated, and so diﬀerent utility diﬀerences must be taken
for decision-makers who chose diﬀerent alternatives. Second, for a person who chose alternative i, the GHK simulator uses the covariance
matrix Ω̃i , while for a person who chose alternative j, the matrix Ω̃j is
used. Both of these matrices are derived from the same covariance matrix Ω of the original errors. We must assure that the parameters in Ω̃i
are consistent with those in Ω̃j , in the sense that they both are derived
from a common Ω. Third, we need to assure that the parameters that
are estimated by maximum likelihood imply covariance matrices Ωj ∀ j
that are positive deﬁnite, as a covariance matrix must be. Fourth, as
always, we must make sure that the model is normalized for scale and
level of utility, so that the parameters are identiﬁed.
Researchers use various procedures to address these issues. I will
describe the procedure that I use.
To assure that the model is identiﬁed, I start with the covariance
matrix of scaled utility diﬀerences with the diﬀerences taken against
the ﬁrst alternative. This is matrix Ω̃1 which is (J − 1) × (J − 1). To
assure that the covariance matrix is positive deﬁnite, I parameterize
the model in terms of the Choleski factor of Ω̃1 . That is, I start with a
lower-triangular matrix that is (J − 1) × (J − 1) whose top-left element
is 1:


1
0 ... ... ... 0


 c21 c22 0 . . . . . . 0 


L1 =  c
c32 c33 0 . . . 0 
 31

..
.
·
The elements ck of this Choleski factor are the parameters that are
estimated in the model. Any matrix that is the product of a lower-

CHAPTER 5. PROBIT

148

triangular full-rank matrix multiplied by itself is positive deﬁnite. So
by using the elements of L1 as the parameters, I am assured that Ω̃1
is positive deﬁnite for any estimated values of these parameters.
The matrix Ω for the J non-diﬀerenced errors is created from L1 .
I create a J × J Choleski factor for Ω by adding a row of zeros at the
top of L1 and a column of zeros at the left. The resulting matrix is


0 0 ... ... ... ...
 0 1
0 ... ... ...


0
c
c
0 ... ...

21
22
L=
 0 c31 c32 c33 0 . . .

.
0 ..
···



0
0 


0 .

0 


Then Ω is calculated as LL . With this Ω, I can derive Ω̃j for any
j. Note that Ω constructed in this way is fully general (i.e., allows
any substitution pattern), since it utilizes all the parameters in the
normalized Ω̃1 .
Utility is expressed in vector form stacked by alternatives: Un =
Vn + εn , εn ∼ N (0, Ω). Consider a person who has chosen alternative
i. For the log-likelihood function, we want to calculate Pni . Recall the
matrix Mi that we introduced in section (5.1). Utility diﬀerences are
taken using this matrix: Ũni = Mi Un , Ṽni = Mi Vn , and ε̃ni = Mi εn .
The covariance of the error diﬀerences ε̃ni is calculated as Ω̃i = Mi ΩMi .
The Choleski factor of Ω̃i is taken and labeled Li . (Note that L1
obtained here will necessarily be the same as the L1 that we used
at the beginning to parameterize the model.) The person’s utility
is expressed as: Ũni = Ṽni + Li ηn where ηn is a (J − 1) vector of
iid standard normal deviates. The GHK simulator is applied to this
expression.
This procedure satisﬁes all of our requirements. The model is necessarily normalized for scale and level since we parameterize the model
in terms of the Choleski factor L1 of the covariance of scaled error
diﬀerences, Ω̃1 . Each Ω̃i is consistent with each other Ω̃j for j = i,
because they are both derived from the same Ω (which is constructed
from L1 .) Each Ω̃i is positive deﬁnite for any values of the parameters,
because the parameters are the elements of L1 . As stated above, any
matrix that is the product of a lower triangular matrix multiplied by
itself is positive deﬁnite, and so Ω̃1 = LL is positive deﬁnite. And each
of the other Ω̃j ’s, for j = 2, . . . , J, is also positive deﬁnite, since they
are constructed to be consistent with Ω1 , which is positive deﬁnite.

5.6. SIMULATION OF THE CHOICE PROBABILITIES

149

GHK as importance sampling
As I described above in the three-alternative case, the GHK simulator
provides a simulated approximation of the integral
 −Ṽn21 /caa
η1 =−∞

Φ(−(Ṽn31 + cab η1 )/cbb )φ(η1 )dη1 .

The GHK simulator can be interpreted in another way that is often
useful.
Importance sampling is a way of transforming an integral to be
more convenient to simulate. The procedure is described in section
(9.2.7), and readers might ﬁnd it useful to jump ahead to review that
section. Importance
sampling can be summarized following. Consider

any integral t̄ = t(ε)g(ε)dε over density g. Suppose that another density exists from which it is easy to draw. Label this other density f (ε).
The density g is called the target density and f is the generating density. The integral can be rewritten as t̄ = [t(ε)g(ε)/f (ε)]f (ε)dε. This
integral is simulated by taking draws from f , calculating [t(ε)g(ε)/f (ε)]
for each draw, and averaging the results. This procedure is called importance sampling because each draw from f is weighted by g/f when
taking the average of t; the weight g/f is the “importance” of the draw
from f . This procedure is advantageous if (1) it is easier to draw from
f than g, and/or (2) the simulator based on [t(ε)g(ε)/f (ε)] has better
properties (e.g., smoothness) than the simulator based on t(ε).
The GHK simulator can be seen as making this type of transformation, and hence as being a type of importance sampling. Let η be
a vector of J − 1 iid standard normal deviates. The choice probability
can be expressed as


Pni =

I(η ∈ B)g(η)dη

(5.7)

where B = {η s.t Ũnji < 0 ∀ j = i} is the set of η’s that result in
i being chosen; g(η) = φ(η1 )...φ(ηJ−1 ) is the density where φ denotes
the standard normal density; and utilities are:
Ũn1 = Ṽn1 + c11 η1
Ũn2 = Ṽn2 + c21 η1 + c22 η2
Ũn3 = Ṽn3 + c31 η1 + c32 η2 + c33 η3

CHAPTER 5. PROBIT

150

etc.
The direct way to simulate this probability is to take draws of η,
calculate I(η ∈ B) for each draw and average the results. This is the
A-R simulator. This simulator has the unfortunate properties that it
can be zero and is not smooth.
For GHK we draw η from a diﬀerent density, not from g(η). Recall
that for GHK, we draw η1 from a standard normal density truncated at
1)
, that
−Ṽn1i /c11 . The density of this truncated normal is Φ(−φ(η
Ṽn1i /c11 )
is: the standard normal density normalized by the total probability
below the truncation point. Draws of η2 , η3 , and so on are also taken
from truncated densities, but with diﬀerent truncation points. Each
φ(η )
of these truncated densities takes the form Φ(·)j for some truncation
point in the denominator. The density from which we draw for the
GHK simulator is therefore:
f (η) =


φ(η1 )
φ(η2 )

 Φ(−Ṽn1i /c11 ) × Φ(−(Ṽn2i +c21 η1 )/c22 ) × etc. for η ∈ B



(5.8)

0 for η ∈
/B

Note that we only take draws that are consistent with the person choosing alternative i (since we draw from the correctly truncated distributions). So f (η) = 0 for η ∈
/ B.
Recall that for a draw of η within the GHK simulator, we calculate:


−Ṽn1i
P̌in (η) = Φ
c11





−(Ṽn2i + c21 η1 )
× Φ
c22
×

etc.



(5.9)

Note that this expression is the denominator of f (η) for η ∈ B, given
in equation (5.8). Using this fact, we can re-write the density f (η) as:
f (η) =

 g(η)

 P̌ni (η) for η ∈ B



0 for η ∈
/B

With this expression for f (η), we can prove that the GHK simulator, P̌in (η), is unbiased for Pni (η):


E(P̌in (η)) =

P̌in (η)f (η)dη

5.6. SIMULATION OF THE CHOICE PROBABILITIES


=
η∈B

P̌in (η)



g(η)
dη
P̌in (η)

151

by (5.6.3)

g(η)dη

=
η∈B



=

I(η ∈ B)g(η)dη

= Pin .
The interpretation of GHK as an importance sampler is also obtained from this expression:


Pin =


I(η ∈ B)g(η)dη

f (η)
dη
f (η)

g(η)
=
f (η)dη
I(η ∈ B)
g(η)/P̌in (η)

=



=


=

I(η ∈ B)g(η)

by (5.6.3)

I(η ∈ B)P̌in (η)f (η)dη
P̌in (η)f (η)dη

where the last equality is because f (η) > 0 only when η ∈ B. The GHK
procedure takes draws from f (η), calculates P̌in (η) for each draw, and
averages the results. Essentially, GHK replaces the 0-1 I(η ∈ B) with
smooth P̌in (η) and makes the corresponding change in the density from
g(η) to f (η).

152

CHAPTER 5. PROBIT

Chapter 6

Mixed Logit
6.1

Choice probabilities

Mixed logit is a highly ﬂexible model that can approximate any random utility model (McFadden and Train, 2000). It resolves the three
limitations of standard logit by allowing for random taste variation,
unrestricted substitution patterns, and correlation in unobserved factors over time. Unlike probit, it is not restricted to normal distributions. Its derivation is straightforward, and simulation of its choice
probabilities is computationally simple.
Like probit, the mixed logit model has been known for many years
but has only become fully applicable since the advent of simulation.
The ﬁrst application of mixed logit was apparently the automobile demand models created jointly by Boyd and Mellman (1980) and Cardell
and Dunbar (1980). In these studies, the explanatory variables did not
vary over decision-makers and the observed dependent variable was
market shares rather than individual customer’s choices. As a result,
the computationally intensive integration that is inherent in mixed
logit (as explained below) needed to be performed only once for the
market as a whole, rather than for each decision-maker in a sample.
Early applications on customer-level data, such as Train et al. (1987)
and Ben-Akiva et al. (1993), included only one or two dimensions of integration, which could be calculated by quadrature. Improvements in
computer speed and in our understanding of simulation methods have
allowed the full power of mixed logits to be utilized. Among the studies to evidence this power are those by Bhat (1998a) and Brownstone
and Train (1999) on cross-sectional data and Erdem (1996), Revelt
153

CHAPTER 6. MIXED LOGIT

154

and Train (1998), and Bhat (2000) on panel data. The description in
the current chapter draws heavily from Train (1999).
Mixed logit models can be derived under a variety of diﬀerent behavioral speciﬁcations, and each derivation provides a particular interpretation. The mixed logit model is deﬁned on the basis of the
functional form for its choice probabilities. Any behavioral speciﬁcation whose derived choice probabilities take this particular form is
called a mixed logit model.
Mixed logit probabilities are the integral of standard logit probabilities over a density of parameters. Stated more explicitly, a mixed
logit model is any model whose choice probabilities can be expressed
in the form:

Pni = Lni (β)f (β)dβ
where Lni (β) is the logit probability evaluated at parameters β:
eVni (β)
Lni (β) = J
Vnj (β)
j=1 e
and f (β) is a density function. Vni (β) is a portion of utility, which
depends on parameters β. If utility is linear in β, then Vni (β) = β  xni .
In this case, the mixed logit probability takes its usual form:
 

Pni =



eβ xni
 βx
nj
je



f (β)dβ.

(6.1)

The mixed logit probability is a weighted average of the logit formula evaluated at diﬀerent values of β, with the weights given by
density f (β). In the statistics literature, the weighted average of several functions is called a mixed function, and the density that provides
the weights is called the mixing distribution. Mixed logit is a mixture
of the logit function evaluated at diﬀerent β’s with f (β) as the mixing
distribution.
Standard logit is a special case where the mixing distribution f (β)
is degenerate at ﬁxed parameters b: f (β) = 1 for β = b and zero for
β = b. The choice probability (6.1) then becomes the simple logit
formula

eb xni
Pni =  b x .
nj
je
The mixing distribution f (β) can be discrete, with β taking a ﬁnite set of distinct values. Suppose β takes M possible values labeled

6.1. CHOICE PROBABILITIES

155

b1 , . . . , bM with probability sm that β = bm . In this case, the mixed
logit becomes the “latent class model” that has long been popular in
psychology and marketing; examples include Kamakura and Russell
(1989) and Chintagunta, Jain and Vilcassim (1991). The choice probability is:



M
ebm xni
sm  b x
.
Pni =
m nj
je
m=1
This speciﬁcation is useful if there are M segments in the population,
each of which has its own choice behavior or preferences. The share of
the population in segment m is sm , which the researcher can estimate
within the model along with the b’s for each segment.
In most applications that have actually been called mixed logit
(such as those cited in the introductory paragraphs above), f (β) is
speciﬁed to be continuous. For example, the density of β can be
speciﬁed to be normal with mean b and covariance W . The choice
probability under this density becomes:
 

Pni =



eβ xni
 βx
nj
je



φ(β | b, W )dβ

where φ(β | b, W ) is the normal density with mean b and covariance W .
The researcher estimates b and W . Lognormal, uniform, triangular,
gamma, or any other distribution can be used. As will be shown in section 6.5, by specifying the explanatory variables and density appropriately, the researcher can represent any utility-maximizing behavior by
a mixed logit model, as well as many forms of non-utility-maximizing
behavior.
Tests for the need for a non-degenerate mixing distribution, as
well as the adequacy of any given distribution, have been developed
by McFadden and Train (2000) and Chesher and Santos-Silva (2002).
Several studies have compared discrete and continuous mixing distributions within the context of mixed logit; see, for example, Wedel and
Kamakura (2000) and Ainslie, Andrews and Currim (2001).
An issue of terminology arises with mixed logit models. There
are two sets of parameters in a mixed logit model. First, we have
the parameters β, which enter the logit formula. These parameters
have density f (β). The second set are parameters that describe this
density. For example, if β is normally distributed with mean b and
covariance W , then b and W are parameters that describe the density

CHAPTER 6. MIXED LOGIT

156

f (β). Usually (though not always, as noted below), the researcher is
interested in estimating the parameters of f .
Denote the parameters that describe the density of β as θ. The
more appropriate way to denote this density is f (β | θ). The mixed
logit choice probabilities do not depend on the values of β. These
probabilities are Pni = Lni (β)f (β | θ)dβ, which is a function of θ.
The parameters β are integrated out. In this sense, the β’s are similar
to the εnj ’s, in that both are random terms that are integrated out to
obtain the choice probability.
Under some derivations of the mixed logit model, the values of
β have interpretable meaning as representing the tastes of individual
decision-makers. In these cases, the researcher might want to obtain
information about the β’s for each sampled decision-maker, as well
as the θ that describes the distribution of β’s across decision-makers.
In Chapter 11, we describe how the researcher can obtain this information based on estimates of θ and the observed choices of each
decision-maker. In the current chapter, we describe the estimation and
interpretation of θ, using classical estimation procedures. In Chapter
12, we describe Bayesian procedures that provide information about θ
and each decision-maker’s β simultaneously.

6.2

Random coeﬃcients

The mixed logit probability can be derived from utility-maximizing
behavior in several ways that are formally equivalent but provide different interpretations. The most straightforward derivation, and most
widely used in recent applications, is based on random coeﬃcients.
The decision-maker faces a choice among J alternatives. The utility
of person n from alternative j is speciﬁed as
Unj = βn xnj + εnj
where xnj are observed variables that relate to the alternative and
decision-maker, βn is a vector of coeﬃcients of these variables for person n representing that person’s tastes, and εnj is a random term that
is iid extreme value. The coeﬃcients vary over decision-makers in the
population with density f (β). This density is a function of parameters
θ that represent, for example, the mean and covariance of the β’s in
the population. This speciﬁcation is the same as for standard logit
except that β varies over decision-makers rather than being ﬁxed.

6.2. RANDOM COEFFICIENTS

157

The decision-maker knows the value of his own βn and εnj ’s for
all j and chooses alternative i if and only if Uni > Unj ∀j = i. The
researcher observes the xnj ’s but not βn or the εnj ’s. If the researcher
observed βn , then the choice probability would be standard logit, since
the εnj ’s are iid extreme value. That is, the probability conditional on
βn is

eβn xni
Lni (βn ) =  β  x .
n nj
je
However, the researcher does not know βn and therefore cannot condition on β. The unconditional choice probability is therefore the integral
of Lni (βn ) over all possible variables of βn :
 

Pni =



eβ xni
 βx
nj
je



f (β)dβ

which is the mixed logit probability (6.1).
The researcher speciﬁes a distribution for the coeﬃcients and estimates the parameters of that distribution. In most applications,
such as Revelt and Train (1998), Mehndiratta (1996), Ben-Akiva and
Bolduc (1996), f (β) has been speciﬁed to be normal or lognormal:
β ∼ N (b, W ) or ln(β) ∼ N (b, W ) with parameters b and W that are
estimated. The lognormal distribution is useful when the coeﬃcient
is known to have the same sign for every decision-maker, such as a
price coeﬃcient that is known to be negative for everyone. Revelt and
Train (2000), Hensher and Greene (2001), and Train (2001) have used
triangular and uniform distributions. With the uniform density, β is
distributed uniformly between b − s and b + s, where the mean b and
spread s are estimated. The triangular distribution has positive density that starts at b − s, rises linearly to b, and then drops linearly to
b + s, taking the form of a tent or triangle. The mean b and spread
s is estimated, like with the uniform, but the density is peaked instead of ﬂat. These densities have the advantage of being bounded on
both sides, thereby avoiding the problem that can arise with normals
and lognormals of unreasonably large coeﬃcients for some share of
decision-makers. By constraining s = b, the researcher can assure that
the coeﬃcients have the same sign for all decision-makers. Siikamaki
(2001) and Siikamaki and Layton (2001) use the Rayleigh distribution
(Johnson, Kotz and Balakrishnan, 1994), which is on one side of zero
like the lognormal but, as these researchers found, can be easier for

CHAPTER 6. MIXED LOGIT

158

estimation than the lognormal. Revelt (1999) used truncated normals.
As these examples indicate, the researcher is free to specify a distribution that satisﬁes his concepts about behavior in his own application.
Variation in tastes that are related to observed attributes of the
decision-maker are captured through speciﬁcation of the explanatory
variables and/or the mixing distribution. For example, cost might be
divided by the decision-maker’s income to allow the value or relative
importance of cost to decline as income rises. The random coeﬃcient
of this variable then represents the variation over people with the same
income in the value that they place on cost. The mean valuation of
cost declines with income while the variance around the mean is ﬁxed.
Observed attributes of the decision-maker can also enter f (β) so that
higher-order moments of taste variation can also depend on attributes
of the decision-maker. For example, Bhat (1998a) and Bhat (2000)
specify f (β) to be log-normal with the mean and variance being a
function of decision-maker characteristics.

6.3

Error-components

A mixed logit model can be used without a random-coeﬃcients interpretation, as simply representing error components that create correlations among the utilities for diﬀerent alternatives. Utility is speciﬁed
as
Unj = α xnj + µn znj + εnj
where xnj and znj are vectors of observed variables relating to alternative j, α is a vector of ﬁxed coeﬃcients, µ is a vector of random terms
with zero mean, and εnj is distributed iid extreme value. The terms
in znj are error components that, along with εnj , deﬁne the stochastic
portion of utility. That is, the unobserved (random) portion of utility is
ηnj = µn znj + εnj , which can be correlated over alternatives depending
on the speciﬁcation of znj . For the standard logit model, znj is identically zero, such that there is no correlation in utility over alternatives.
This lack of correlation gives rise to the IIA property and its restrictive
substitution patterns. With non-zero error components, utility is correlated over alternatives: Cov(ηni , ηnj ) = E(µn zni +εni )(µn znj +εnj ) =
 Wz
zni
nj where W is the covariance of µn . Utility is correlated over
alternatives even when, as in most speciﬁcations, the error components
are independent such that W is diagonal.

6.3. ERROR-COMPONENTS

159

Various correlation patterns, and hence substitution patterns, can
be obtained by appropriate choice of variables to enter as error components. For example, an analog to nested logit is obtained by specifying a dummy variable for each nest that equals 1 for each alternative
in the nest and zero for alternatives outside the nest. With K non
overlapping nests, the error components are µn znj = K
k=1 µnk djk ,
where djk = 1 if j is in nest k and zero otherwise. It is convenient
in this situation to specify the error components to be independently
normally distributed: µnk iid N (0, σk ). The random term µnk enters
the utility of each alternative in nest k, inducing correlation among
these alternatives. It does not enter any of the alternatives in other
nests, thereby not inducing correlation between alternatives in the nest
with those outside the nest. The variance σk captures the magnitude
of the correlation. It plays an analogous role as the “inclusive value
coeﬃcient” of nested logit models.
To be more precise, the covariance between two alternatives in nest
k is Cov(ηni , ηnj ) = E(µk + εni )(µk + εnj ) = σk . The variance for each
of the alternatives in nest k is V ar(ηni ) = E(µk + εni )2 = σk + π 2 /6,
since the variance of the extreme value term, εni , is π 2 /6 (see section
3.1). The correlation between any two alternatives within nest k is
therefore σk /(σk + π 2 /6). Constraining the variance of each nest’s
error component to be the same for all nests (i.e., constraining σk =
σ, k = 1, . . . , K), is analogous to constraining the log-sum coeﬃcient
to be the same for all nests in a nested logit. This constraint also
assures that the mixed logit model is normalized for scale and level.
Allowing diﬀerent variances for the random terms for diﬀerent nests
is analogous to allowing the inclusive value coeﬃcient to diﬀer across
nests in a nested logit. An analog to overlapping nests is captured
with dummies that identify overlapping sets of alternatives, as in Bhat
(1998a). An analog to heteroskedastic logit (discussed in section 4.5)
is obtained by entering an error component for each alternative. BenAkiva, Bolduc and Walker (2001) provide guidance on how to specify
these variables appropriately.
Error-components and random-coeﬃcients speciﬁcations are formally equivalent. Under the random-coeﬃcient motivation, utility is
speciﬁed as Unj = βn xnj + εnj with random βn . The coeﬃcients βn
can be decomposed into their mean denoted α and deviations denoted
µn such that Unj = α xnj + µn xnj + εnj , which has error components
deﬁned by znj = xnj . Conversely, under an error-components moti-

160

CHAPTER 6. MIXED LOGIT

vation, utility is Unj = α xnj + µn znj + εnj , which is equivalent to
a random parameters model with ﬁxed coeﬃcients for variables xnj
and random coeﬃcients with zero means for variables znj . If xnj and
znj overlap (in the sense that some of the same variables enter xnj
and znj ,) the coeﬃcients of these variables can be considered to vary
randomly with mean α and the same distribution as µn around their
mean.
Though formally equivalent, the way a researcher thinks about the
model aﬀects the speciﬁcation of the mixed logit. For example, when
thinking in terms of random parameters, it is natural to allow each
variable’s coeﬃcient to vary and perhaps even to allow correlations
among the coeﬃcients. This is the approach pursued by Revelt and
Train (1998). However, when the primary goal is to represent substitution patterns appropriately through the use of error components,
the emphasis is placed on specifying variables that can induce correlations over alternatives in a parsimonious fashion so as to provide
suﬃciently realistic substitution patterns. This is the approach taken
by Brownstone and Train (1999). The goals diﬀered in these studies, with Revelt and Train being interested in the pattern of tastes,
while Brownstone and Train were more concerned with prediction. The
number of explanatory variables also diﬀered, with Revelt and Train
examining six variables, such that estimating the joint distribution of
their coeﬃcients was a reasonable goal, while Brownstone and Train
included 26 variables. Expecting to estimate the distribution of 26
coeﬃcients might be unreasonable, and yet thinking in terms of random parameters instead of error components can lead the researcher
to such unreasonable expectations. It is important to remember that
the mixing distribution, whether motivated by random parameters or
error components, captures variance and correlations in unobserved
factors. There is a natural limit on how much one can learn about
things that are not seen.

6.4

Substitution patterns

Mixed logit does not exhibit independence from irrelevant alternatives
(IIA) or the restrictive substitution patterns of logit. The ratio of
mixed logit probabilities Pni /Pnj depends on all the data, including
attributes of alternatives other than i or j. The denominators of the
logit formula are inside the integral and therefore do not cancel. The

6.5. APPROXIMATION TO ANY RANDOM UTILITY MODEL161
percent change in the probability for one alternative given a change in
the m-th attribute of another alternative is:

1
=
−
β m Lni (β)Lnj (β)f (β)dβ
Enixm
nj
Pni



Lni (β)
m
f (β)dβ,
= − β Lnj (β)
Pni
where β m is the m-th element of β. This elasticity is diﬀerent for each
alternative i. A 10 percent reduction for one alternative need not imply
(as with logit) a 10 percent reduction in each other alternative. Rather,
the substitution pattern depends on the speciﬁcation of the variables
and mixing distribution, which can be determined empirically.
Note that the percent change in probability depends on the correlation between Lni (β) and Lnj (β) over diﬀerent values of β, which
is determined by the researcher’s speciﬁcation of variables and mixing
distribution. For example, to represent a situation where an improvement in alternative j draws more proportionately from alternative i
than alternative k, the researcher can specify an element of x that is
positively correlated between i and j but uncorrelated or negatively
correlated between k and j, with a mixing distribution that allows the
coeﬃcient of this variable to vary.

6.5

Approximation to any random utility model

McFadden and Train (2000) show that any random utility model (RUM)
can be approximated to any degree of accuracy by a mixed logit with
appropriate choice of variables and mixing distribution. This proof is
analogous to the RUM-consistent approximations provided by Dagsvik
(1994). An intuitive explanation can easily be provided. Suppose the
true model is Unj = αn znj where znj are variables related to alternative j and α follows any distribution f (α). Any random utility
model can be expressed in this form. (The more traditional nota = x , d  and
tion of Unj = βn xnj + εnj is obtained by letting znj
nj j


α = βn , εnj  and f (α) the joint density of βn and εnj ∀ j.) Conditional on α, the person’s choice is fully determined since Unj is then
known for each j. The conditional probability is therefore:
qni (α) = I(αn zni > αn znj ∀ j = i)
where I(·) is the 1-0 indicator of whether the event in parentheses
occurs. This conditional probability is deterministic in the sense that

CHAPTER 6. MIXED LOGIT

162

the probability is either zero or one: conditional on all the unknown
random terms, the decision-maker’s choice is completely determined.
The unconditional choice probability is the integral of qni (α) over α:


Qni =

I(αn zni > αn zni ∀ j = i)f (α)dα.

We can approximate this probability with a mixed logit. Scale
∗ = (α/λ)z . This scaling does not change
utility by λ, such that Unj
nj
the model since behavior is unaﬀected by the scale of utility. Then add
an iid extreme value term: εnj . The addition of the extreme value term
does change the model, since it changes the utility of each alternative.
We add it because doing so gives us a mixed logit. And, as we will
show (this is the purpose of the proof), adding the extreme value term
is innocuous. The mixed logit probability based on this utility is:
 

Pni =



e(α/λ) zni
 (α/λ) z
nj
je



f (α)dβ.

As λ approaches zero, the coeﬃcients α/λ in the logit formula grow
large and Pni approaches a 1-0 indicator for the alternative with the
highest utility. That is, the mixed logit probability Pni approaches the
true probability Qni as λ approaches zero. By scaling the coeﬃcients
upwards suﬃciently, the mixed logit based on these scaled coeﬃcients
is arbitrarily close to the true model. Srinivasan and Mahmassani
(2000) use this concept of raising the scale of coeﬃcients to show that
a mixed logit can approximate a probit model; the concept applies
generally to approximate any random utility model.
Recall that we added an iid extreme value term to the true utility of
each alternative. These terms change the model because the alternative
with highest utility before the terms are added might not have highest
utility after adding them (since a diﬀerent amount is added to each
utility). However, by raising the scale of utility suﬃciently, we can be
essentially sure that the addition of the extreme value terms has no
eﬀect. Consider a two alternative example. Suppose, using the true
model with its original scaling, that the utility of alternative 1 is 0.5
units higher than the utility of alternative 2, such that alternative 1
is chosen. Suppose we add an extreme value term to each alternative.
There’s a good chance, given the variance of these random terms, that
the value obtained for alternative 2 will exceed that for alternative 1 by
at least half a unit, such that alternative 2 obtains the highest utility

6.6. SIMULATION

163

instead of 1 after adding them. The addition of the extreme value terms
changes the model since it changes which alternative has the highest
utility. Suppose, however, that we scale up the original utility by a
factor of 10 (i.e., λ = 0.10). The utility for alternative 1 now exceeds
the utility for alternative 2 by 5 units. It is highly unlikely that adding
extreme value terms to these utilities will reverse this diﬀerence. That
is, it is highly unlikely, in fact next to impossible, that the value of
εn2 that is added to the utility of alternative 2 is larger by 5 than the
εn1 that is added to the utility of alternative 1. If scaling up by 10
is not suﬃcient to assure that adding the extreme value term has no
eﬀect, then the original utilities can be scaled up by 100 or 1000. At
some point, a scale will be found for which the addition of the extreme
value terms has no eﬀect. Stated succinctly: adding an extreme value
term to true utility, which makes the model into a mixed logit, does
not change utility in any meaningful way when the scale of the utility
is suﬃciently large. A mixed logit can approximate any random utility
model simply by scaling up utility suﬃciently.
This demonstration is not intended to suggest that raising the scale
of utility is actually how the researcher would proceed in specifying a
mixed logit as an approximation to the true model. Rather, the demonstration simply indicates that if no other means for specifying a mixed
logit to approximate the true model can be found, then this re-scaling
procedure can be used to attain the approximation. Usually, a mixed
logit can be speciﬁed that adequately reﬂects the true model without
needing to resort to an upward scaling of utility. For example, the true
model will usually contain some iid term that is added to the utility of
each alternative. Assuming an extreme value distribution for this term
is perhaps close enough to reality to be empirically indistinguishable
from other distributional assumptions for the iid term. In this case,
the scale of utility is determined naturally by the variance of this iid
term. The researcher’s task is simply to ﬁnd variables and a mixing
distribution that capture the other parts of utility, namely, the parts
that are correlated over alternatives or heteroskedastic.

6.6

Simulation

Mixed logit is well suited to simulation methods for estimation. Utility
is Unj = βn xnj + εnj where the the coeﬃcients βn are distributed with
density f (β | θ) where θ refers collectively to the parameters of this

CHAPTER 6. MIXED LOGIT

164

distribution (such as the mean and covariance of β). The researcher
speciﬁes the functional form f (·) and wants to estimate the parameters
θ. The choice probabilities are


Pni =
where:

Lni (β)f (β | θ)dβ


eβ xni
.
Lni (β) = J
β  xnj
j=1 e

The probabilities are approximated through simulation for any given
value of θ. (1) Draw a value of β from f (β | θ) and label it β r with the
superscript r = 1 referring to the ﬁrst draw. (2) Calculate the logit
formula Lni (β r ) with this draw. (3) Repeat steps 1 and 2 many times,
and average the results. This average is the simulated probability:
P̌ni =

1 R
Lni (β r )
R r=1

where R is the number of draws. P̌ni is an unbiased estimator of Pni
by construction. Its variance decreases as R increases. It is strictly
positive, such that ln(P̌ni ) is deﬁned, which is useful for approximating
the log-likelihood function below. P̌ni is smooth (twice diﬀerentiable)
in the parameters θ and the variables x, which facilitates the numerical
search for the maximum of the likelihood function and the calculation
of elasticities. And P̌ni sums to one over alternatives, which is useful
in forecasting.
The simulated probabilities are inserted into the log-likelihood function to give a simulated log-likelihood:
N

J

dnj lnP̌nj

SLL =
n=1 j=1

where dnj = 1 if n chose j and zero otherwise. The maximum simulated
likelihood estimator (MSLE), is the value of θ that maximizes SLL.
The properties of this estimator are discussed in Chapter 10. Usually,
diﬀerent draws are taken for each observation. This procedure maintains independence over decision-makers of the simulated probabilities
that enter SLL. Lee (1992) describes the properties of MSLE when
the same draws are used for all observations.

6.7. PANEL DATA

165

The simulated mixed logit probability can be related to acceptreject (A-R) methods of simulation. A-R simulation is described in
section (5.6) for probit models, but it is applicable more generally.
For any random utility model, the A-R simulator is constructed as
follows: (1) A draw of the random terms is taken. (2) The utility of
each alternative is calculated based on this draw, and the alternative
with the highest utility is identiﬁed. (3) Steps 1 and 2 are repeated
many times. (4) The simulated probability for an alternative is calculated as the proportion of draws for which that alternative has the
highest utility. The A-R simulator is unbiased by construction. However, it is not strictly positive for any ﬁnite number of draws. It is
also not smooth but rather a step-function: constant within ranges of
parameter for which the identity of the alternative with the highest
utility does not change for any draws, and with jumps where changes
in the parameters change the identity of the alternative with the highest utility. Numerical methods for maximization based on the A-R
simulator are hampered by these characteristics. To address these numerical problems, the A-R simulator can be smoothed by replacing the
0-1 indicator with the logit formula. As discussed in section (5.6.2),
the logit-smoothed A-R simulator can approximate the A-R simulator
arbitrarily closely by scaling utility appropriately.
The mixed logit simulator can be seen as a logit-smoothed A-R
simulator of any random utility model: draws of the random terms
are taken, utility is calculated for these draws, the calculated utilities
are inserted into the logit formula, and the results are averaged. The
theorem that a mixed logit can approximate any random utility model
(section 6.5) can be viewed from this perspective. We know from section (5.6.2) that the logit-smoothed A-R simulator can be arbitrarily
close to the A-R simulator for any model, with suﬃcient scaling of utility. Since the mixed logit simulator is equivalent to a logit-smoothed
A-R simulator, the simulated mixed logit model can be arbitrarily close
to the A-R simulator of any model.

6.7

Panel data

labelsec:mxpanel
The speciﬁcation is easily generalized to allow for repeated choices
by each sampled decision-maker. The simplest speciﬁcation treats the
coeﬃcients that enter utility as varying over people but being constant

CHAPTER 6. MIXED LOGIT

166

over choice situations for each person. Utility from alternative j in
choice situation t by person n is Unjt = βn xnjt +εnjt with εnjt being iid
extreme value over time, people, and alternatives. Consider a sequence
of alternatives, one for each time period, i = {i1 , . . . , iT }. Conditional
on β the probability that the person makes this sequence of choices is
the product of logit formulas:
T

Lni (β) =
t=1



eβn xnit t
 β x
n njt
je

!

(6.2)

since the εnjt ’s are independent over time. The unconditional probability is the integral of this product over all values of β:


Pni =

Lni (β)f (β)dβ.

(6.3)

The only diﬀerence between a mixed logit with repeated choices and
that with only one choice per decision-maker is that the integrand
involves a product of logit formulas, one for each time period, rather
than just one logit formula. The probability is simulated similarly to
the probability with one choice period. A draw of β is taken from its
distribution. The logit formula is calculated for each period, and the
product of these logits is taken. This process is repeated for many
draws, and the results are averaged.
Past and future exogenous variables can be added to the utility in
a given period to represent lagged response and anticipatory behavior, as described in section (5.5) in relation to probit with panel data.
However, unlike probit, lagged dependent variables can be added in a
mixed logit model without changing the estimation procedure. Conditional on βn , the only remaining random terms in the mixed logit
are the εnj ’s, which are independent over time. A lagged dependent
variable entering Unjt is uncorrelated with these remaining error terms
for period t, since these terms are independent over time. The conditional probabilities (conditional on β) are therefore the same as in
equation (6.2), but with the x’s including lagged dependent variables.
The unconditional probability is then the integral of this conditional
probability over all values of β, which is just equation (6.3). In this
regard, mixed logit is more convenient than probit for representing
state-dependence, since lagged dependent variables can be added to
mixed logit without adjusting the probability formula or simulation
method. Erdem (1996) and Johannesson and Lundin (2000) exploit

6.7. PANEL DATA

167

this advantage to examine habit formation and variety seeking within
a mixed logit that also captures random taste variation.
If choices and data are not observed from the start of the process
(i.e., from the ﬁrst choice situation that the person faces), the issue
of initial conditions must be confronted, just as with probit. The researcher must somehow represent the probability of the ﬁrst observed
choice, which depends on the previous, unobserved choices. Heckman
and Singer (1986) provide ways to handle this issue. However, when the
researcher observes the choice process from the beginning, the initial
conditions issue does not arise. In this case, the use of lagged dependent variables to capture inertia or other types of state-dependence is
straightforward with mixed logit. Stated-preference data (that is, answers to a series of choice situations posed to respondents in a survey)
provide a prominent example of the researcher observing the entire
sequence of choices.
In the speciﬁcation so far and in nearly all applications, the coeﬃcients βn are assumed to be constant over choice situations for a
given decision-maker. This assumption is appropriate if the decisionmaker’s tastes are stable over the time period that spans the repeated
choices. However, the coeﬃcients associated with each person can be
speciﬁed to vary over time in a variety of ways. For example, each
person’s tastes might be serially correlated over choice situations, such
that utility is
Unjt = βnt xnjt + εnjt
βnt = b + β̃nt
β̃nt = ρβ̃nt−1 + µnt
where b is ﬁxed and µnt is iid over n and t. Simulation of the probability
for the sequence of choices proceeds as follows.
1. Draw µrn1 for the initial period and calculate the logit formula
r = b + µr .
for this period using βn1
n0
2. Drawe µrn2 for the second period, calculate βn2 = b + ρµrn1 + µrn2 ,
r .
and then calculate the logit formula based on this βn2
3. Continue for all T time periods.
4. Take the product of the T logits.
5. Repeat steps 1-4 for numerous sequences of draws.

CHAPTER 6. MIXED LOGIT

168
6. Average the results.

The burden placed on simulation is greater than with coeﬃcients being
constant over time for each person, requiring T times as many draws.

6.8

Case Study

As illustration, consider a mixed logit of angler’s choice of ﬁshing site
(Train, 1999). The speciﬁcation takes a random-coeﬃcients form. Utility is Unjt = βn xnjt + εnjt , with coeﬃcients βn varying over anglers
but not over trips for each angler. The probability of the sequence of
sites chosen by each angler is given by equation (6.3) above.
The sample consists of 962 river trips taken in Montana by 258
anglers during the period of July 1992 through August 1993. A total
of 59 possible river sites were deﬁned based on geographical and other
relevant factors. Each site contains one or more of the stream segments used in the Montana River Information System. The following
variables enter as elements of x for each site:
1. Fish stock, measured in 100 ﬁsh per 1000 feet of river.
2. Aesthetics rating, measured on a scale of 0 to 3, with 3 being the
highest.
3. Trip cost: cost of traveling from the angler’s home to the site,
including the variable cost of driving (gas, maintenance, tires,
oil) and the value of time spent driving (with time valued at
one-third the angler’s wage.)
4. Indicator that the Angler’s Guide to Montana lists the site as a
major ﬁshing site.
5. Number of campgrounds per US Geological Survey (USGS) block
in the site.
6. Number of state recreation access areas per USGS block in the
site.
7. Number of restricted species at the site.
8. Log of the size of the site, in USGS blocks.

6.8. CASE STUDY

169

The coeﬃcients of variables 4 - 7 can logically take either sign;
for example, some anglers might like having campgrounds while other
anglers prefer the privacy that comes from not having nearby campgrounds. Each of these coeﬃcients is given an independent normal
distribution with mean and standard deviation that are estimated.
The coeﬃcients for trip cost, ﬁsh stock, and aesthetics rating of the
site are expected to have the same sign for all anglers with only their
magnitudes diﬀering over anglers. These coeﬃcients are given independent lognormal distributions. The mean and standard deviation
of the log of the coeﬃcient is estimated, and the mean and standard
deviation of the coeﬃcient itself are calculated from these estimates.
Since the lognormal distribution is deﬁned over the positive range and
trip cost is expected to have a negative coeﬃcient for all anglers, the
negative of trip cost enters the model. The coeﬃcient for the log of
size is assumed to be ﬁxed. This variable accounts for the fact that the
probability of visiting a larger site is higher than that for a smaller site,
all else equal. Having the coeﬃcient of this variable vary over people,
while possible, would not be particularly meaningful. A version of the
model with correlated coeﬃcients is given by Train (1998). The site
choice model is part of an overall model, given by Desvousges, Waters
and Train (1996), of the joint choice of trip frequency and site choice.
Simulation was performed using one thousand random draws for
each sampled angler. The results are given in Table 6.1. The standard
deviation of each random coeﬃcient is highly signiﬁcant, indicating
that these coeﬃcients do indeed vary in the population.
Consider ﬁrst the normally distributed coeﬃcients. The estimated
means and standard deviations of these coeﬃcients provide information on the share of the population that places a positive value on the
site attribute and the share that places a negative value. The distribution of the coeﬃcient of the indicator that the Angler’s Guide to
Montana lists the site as a major site obtains an estimated mean of
1.018 and estimated standard deviation of 2.195, such that 68 percent
of the distribution is above zero and 32 percent below. This implies
that being listed as a major site in the Angler’s Guide to Montana
is a positive inducement for about two-thirds of anglers and a negative factor for the other third who apparently prefer more solitude.
Campgrounds are preferred by about half (53 percent) of anglers and
avoided by the other half. And about one-third of anglers (31 percent)
are estimated to prefer having numerous access areas, while the other

170

CHAPTER 6. MIXED LOGIT

Table 6.1: Mixed Logit Model of River Fishing Site Choice
Parameter
Fish Stock
Mean of ln(coeﬃcient)
-2.876
Std. dev. of ln(coeﬃcient)
1.016
Aesthetics
Mean of ln(coeﬃcient)
-0.794
Std. dev. of ln(coeﬃcient)
0.849
Total cost (neg.)
Mean of ln(coeﬃcient)
-2.402
Std. dev. of ln(coeﬃcient)
0.801
Guide lists as major
Mean coeﬃcient
1.018
Std. dev. of coeﬃcient
2.195
Campgrounds
Mean coeﬃcient
0.116
Std. dev. of coeﬃcient
1.655
Access areas
Mean coeﬃcient
-0.950
Std. dev. of coeﬃcient
1.888
Restricted species
Mean coeﬃcient
-0.499
Std. dev. of coeﬃcient
0.899
Log(size)
Mean coeﬃcient
0.984
Likelihood ratio index
SLL at convergence

0.5018
-1932.33

Std. error
0.6066
0.2469
0.2287
0.1382
0.0631
0.0781
0.2887
0.3518
0.3233
0.4350
0.3610
0.3511
0.1310
0.1640
0.1077

6.8. CASE STUDY

171

two-thirds prefer there being fewer access areas.
Consider now the lognormal coeﬃcients. Coeﬃcient β k follows a
lognormal if the log of β k is normally distributed. We parameterize
the lognormal distribution is terms of the underlying normal. That is,
we estimate parameters b and s that represent the mean and variance
of the log of the coeﬃcient: ln(β k ) ∼ N (m, s). The mean and variance
of β k are then derived from the estimates of m and s. The median
is exp(m), the mean is exp(m + s/2), and the variance is exp(2m +
s)[exp(s) − 1]. The point estimates imply that the coeﬃcients of ﬁsh
stock, aesthetics, and trip cost have the following median, mean, and
standard deviations.
Median Mean Std. Dev
Fish stock 0.0563
0.0944 0.1270
Aesthetics 0.4519
0.6482 0.6665
Trip cost
0.0906
0.1249 0.1185
The ratio of an angler’s ﬁsh stock coeﬃcients to the trip cost coeﬃcient is a measure of the amount that the angler is willing to pay
to have additional ﬁsh in the river. Since the ratio of two independent
log-normally distributed terms is also log-normally distributed, we can
calculate moments for the distribution of willingness to pay. The log
of the ratio of the ﬁsh stock coeﬃcient to the trip cost coeﬃcient has
estimated mean -0.474 and standard deviation of 1.29. The ratio itself
therefore has median 0.62, mean 1.44, and standard deviation 2.96.
That is, the average willingness to pay to have the ﬁsh stock raised
by 100 ﬁsh per 1000 feet of river is estimated to be $1.44, and there
is very wide variation in angler’s willingness to pay for additional ﬁsh
stock. Similarly, $9.87 is the estimated average willingness to pay for
a site that has an aesthetics rating that is higher by 1, and again the
variation is fairly large.
As this application illustrates, the mixed logit provides more information than a standard logit since the mixed logit estimates the
extent to which anglers diﬀer in their preferences for site attributes.
The standard deviations of the coeﬃcients enter signiﬁcantly, indicating that a mixed logit provides a signiﬁcantly better representation
of the choice situation than standard logit, which assumes that coeﬃcients are the same for all anglers. The mixed logit also accounts for
the fact that several trips are observed for each sampled angler and
that each angler’s preferences apply to each of the angler’s trips.

172

CHAPTER 6. MIXED LOGIT

Chapter 7

Variations on a Theme
7.1

Introduction

Simulation gives the researcher the freedom to specify models that appropriately represent the choice situations under consideration, without being unduly hampered by purely mathematical concerns. This
perspective has been the overarching theme of our book. The discrete
choice models that we have discussed– namely, logit, nested logit, probit and mixed logit – are used in the vast majority of applied work.
However, readers should not feel themselves constrained to use these
models. In the current chapter, we describe several models that are
derived under somewhat diﬀerent behavioral concepts. These models
are variations on the ones already discussed, directed toward speciﬁc
issues and data. The point is not simply to describe additional models.
Rather, the discussion illustrates how the researcher might examine a
choice situation and develop a model and estimation procedure that
seem appropriate for that particular situation, drawing from, and yet
personalizing, the standard set of models and tools.
Each section of this chapter is motivated by a type of data, representing the outcome of a particular choice process. The arena in
which such data might arise is described, and the limitations of the
primary models for these data are identiﬁed. In each case, a new
model is described that better represents the choice situation. Often
this new model is only a slight change from one of the primary models.
However, the slight change will often make the standard software unuseable, such that the researcher will need to develop her own software,
perhaps by modifying the codes that are available for standard models.
173

174

CHAPTER 7. VARIATIONS ON A THEME

The ability to revise code to represent new speciﬁcations enables the
researcher to utilize the freedom that the ﬁeld oﬀers.

7.2

Stated-Preference and Revealed-Preference
Data

Revealed-preference data relate to people’s actual choices in real-world
situations. These data are called “revealed-preference” because people
reveal their tastes, or preferences, though the choices they make in the
world. Stated-preference data are data collected in experimental or
survey situations where respondents are presented with hypothetical
choice situations. The term “stated-preference” denotes the fact that
the respondents state what their choices would be in the hypothetical
situations. For example, in a survey, a person might be presented with
three cars with diﬀerent prices and other attributes. The person is
asked which of the three cars he would buy if oﬀered only these three
cars in the real world. The answer the person gives is the person’s
stated choice. Revealed-preference data for the respondent is obtained
by asking which car they bought when they last bought a car.
There are advantages and limitations to each type of data. Revealedpreference data have the advantage that they reﬂect actual choices.
This, of course, is a very big advantage. However, revealed preference
data are limited to the choice situations and attributes of alternatives
that currently exist or have existed historically. Often a researcher will
want to examine people’s responses in situations that do not currently
exist, such as the demand for a new product. Revealed-preference data
are simply not available for these new situations. Even for choice situations that currently exist, there might be insuﬃcient variation in
relevant factors to allow estimation with revealed-preference data. For
example, suppose the researcher wants to examine the factors that affect California households’ choice of energy supplier. While residential
customers have been able to choose among suppliers for many years,
there has been practically no diﬀerence in price among the suppliers’
oﬀers. Customers’ response to price cannot be estimated on data that
contain little or no price variation. An interesting paradox arises in
this regard. If customers were highly price responsive, then suppliers,
knowing this, would oﬀer prices that meet their competitors’ prices;
the well-known equilibrium in this situation is that all ﬁrms oﬀer (es-

7.2. SP/RP

175

sentially) the same price. If the data from this market were used in
a choice model, the price coeﬃcient would be found to be insigniﬁcant, since there is little price variation in the data. The researcher
could erroneously conclude from this insigniﬁcance that price is unimportant to consumers. This paradox is inherent in revealed-preference
data. Factors that are the most important to consumers will often
exhibit the least variation due to the natural forces of market equilibrium. Their importance might therefore be diﬃcult to detect with
revealed-preference data.
Stated-preference data complement revealed-preference data. A
questionnaire is designed in which the respondent is presented with
one or more choice experiments. In each experiment, two or more
options are described and the respondent is asked which option he/she
would choose if facing the choice in the real world. For example, in
the data that we examine in Chapter 11, each surveyed respondent is
presented with 12 experiments. In each experiment, four hypothetical
energy suppliers were described, with the price, contract terms, and
other attributes given for each supplier. The respondent is asked to
state which of the four suppliers he/she would choose.
The advantage of stated-preference data is that the experiments
can be designed to contain as much variation in each attribute as the
researcher thinks is appropriate. While there might be little price variation over suppliers in the real world, the suppliers that are described
in the experiments can be given suﬃciently diﬀerent prices to allow precise estimation. Attributes can be varied over respondents and over
experiments for each respondent. This degree of variation contrasts
with market data, where often the same products are available to all
customers, such that there is no variation over customers in the attributes of products. Importantly, for products that have never been
oﬀered before, or for new attributes of old products, stated-preference
data allow estimation of choice models when revealed-preference data
do not exist. Louviere, Hensher and Swait (2000) describe the appropriate collection and analysis of stated-preference data.
The limitations of stated-preference data are obvious: what people
say they will do is often not the same as what they actually do. People
might not know what they would do if a hypothetical situation were
real. Or, they might not be willing to say what they would do. In fact,
respondents’ concept of what they would do might be inﬂuenced by
factors that wouldn’t arise in the real choice situations, such as their

176

CHAPTER 7. VARIATIONS ON A THEME

perception of what the interviewer expects or wants as answers.
By combining stated- and revealed-preference data, the advantages
of each can be obtained while mitigating the limitations. The statedpreference data provide the needed variation in attributes, while the
revealed-preference data ground the predicted shares in reality. To
utilize these relative strengths, an estimation procedure is needed that
(1) allows the ratios of coeﬃcients (which represent the relative importance of the various attributes) to be estimated primarily from the
stated-preference data (or more generally, from whatever variation in
the attributes exists, which is usually from the stated-preference data),
while (2) allowing the alternative-speciﬁc constants and overall scale of
the parameters to be determined by the revealed preference data (since
the constants and scale determine average shares in base conditions.)
Procedures for estimating discrete choice models on a combination
of stated- and revealed-preference data are described by Ben-Akiva
and Morikawa (1990), Hensher and Bradley (1993) and Hensher, Louviere and Swait (1999) in the context of logit models and by Bhat and
Castelar (2001) and Brownstone, Bunch and Train (2000) with mixed
logit. These procedures constitute variations on the methods we have
already examined. The most prevalent issue when combining statedand revealed-preference data is that the unobserved factors are generally diﬀerent for the two types of data. We describe in the following
paragraphs how this issue can readily be addressed.
Let the utility that person n obtains from alternative j in situation
t be speciﬁed as Unjt = β  xnjt + enjt where xnjt does not include
alternative-speciﬁc constants and enjt represents the impact of factors
that are not observed by the researcher. These factors have a mean
for each alternative (representing the average eﬀect of all excluded
factors on the utility of that alternative) and a distribution around
this mean. The mean is captured by an alternative-speciﬁc constant,
labeled cj , and, for a standard logit model, the distribution around
this mean is extreme value with variance λ2 π 2 /6. As described in
chapters 2 and 3, the scale of utility is set by normalizing the variance
of the unobserved portion of utility. The utility function becomes
Unjt = (β/λ) xnjt + (cj /λ) + εnjt , where the normalized error εnjt =
(enjt − cj )/λ, is now iid extreme value with variance π 2 /6. The choice
probability is the logit formula based on (β/λ) xnjt + (cj /λ). The
parameters that are estimated are the original parameters divided by
the scale factor λ.

7.2. SP/RP

177

This speciﬁcation is reasonable for many kinds of data and choice
situations. However, there is no reason to expect the alternativespeciﬁc constants and the scale factor to be the same for statedpreference data as for revealed-preference data. These parameters reﬂect the impact of unobserved factors, which are necessarily diﬀerent
in real choice situations than hypothetical survey situations. In real
choices, a multitude of issues that aﬀect a person but are not observed
by the researcher come into play. In a stated-preference experiment,
the respondent is (usually) asked to assume all alternatives to be the
same on factors that are not explicitly mentioned in the experiment.
If the respondent follows this instruction exactly, there would, by definition, be no unobserved factors in the stated-preference choices. Of
course, respondents inevitably bring some outside concepts into the
experiments, such that unobserved factors do enter. However, there
is no reason to expect that these factors are the same, in mean or
variance, as in real world choices.
To account for these diﬀerences, separate constants and scale parameters are speciﬁed for stated-preference choice situations as for
revealed-preference situations. Let csj and crj represent the mean impact of unobserved factors for alternative j in stated-preference experiments and revealed-preference choices, respectively. Similarly, let
λs and λr represent the scale (proportional to the standard deviation) of the distribution of unobserved factors around these means
in stated- and revealed-preference situations, respectively. To set the
overall scale of utility, we normalize either of the scale parameters to 1,
which makes the other scale parameter be the ratio of the two original
scale parameters. Let’s normalize λr , such that λs reﬂects the variance
of unobserved factors in stated-preference situations relative to that in
revealed-preference situations. Utility then becomes:
Unjt = (β/λs ) xnjt + (csj /λs ) + εnjt
for each t that is a stated-preference situation, and
Unjt = βxnjt + crj + εnjt
for each t that is a revealed-preference situation.
The model is estimated on the data from both the revealed- and
stated-preference choices. Both groups of observations are ”stacked”
together as input to a logit estimation routine. A separate set of

178

CHAPTER 7. VARIATIONS ON A THEME

alternative-speciﬁc constants is estimated for the stated-preference and
revealed-preference data. Importantly, the coeﬃcients in the model are
divided by a parameter 1/λs for the stated-preference observations.
This separate scaling is not feasible in most standard logit estimation
packages. However, the researcher can easily modify available codes (or
their own code) to allow for this extra parameter. Hensher and Bradley
(1993) show how to estimate this model on software for nested logits.
Note that, with this set-up, the elements of β are estimated on
both types of data. The estimates will necessarily reﬂect the amount
of variation that each type of data contains for the attributes (that
is, the elements of x ). If there is little variance in the revealedpreference data, reﬂecting conditions in real-world markets, then the
β’s will be determined primarily by the stated-preference data, which
contain whatever variation was built into the experiments. Insofar as
the revealed-preference data contain useable variation, this information
will be incorporated into the estimates.
The alternative-speciﬁc constants are estimated separately for the
two types of data. This distinction allows the researcher to avoid
many of the biases that stated-preference data might exhibit. For
example, respondents often say that they will buy a product far more
than they actually end up doing. The average probability of buying the
product is captured in the alternative-speciﬁc constant for the product.
If this bias is occurring, then the estimated constant for the statedpreference data will be greater than that for the revealed-preference
data. When forecasting, the researcher can use the constant from the
revealed-preference data, thereby grounding the forecast in a marketbased reality. Similarly, the scale for the revealed preference data
(which is normalized to 1) can be used in forecasting instead of the
scale from the stated-preference data, thereby incorporating correctly
the real-world variance in unobserved factors.

7.3

Ranked Data

In stated-preference experiments, respondents might be asked to rank
the alternatives instead of just identifying the one alternative that they
would choose. This ranking can be requested in a variety of ways.
The respondents can be asked to state which alternative they would
choose, and then, after they have make this choice, can be asked which
of the remaining alternatives they would choose, continuing through

7.3. RANKED DATA

179

all the alternatives. Instead, respondents can simply be asked to rank
the alternatives from best to worst. In any case, the data that the
researcher obtains is a ranking of the alternatives that presumably
reﬂects the utility that the respondent obtains from each alternative.
Ranked data can be handled in a standard logit or mixed logit
model using currently available software without modiﬁcation. All that
is required is that the input data be constructed in a particular way,
which we describe below. For a probit model, the available software
would need to be modiﬁed slightly to handle ranked data. However,
the modiﬁcation is straightforward. We consider standard and mixed
logit ﬁrst.

7.3.1

Standard and mixed logit

Under the assumptions for standard logit, the probability of any ranking of the alternatives from best to worst can be expressed as the
product of logit formulas. Consider, for example, a respondent who
was presented with four alternatives labeled A, B, C, and D. Suppose
the person ranked the alternatives as follows: C, B, D, A, where C
is the ﬁrst choice. If the utility of each alternative is distributed iid
extreme value (as for a logit model), then the probability of this ranking can be expressed as: the logit probability of choosing alternative C
from the set A, B, C, D, times the logit probability of choosing alternative B from the remaining alternatives A, B, D, times the probability
of choosing alternative D from the remaining alternatives A and D.
Stated more explicity, let Unj = β  xnj + εnj for j = A, . . . , D with
εnj iid extreme value. Then:
P rob(ranking C, B, D, A)
=


eβ xnC

β  xnj
j=A,B,C,D e



(7.1)

eβ xnB

β  xnj
j=A,B,D e




eβ xnD

β  xnj
j=A,D e

This simple expression for the ranking probability is an outcome of the
particular form of the extreme value distribution, ﬁrst shown by Luce
and Suppes (1965). It does not apply in general; for example it does
not apply with probit models.
Equation 7.1 implies that the ranking of the four alternatives can
be represented as being the same as three independent choices by the
respondent. These three choices are called “pseudo-observations” because each respondents’ complete ranking, which constitutes an ob-

CHAPTER 7. VARIATIONS ON A THEME

180

servation, is written as if it were multiple observations. In general,
a ranking of J alternatives provides J − 1 ”pseudo-observations” in
a standard logit model. For the ﬁrst pseudo-observation, all alternatives are considered available, and the dependent variable identiﬁes the
ﬁrst-ranked alternative. For the second pseudo-observation, the ﬁrst
ranked alternative is discarded. The remaining alternatives constitute
the choice set, and the dependent variable identiﬁes the second-ranked
alternative. And so on. In creating the input ﬁle for logit estimation, the explanatory variables for each alternative are repeated J − 1
times, making that many pseudo-observations. The dependent variable for these pseudo-observations identiﬁes, respectively, the ﬁrst-,
second-, etc. ranked alternatives. For each pseudo-observation, the
alternatives that are ranked above the dependent variable for that
pseudo-observation are omitted (i.e., censored out.) Once the data are
constructed in this way, the logit estimation proceeds as usual.
A logit model on ranked alternatives is often called an “exploded
logit,” since each observation is exploded into several pseudo-observations
for the purposes of estimation. Prominent applications include Beggs,
Cardell and Hausman (1981), Chapman and Staelin (1982), and Hausman and Ruud (1987).
A mixed logit model can be estimated on ranked data with the
same explosion. Assume now that β is random with density g(β | θ)
where θ are parameters of this distribution. Conditional on β, the
probability of the person’s ranking is a product of logits, as given in
equation 7.1 above. The unconditional probability is then the integral
of this product over the density of β:
P rob(ranking C, B, A, D)
 

=



eβ xnC





eβ xnB
eβ xnD





β xnj
β xnj
β  xnj
j=A,B,C,D e
j=A,B,D e
j=A,D e



g(β | θ)dθ.

The mixed logit model on ranked alternatives is estimated with regular mixed logit routines for panel data, using the input data set-up as
described above for logit where the J − 1 pseudo-observations for each
ranking are treated as J − 1 choices in a panel. The mixed logit incorporates the fact that each respondent has his own coeﬃcients and,
importantly, that the respondent’s coeﬃcients aﬀect his entire ranking
such that the pseudo-observations are correlated. A logit model on
mixed data does not account for this correlation.

7.3. RANKED DATA

7.3.2

181

Probit

Ranked data can also be utilized eﬀectively in a probit model. Let the
utility of the four alternatives be as stated above for a logit except that
the error terms are jointly normal: Unj = β  xnj +εnj for j = A, B, C, D
where εn = εnA , . . . , εnD  is distributed N (0, Ω). As before, the probability of the person’s ranking is P rob(ranking C, B, D, A) = P rob(UnC >
UnB > UnD > UnA ). Decomposing this joint probability into conditionals and a marginal does not help with a probit in the way that it
does with logit, since the conditional probabilities do not collapse to
unconditional probabilities as they do under independent errors. Another tack is taken instead. Recall that for probit models, we found
that it is very convenient to work in utility diﬀerences rather than the
utilities themselves. Denote Ũnjk = Unj − Unk , x̃njk = xnj − xnk , and
ε̃njk = εnj − εnk . The probability of the ranking can then be expressed
as P rob(ranking C, B, D, A) = P rob(UnC > UnB > UnD > UnA ) =
P rob(ŨnBC < 0, ŨnDB < 0, ŨnDA < 0).
To express this probability, we deﬁne a transformation matrix M
that takes appropriate diﬀerences. The reader might want to review
section (5.6.3) on simulation of probit probabilities for one chosen alternative, which uses a similar transformation matrix. The same procedure is used for ranked data, but with a diﬀerent transformation
matrix.
Stack the alternatives A to D, such that utility is expressed in
vector form as Un = Vn + εn where εn ∼ N (0, Ω). Deﬁne the 3 × 4
matrix:


0
1 −1 0


0 1 
M =  0 −1
−1
0
0 1
This matrix has a row for each inequality in the argument of the probability P rob(ŨnBC < 0, ŨnDB < 0, ŨnDA < 0). Each row contains a 1
and a -1, along with zeros, where the 1 and -1 identify the alternatives
that are being diﬀerenced for the inequality. With this matrix, the
probability of the ranked alternatives becomes
P rob(ranking C, B, D, A) = P rob(ŨnBC < 0, ŨnDB < 0, ŨnDA < 0)
= P rob(M Un < 0)
= P rob(M Vn + M εn < 0)
= P rob(M εn < −M Vn )

CHAPTER 7. VARIATIONS ON A THEME

182

The error diﬀerences deﬁned by M εn are distributed jointly normal
with zero mean and covariance M ΩM  . The probability that these correlated error diﬀerences fall below −M Vn is simulated by GHK in the
manner given in section (5.6.3). The procedure has been implemented
by Hajivassiliou and Ruud (1994) and Schechter (2001).

7.4

Ordered Responses

In surveys, respondents are often asked to provide ratings of various
kinds. Examples include:
How good a job do you think the President is doing? Check one:
1. very good job
2. good job
3. neither good nor bad
4. poor job
5. very poor job
How well do you like this book? Rate the book from 1 to 7, where
1 is the worst you have ever read (aside from The Bridges of Madison
County, of course) and 7 is the best
1 2 3 4 5 6 7
How likely are you to buy a new computer this year?
1. Not likely at all
2. Somewhat likely
3. Very likely
The main characteristic of these questions, from a modeling perspective, is that the potential responses are ordered. A book rating of
6 is higher than 5 which is higher than 4; and a Presidential rating of
“very poor” is worse than “poor,” which is worse than “neither good
nor bad”. A standard logit model could be speciﬁed with each potential response as an alternative. However, the logit model’s assumption
of independent errors for each alternative is inconsistent with the fact

7.4. ORDERED RESPONSES

183

that the alternatives are ordered: with ordered alternatives, one alternative is similar to those close to it and less similar to those further
away. The ordered nature could be handled by specifying a nested
logit, mixed logit, or probit model that accounts for the pattern of
similarity and dissimilarily among the alternatives. For example, a
probit model could be estimated with correlation among the alternatives, with the correlation between 2 and 3 being greater than that
between 1 and 3, and the correlation between 1 and 2 also being larger
than that between 1 and 3. However, such a speciﬁcation, while it
might provide ﬁne results, does not actually ﬁt the structure of the
data. Recall that the traditional derivation for these models starts
with a speciﬁcation of the utility associated with each alternative. For
the ratings question about the President’s job, the derivation would
assume that there are seven utilities, one for each potential response,
and that the person chooses the number 1 to 5 that has the greatest
utility. While it is perhaps possible to think of the decision process in
this way (and the resulting model will probably provide useful results),
it is not a very natural way to think about the respondent’s decision.
A more natural representation of the decision process is to think
of the respondent as having some level of utility or opinion associated
with the object of the question and answering the question on the basis
of how great this utility is. For example, on the Presidential question,
the following derivation seems to better represent the decision process.
Assume that the respondent has an opinion on how well the President
is doing. This opinion is represented in a (unobservable) variable that
we label U , where higher levels of U mean that the person thinks
the President is doing a better job and lower levels mean he thinks
the President is going a poorer job. In answering the question, the
person is asked to express this opinion in one of ﬁve categories: “very
good job,” “good job,“ etc. That is, even though the person’s opinion,
U , can take many diﬀerent levels representing various levels of liking
or disliking the job the President is doing, the question allows only
5 possible responses. The person chooses a response on the basis of
the level of his U . If U is above some cutoﬀ, which we label k1 , the
respondent chooses the answer “very good job.” If U is below k1 but
above another cut-oﬀ, k2 , then he answers “good job.” And so on.
The decision is represented as:
• “very good job” if U > k1

CHAPTER 7. VARIATIONS ON A THEME

184

• “good job” if k1 > U > k2
• “neither good or bad” if k2 > U > k3
• “poor job” if k3 > U > k4
• “very poor job” if k4 > U
The researcher observes some factors that relate to the respondents’ opinion, such as the person’s political aﬃliation, income, and so
on. However, other factors that aﬀect the person’s opinion cannot be
observed. Decompose U into unobserved and unobserved components:
U = β  x + ε. As usual, the unobserved factors ε are considered random. Their distribution determines the probability for the ﬁve possible
responses.
Figure 7.1 illustrates the situation. U is distributed around β  x
with the shape of the distribution following the distribution of ε. There
are cut-oﬀ points for the possible responses: k1 , . . . , k4 . The probability
that the person answers with “very poor job” is the probability that U
is less than k4 , which is the area in the left tail of the distribution. The
probability that the person says “poor job” is the probability that U
is above k4 , indicating that he doesn’t think that the job is very poor,
but is below k3 . This probability is the area between k4 and k3 .
f (U)

Prob (neither good nor poor)
Prob (good)

Prob (poor)

Prob (very good)

Prob (very poor)

U
k4

k3

k2

k1

Figure 7.1: Distribution of opinion about president’s job.
Once a distribution for ε is speciﬁed, the probabilities can be calculated exactly. For simplicity, assume that ε is distributed logistic, which means that the cumulative distribution of ε is F (ε) =

7.4. ORDERED RESPONSES

185

exp(ε)/(1 + exp(ε)). The probability of the answer “very poor job”
is then:
P rob(“very poor job”) = P rob(U < k4 )
= P rob(β  x + ε < k4 )
= P rob(ε < k4 − β  x)


=

ek4 −β x
1 + ek4 −β  x

The probability of ”poor job” is:
P rob(“poor job”) = P rob(k4 < U < k3 )
= P rob(k4 < β  x + ε < k3 )
= P rob(k4 − β  x < ε < k3 − β  x)
= P rob(ε < k3 − β  x) − P rob(ε < k4 − β  x)


=



ek4 −β x
ek3 −β x
x −
k
−β
1+e 3
1 + ek4 −β  x

Probabilities for the other answers are obtained analogously. The
probabilities enter the log-likelihood function as usual, and maximization of the likelihood function provides estimates of the parameters.
Note that the parameters consist of β, which gives the impact of the
explanatory variables on people’s opinion of the President, as well as
the cut-oﬀ points k1 , . . . , k4 .
The model is called ordered logit, since it uses the logistic distribution on ordered alternatives. Unfortunately, nested logit models
have occasionally been called ordered logits; this nomenclature causes
confusion and will hopefully be avoided in the future.
Note that the probabilities in the ordered logit model incorporate
the binary logit formula. This similarity to binary logit is only incidental: the traditional derivation of a binary logit speciﬁes two alternatives
with utility for each, while the ordered logit model has one utility with
multiple alternatives to represent the level of that utility. The similarity in formula arises from the fact that, if two random variables
are iid extreme value, then their diﬀerence follows a logistic distribution. Therefore, assuming that both utilities in a binary logit are iid
extreme value is equivalent to assuming that the diﬀerence in the utilities is distributed logistic, the same as the utility in the ordered logit
model.

CHAPTER 7. VARIATIONS ON A THEME

186

A similar model is obtained under the assumption that ε is distributed standard normal instead of logistic (Zavoina and McElvey,
1975). The only diﬀerence arises in that the binary logit formula is
replaced with the cumulative standard normal distribution. That is,
P rob(“very poor job”) = P rob(ε < k4 − β  x)


= Φ(ek4 −β x )
and
P rob(“poor job”) = P rob(ε < k3 − β  x) − P rob(ε < k4 − β  x)




= Φ(ek3 −β x ) − Φ(ek4 −β x )
where Φ is the standard cumulative normal function. This model is
called ordered probit. Software for ordered logit and probit is available
in many commercial packages.
The researcher might believe that the parameters vary randomly
in the population. In that case, a mixed version of the model can
be speciﬁed, as in Bhat (1999). Let the density of β be g(β | θ).
Then the mixed ordered logit probabilities are simply the ordered logit
probabilities integrated over the density g(·). For example,
 

P rob(“very poor job”) =



ek4 −β x
1 + ek4 −β  x



g(β | θ)dβ

and
 

P rob(“poor job”) =





ek4 −β x
ek3 −β x
−

1 + ek3 −β x 1 + ek4 −β  x



g(β | θ)dβ

and so on. These probabilities are simulated in the same way as mixed
logits, by drawing values of β from g(·), calculating the ordered logit
probability for each draw, and averaging the results. Mixed ordered
probit is derived similarly.

7.4.1

Multiple ordered responses

Respondents’ answers to diﬀerent questions are often related. For example, a person’s rating of how well the President is doing is probably
related to the person’s rating of how well the economy is doing. The
researcher might want to incorporate into the analysis the fact that

7.4. ORDERED RESPONSES

187

the answers are related. To be concrete, suppose that respondents
are asked to rate both the President and the economy on a ﬁve point
scale, like the rating given above for the President. Let U be the respondent’s opinion of the job the president is doing, and let W be the
respondent’s assessment of the economy. Each of these assessments can
be decomposed into observed and unobserved factors: U = β  x + ε and
W = α z + µ. Insofar as the assessments are related due to observed
factors, the same variables can be included in x and z. To allow for
the possibility that the assessments are related due to unobserved factors, we specify ε and µ to be jointly normal with correlation ρ (and
unit variances by normalization.) Let the cut-oﬀs for U be denoted
k1 , . . . , k4 as before and the cut-oﬀs for W be denoted c1 , . . . , c4 . We
want to derive the probability of each possible combination of responses
to the two questions.
The probability that the person says the President is doing a “very
poor job” and also that the economy is doing “very poorly” is derived
as follows:
P rob(President “very poor” and economy “very poor”)
= P rob(U < k4 and W < c4 )
= P rob(ε < k4 − β  x and µ < c4 − α z)
= P rob(ε < k4 − β  x) × P rob((µ < c4 − α z | ε < k4 − β  x)
Similarly, the probability of a rating of “very poor” for the President
and “good“ for the economy is:
P rob(President “very poor“ and economy “good“)
= P rob(U < k4 and c2 < W < c1 )
= P rob(ε < k4 − β  x and c2 − α z < µ < c1 − α z)
= P rob((ε < k4 − β  x) × P rob((c2 − α z < µ < c1 − α z | ε < k4 − β  x)
The probabilities for other combinations are derived similarly, and generalization to more than two related questions is straightforward. The
model is called multivariate (or multiresponse) ordered probit. The
probabilities can be simulated by GHK in a manner similar to that
described in chapter 5. The explanation in Chapter 5 assumes that
truncation of the joint normal is only on one side (since for a standard
probit the probability that is being calculated is the probability that
all utility diﬀerences are below zero, which is truncation from above),

188

CHAPTER 7. VARIATIONS ON A THEME

while the probabilities for multivariate ordered probit are truncated on
two sides (as for the second probability above). However, the logic is
the same, and interested readers can refer to Hajivassiliou and Ruud
(1994) for an explicit treatment of GHK with two-sided truncation.

7.5

Contingent Valuation

In some surveys, respondents are asked to express their opinions or
actions relative to a speciﬁc number that the interviewer states. For
example, the interviewer might ask: “Consider a project that protected
the ﬁsh in speciﬁc rivers in Montana. Would you be willing to spend
$ 50 to know that the ﬁsh in these rivers are safe?” This question is
sometimes followed by another question that depends on the respondent’s answer to the ﬁrst question. For example, if the person said
“yes” to the above question, the interviewer might follow-up by asking, “How about $ 75? Would you be willing to pay $ 75?” If the
person answered “no” to the ﬁrst question, indicating that he was not
willing to pay $ 50, the interviewer would follow-up with “Would you
be willing to pay $ 25?”
These kinds of questions are used in environmental studies where
the lack of markets for environmental quality prevent valuation of resources by revelation procedures; the papers edited by Hausman (1993)
provide a review and critique of the procedure, which is often called
“contingent valuation.” When only one question is asked, such as
whether the person is willing to pay $ 50, the method is called “single
bounded,” since the person’s answer gives one bound on their true willingness to pay. If the person answers “yes,” the researcher knows that
their true willingness to pay is at least $ 50, but she does not know how
much more. If the person answers “no,” the researcher knows that the
person’s willingness to pay is less than $ 50. Examples of studies using
single bounded methods are Cameron and James (1987) and Cameron
(1988).
When a follow-up question is asked, the method is called “doublebounded.” If the person says that he is willing to pay $ 50 but not
$ 75, the researcher knows his true willingness to pay is between $ 50
and $ 75, that is, is bounded on both sides. If the person says he is
not willing to pay $ 50 but is willing to pay $ 25, his willingness to
pay is known to be between $ 25 and $ 50. Of course, even with a
double-bounded method, some respondents’ willingness to pay is only

7.5. CONTINGENT VALUATION

189

singly bounded, such as a person who says he is willing to pay $ 50 and
also willing to pay $ 75. Examples of this approach include Hanemann,
Loomis and Kanninen (1991), Cameron and Quiggin (1994), and Cai,
Deilami and Train (1998).
The ﬁgure that is used as the prompt, i.e., the $ 50 in our example,
is varied over respondents. The answers from a sample of people are
then used to estimate the distribution of willingness to pay. The estimation procedure is closely related to that described above for ordered
logits and probits, except that the cut-oﬀ points are given by the questionnaire design rather than estimated as parameters. We describe the
procedure as follows.
Let Wn represent the true willingness to pay of person n. Wn varies
over people with distribution f (W | θ) where θ are the parameters of
the distribution, such as the mean and variance. The researcher’s goal
is to estimate these population parameters. Suppose the researcher
designs a questionnaire with a single-bounded approach, giving a different prompt (or reference value) for diﬀerent respondents. Denote
the prompt that is given to person n as kn . The person answers the
question with a “yes” if Wn > kn and “no” otherwise. The researcher
assumes that Wn is distributed normally in the population with mean
W̄ and variance σ 2 .
The probability of “yes” is P rob(Wn > kn ) = 1 − P rob(Wn <
kn ) = 1 − Φ((kn − W̄ )/σ) and the probability of “no“ is Φ((kn −
W̄ )/σ), where Φ(·) is the standard cumulative normal function. The

log-likelihood function is then n yn log(1 − Φ((kn − W̄ )/σ)) + (1 −
yn )log(Φ((kn − W̄ )/σ)), where yn = 1 if person n said “yes” and 0
otherwise. Maximizing this function provides estimates of W̄ and σ.
A similar procedure is used if the researcher designs a doublebounded questionnaire. Let the prompt for the second question be
knu if the person answered “yes” to the ﬁrst question, where knu > kn ,
and let knl be the second prompt if the person initially answered “no,”
where knl < kn . There are four possible sequences of answers to the
two questions. The probabilities for these sequences are illustrated in
Figure 7.2 and given below:
• “no” then “no”: P = P rob(Wn < knl ) = Φ((knl − W̄ )/σ)
• “no” then “yes”: P = P rob(knl < Wn < kn ) = Φ((kn − W̄ )/σ) −
Φ((knl − W̄ )/σ)

CHAPTER 7. VARIATIONS ON A THEME

190
f (W )

Prob (yes, no)

Prob (no, yes)
Prob (yes, yes)
Prob (no, no)

W
knl

kn

knu

Figure 7.2: Distribution of willingness to pay.
• “yes” then “no”: P = P rob(kn < Wn < knu ) = Φ((knu −
W̄ )/σ) − Φ((kn − W̄ )/σ)
• “yes” then “yes”: P = P rob(Wn > knu ) = 1 − Φ((knu − W̄ )/σ)
These probabilities enter the log-likelihood function, which is maximized to obtain estimates of W̄ and σ. Other distributions can of
course be used instead of normal. Lognormal is attractive if the researcher assumes that all people have a positive willingness to pay. Or
the researcher might specify a distribution that has a mass at zero
to represent the share of people who are not willing to pay anything,
and a lognormal for the remaining share. Generalization to multiple
dimensions is straightforward, to reﬂect, for example, that people’s
willingness to pay for one environmental package might also be related
to their willingness to pay for another. As with multi-response ordered
probit, the GHK simulator comes in handy when the multiple values
are assumed to be distributed jointly normal.

7.6

Mixed Models

We have discussed mixed logit and mixed ordered logit. Of course,
mixed models of all kinds can be developed using the same logic. Any
model whose probabilities can be written as a function of parameters
can also be mixed by allowing the parameters to be random and integrating the function over the distribution of parameters (Greene, 2001)

7.6. MIXED MODELS

191

The probability is simulated by drawing from the distribution, calculating the function for each draw, and averaging the results. We give
two examples below, but researchers will inevitably develop others that
meet the needs of their particular projects, such as Bhat’s (1999) use
of mixed ordered logit.

7.6.1

Mixed Nested Logit

The mixed logit model does not exhibit the independence from irrelevant alteratives property of logit, and can approximate any substitution pattern by appropriate speciﬁcation of variables and mixing
distribution. This fact has lead some people to feel that there is no further need for nested logit models. A mixed logit can be estimated that
provides an analogous correlation/substitution patterns as a nested
logit. For example, consider a nested logit with two nests of alternatives labeled A and B. Provided the logsum coeﬃcients are between 0
and 1, substitution within each nest is greater than substitution across
nests. This substitution pattern can be represented in a mixed logit
model by specifying a dummy variable for each nest and allowing the
coeﬃcients on the dummies to be random (constraining, for identiﬁcation purposes, the means to be zero if a full set of alternative-speciﬁc
constants are included and the two variances to be the same.)
While a mixed logit can be speciﬁed in this way, doing so misses the
point of simulation. As discussed in Chapter 1, simulation is used as a
way to approximate integrals when a closed form does not exist. Analytic integration is always more accurate than simulation and should
be used whenever feasible, unless there is a compelling reason to the
contrary. Using a mixed logit to represent the substitution patterns of
a nested logit, while feasible, replaces the closed-form integral of the
nested logit with an integral that needs to be simulated. From a numerical perspective, this replacement can only reduce accuracy. The
only possible advantages of mixed logit in this context are that (1) it
might be easier for the researcher to test numerous nesting structures,
including overlapping nests, within a mixed logit than a nested logit,
and (2) the researcher might specify other coeﬃcients to be random
such that a mixed logit is already being used.
The second reason suggests a mixed nested logit. Suppose the researcher believes that some of the coeﬃcients in the model are random
and also that, conditional on these coeﬃcients, the unobserved factors

192

CHAPTER 7. VARIATIONS ON A THEME

are correlated over alternatives in a way that can be represented by a
nested logit. A mixed nested logit model can be speciﬁed to represent
this situation. Conditional on the coeﬃcients that enter utility, the
choice probabilities are nested logit, which is a close-form and can be
calculated exactly. The unconditional probability is the nested logit
formula integrated over the distribution of the the random coeﬃcients.
Software for mixed logit can be modiﬁed by simply locating the logit
formula within the code and changing it to the appropriate nested logit
formula. Experience indicates that maximizing the likelihood function
for unmixed nested logits is often diﬃcult numerically, and mixing
the model will compound this diﬃculty. Hierarchical Bayes estimation
(Chapter 12) could prove particularly useful in this situation, since it
does not involve maximizing the likelihood function.

7.6.2

Mixed Probit

A constraint of probit models, and in fact their deﬁning characteristic,
is all random terms enter utility linearly and are randomly distributed
such that utility itself is normally distributed. This constraint can
be removed by specifying a mixed probit. Suppose that some random
terms enter non-linearly or are not randomly distributed, but that conditional on these, utility is normally distributed. For example, a price
coeﬃcient might be lognormal to assure that it is negative for all people, and yet all other coeﬃcients are either ﬁxed or normal and the
ﬁnal error terms are jointly normal. A mixed probit model is appropriate for this speciﬁcation. Conditional on the price coeﬃcient, the
choice probabilities follow the standard probit formula. The unconditional probabilities are the integral of this probit formula over the
distribution of the price coeﬃcient. Two layers of simulation are used
to approximate the probabilities: (1) a draw of the price coeﬃcient
is taken, and (2) for this draw, the GHK or other probit simulator is
used to approximate the conditional choice probability. This process
is repeated many times and the results are averaged.
Long run times can be expected for the mixed probit model since
the GHK simulator is calculated for each draw of the price coeﬃcient. However, the number of draws in the GHK simulator can be
reduced, since the averaging over draws of the price coeﬃcient reduces
the variance generated by the GHK simulator. In principle, the GHK
simulator can be based on only one draw for each draw of the price

7.7. DYNAMIC OPTIMIZATION

193

coeﬃcient. In practice, it might be advisable to use more than one
draw but far fewer than would used in a unmixed probit.
The mixed probit model provides a way for the researcher to avoid
some of the practical diﬃculties that can arise with a mixed logit
model. For example, to represent pure heteroskedasticity (i.e., a diﬀerent variance for each alternative’s utility) or a ﬁxed correlation pattern
among alternatives (i.e., a covariance matrix that does not depend on
the variables), it can often be easier to estimate a probit instead of
specifying numerous error components within a mixed logit. As emphasized by Ben-Akiva et al. (2001), speciﬁcation of covariance and
heteroskedasticity can be more complex in a mixed logit model than
a probit, due to the fact that iid extreme value terms are necessarily added to whatever other random elements the researcher speciﬁes.
Probit is a more natural speciﬁcation in these situations. However, if
the researcher wants to include some non-normal random terms, an unmixed probit cannot be used. Mixing the probit allows the researcher
to include non-normal terms while still maintaining the simplicity of
probit’s representation of ﬁxed covariance for additive errors. Conceptually, the speciﬁcation and estimation procedure are straightforward.
The cost comes only in extra computation time, which becomes less
relevant as computers get faster.

7.7

Dynamic optimization

In previous chapters we examined certain types of dynamics, by which
choices in one period aﬀect choices in another period. For example, we
described how a lagged dependent variable can be included to capture
inertia or variety-seeking behavior. These discussions suggest a much
wider realm of dynamics than we had actually considered. In particular: if past choices aﬀect current choices, then current choice aﬀect
future choices, and a decision-maker who is aware of this fact will take
these future impacts into consideration. A link from the past to the
present necessarily implies a link from the present to the future.
In many situations, the choices that a person makes at one point in
his life have profound impact on the options that are available to him in
the future. Going to college, while expensive and sometimes irritating,
enhances future job possibilities. Saving money now allows a person to
buy things later than he otherwise would not be able to aﬀord. Going
to the gym today means that we can skip going tomorrow. Most of us

194

CHAPTER 7. VARIATIONS ON A THEME

take future impacts like these into consideration when choosing among
current alternatives.
The question is: how can behavior such as this be represented in
discrete choice models? In general the situation can be described as
follows. A person makes a series of choices over time. The alternative
that is chosen in one period aﬀects the attributes and availability of
alternatives in the future. Sometimes the future impacts are not fully
known, or depend on factors that have not yet transpired (such as
the future state of the economy). However, the person knows that he
will, in the future, maximize utility among the alternatives that are
available at that time under the conditions that prevail at that time.
This knowledge enables him to choose the alternative in the current
period that maximizes his expected utility over the current and future
periods. The researcher recognizes that the decision-maker acts in this
way, but does not observe everything that the decision-maker considers
in the current and future periods. As usual, the choice probability is
an integral of the decision-maker’s behavior over all possible values of
the factors that the researcher does not observe.
In this section we specify models in which the future consequences
of current decisions are incorporated. For these models, we will assume
that the decision-maker is fully rational in the sense that he optimizes
perfectly in each time period given the information that is available to
him at that point in time and given that he knows he will act optimally
in the future when future information is revealed. The procedures for
modeling these decisions were ﬁrst developed for various applications
by, for example,Wolpin (1984) on women’s fertility, Pakes (1986) on
patent options, Wolpin (1987) on job search, Rust (1987) on engine
replacement, Berkovec and Stern (1991) on retirement, and others.
Eckstein and Wolpin (1989) provide an excellent survey of these early
contributions. The thrust of more recent work has primarily between
toward solving some of the computational diﬃculties that can arise in
these models, as discussed below.
Before embarking on this endeavor, it is important to keep the concept of rationality in perspective. A model of rational decision-making
over time does not necessarily represent behavior more accurately than
a model of myopic behavior, where the decision-maker ignores future
consequences. In fact, the truth in a given situation might lie between
these two extremes: decision-makers might be acting in ways that are
neither completely myopic nor completely rational. As we will see, the

7.7. DYNAMIC OPTIMIZATION

195

truly optimizing behavior is very complex. People might engage in
behavior that is only approximately optimal simply because they (we)
can’t ﬁgure out the truly optimal way to proceed. Viewed in another
light, one could argue that people always optimize when the realm of
optimization is broadened suﬃciently. For example, rules of thumb or
other behavior that seem only to approximate optimality might actually be optimal when the costs of optimization are considered.
The concepts and procedures that are developed to examine optimizing behavior carry over, in modiﬁed form, to other types of behavior
that recognize future impacts from current choices. Furthermore, the
researcher can often test alternative behavioral representations. Myopic behavior nearly always appears as a testable restriction on a fully
rational model, namely, a zero coeﬃcient for the variable that captures
future impacts. Sometimes, the standard rational model is a restriction on a supposedly non-rational one. For example, O’Donoghue and
Rabin (1999), among others, argue that people are time inconsistent:
when it is Monday, we weigh the beneﬁts and costs that will come on,
say, Wednesday only marginally more than those that will arrive on
Thursday, and yet when Wednesday actually arrives, we weigh Wednesday’s (today’s) beneﬁts and costs far more than Thursday’s. Essentially, we have a bias for the present. The standard rational model,
where the same discount rate is used between any two periods independent of whether the person is in one of the periods, constitutes a
restriction on the time-inconsistent model.
The concepts in this area of analysis are more straightforward than
the notation. To develop the concepts with a minimum of notation,
we will start with a two period model in which the decision-maker
knows the exact impact of ﬁrst-period choices on the second-period
alternatives and utilities. We will then expand the model to more
periods and to situations where the decision-maker faces uncertainty
about future impacts.

7.7.1

Two-periods, no uncertainty about future impacts

To make the explication concrete, consider a high school student’s
choice of whether or not to go to college. The choice can be examined
in the context of two periods: the college years and the post-college
years. In the ﬁrst period, the student either goes to college or not.
Even though these are called the college years, the student need not

196

CHAPTER 7. VARIATIONS ON A THEME

go to college but can take a job instead right out of high school. In the
second period the student chooses among the jobs that are available
to him at that time. Going to college during the “college years” means
less income during that period but better job options in the postcollege years. U1C is the utility that the student obtains in period 1
from going to college, and U1W is the utility he obtains in the ﬁrst
period if he works in the ﬁrst period instead of going to college. If
the student were myopic, he would choose college only if U1C > U1W .
However, we assume that he is not myopic. For the second period, let
J denote the set of all possible jobs. The utility of job j in period
C if the student went to college and U W if he worked in the
2 is U2j
2j
ﬁrst period. The utility from a job depends on the wage that the
person is paid as well as other factors. For many jobs, people with
a college degree are paid higher wages and granted greater autonomy
C > U W . However, working in
and responsibility. For these jobs, U2j
2j
the ﬁrst period provides on-the-job experience that commands higher
wages/responsibility than a college degree for some jobs; for these,
W > U C . A job not being available is represented as having a utility
U2j
2j
of negative inﬁnity. For example, if job j is available only to college
W = −∞.
graduates, then U2j
How will the high school student decide whether to go to college?
C and U W for all j ∈ J
We assume for now that the student knows U2j
2j
when deciding whether to go to college in the ﬁrst period. That is, the
student has perfect knowledge of his future options under whatever
choice he makes in the ﬁrst period. We will later consider how the
decision-process changes when the student is uncertain about these
future utilities. The student knows that when the second period arrives
he will choose the job that provides the greatest utility. That is, he
knows in the ﬁrst period that the utility that he will obtain in the
second period if he chooses college in the ﬁrst period is the maximum
C over all possible jobs. We label this utility as U C = max (U C ).
of U2j
j
2
2j
The student therefore realizes that, if he chooses college in the ﬁrst
period, his total utility over both periods will be:
T UC

= U1C + λU2C
C
= U1C + λmaxj (U2j
)

where λ reﬂects the relative weighting of the two periods’ utilities in
the student’s decision-process. Given the way we have deﬁned time
periods, λ incorporates the relative time spans of each period as well

7.7. DYNAMIC OPTIMIZATION

197

as the traditional discounting of future utility relative to current utility.
Thus, λ can exceed one, even with discounting, if the second period
represents say forty years while the ﬁrst period is four years. Myopic
behavior is represented as λ = 0.
The same logic is applied to the option of working in the ﬁrst period
instead of going to school. The student knows that he will choose the
W ) and the
job that oﬀers the greatest utility such that U2W = maxj (U2j
total utility over both period from choosing to work in the ﬁrst period
is
T UW

= U1W + λU2W
W
= U1W + λmaxj (U2j
).

The student chooses college if T UC > T UW and otherwise chooses to
work in the ﬁrst period.
This completes the description of the decision-maker’s behavior.
We now turn to the researcher. As always, the researcher observes only
some of the factors that aﬀect the student’s utility. Each utility in each
period is decomposed into an observed and unobserved component:
U1C = V1C + ε1C
U1W = V1W + ε1W
and
C
= V2jC + εC
U2j
2j
W
U2j
= V2jW + εW
2j

for all j ∈ J. Collect the unobserved components into vector ε =
W
ε1C , ε1W , εC
2j , ε2j , ∀j, and denote the density of these terms as f (ε).
The probability of the student choosing college is
PC

= P rob(T UC > T UW )
C
W
) > U1W + maxj (U2j
)]
= P rob[U1C + maxj (U2j
W
W
= P rob[V1C + ε1C + maxj (V2jC + εC
2j ) > V1W + ε1W + maxj (V2j + ε2j )]



=

W
W
I[V1C + ε1C + maxj (V2jC + εC
2j ) > V1W + ε1W + maxj (V2j + ε2j )]f (ε)dε

where I[.] is an indicator of whether the statement in brackets is true.

198

CHAPTER 7. VARIATIONS ON A THEME

The integral can be approximated through simulation. For an
accept-reject simulator: (1) Take a draw from f (ε), with its comC
C
Cr
ponents labeled εr1C , εCr
2j , etc. (2) Calculate U2j = V2j + ε2j for all
Cr
j, determine the highest one and labeled it U2 . Similarly, calculate
r + λU Cr and simiU2W r . (3) Calculate the total utilities as T UCr = V1C
2
r
r
r . If so, set I r = 1.
larly for T UW . (4) Determine whether T UC > T UW
Otherwise, let I r = 0. (5). Repeat steps 1-4 R times. The simulated

probability of choosing college is P̃C = r I r /R.
Convenient error partitioning (as explained in section 1.2) can be
utilized to obtain a smooth and more accurate simulator than acceptreject, provided that the integral over the ﬁrst period errors has a closed
form conditional on the second period errors. Suppose for example
that ε1C and ε1W are iid extreme value. Label the second period
errors collectively as ε2 with any density g(ε2 ). Conditional on the
second period errors, the probability of the student going to college is a
standard logit model with an extra explanatory variable that captures
the future eﬀect of the current choice. That is,
C

PC (ε2 ) =

eV1C +U2 (ε2 )
C

C

eV1C +U2 (ε2 ) + eV1W +U2 (ε2 )

where U2C (ε2 ) is calculated from the second period errors as U2C (ε2 ) =
W
maxj (V2jC + εC
2j ), and similarly for U2 (ε2 ). The unconditional probability is then the integral of this logit formula over all possible values
of the second-period errors:


PC =

PC (ε2 )g(ε2 )dε2 .

The probability is simulated as follows: (1) Take a draw from density
g(·) and label it εr2 . (2) Using this draw of the second period errors,
calculate the utility that would be obtained from each possible job if
Cr = V C +εCr for all j.
the person went to college. That is, calculate U2j
2j
2j
(3) Determine the maximum of these utilities and label it U2Cr . This
is the utility that the person would obtain in the second period if he
went to college in the ﬁrst period, based on this draw of the secondW r ∀j and then determine
period errors. (4)-(5) Similarly, calculate U2j
the maximum U2W r . (6) Calculate the conditional choice probability
for this draw as
Cr
eV1C +U2
r
PC =
Cr
Wr .
eV1C +U2 + eV1W +U2

7.7. DYNAMIC OPTIMIZATION

199

(7) Repeat steps 1-6 many times, labeled r = 1, . . . , R. (8) The simu
lated probability is P̃C = r PCr /R.
If the second-period errors are also iid extreme value, then the
probability of taking a particular job in the second period is standard
logit. The probability of going to college and taking job j is


PCj =

C
eV1C +U2 (ε2 )
C
C
eV1C +U2 (ε2 ) + eV1W +U2 (ε2 )

!





C
V2j

e
g(ε2 )dε2  

C

V
k e 2k



The choice probabilities for the ﬁrst period are simulated by taking
draws of the second period errors, as described above with g(·) being the extreme value distribution. However, the probabilities for the
second period are calculated exactly. The draws of the second-period
errors are used only in calculating the ﬁrst period probabilities, where
they do not integrate out in closed form. The second-period errors integrate out of the second-period probabilities in a closed form, which is
used to calculate the second-period probabilities exactly. Application
to other distributions that allow correlation over alternatives, such as
GEV or normal, is straightforward. Allowing the errors to be correlated over time can be accomplished with a joint normal distribution
and simulation of both periods’ probabilities.

7.7.2

Multiple periods

We ﬁrst expand to three periods and then generalize to any number of
periods. The model of college choice can be extended by considering
retirement options. When a person reaches retirement age, there are
usually several options available. He can continue working full time,
or work part time and spend part of his retirement funds, or retire
fully and collect social security and perhaps a pension. The person’s
income under these alternatives depends largely on the job that the
person has held and the retirement plan that the job provided. Three
periods are suﬃcient to capture the decision process. The person goes
to college or not in the ﬁrst period, chooses a job in the second period,
and chooses among the available retirement-age options in the third
period. The high school student knows, when deciding whether to go
to college, that this decision will aﬀect his job opportunities, which in
turn will aﬀect his retirement options. (This foreknowledge is starting
to seem like a mighty big burden for a high school student, but let’s
proceed without getting too depressed.)

CHAPTER 7. VARIATIONS ON A THEME

200

The set of retirement-age alternatives is labeled S with elements
indexed by s. In the third period, the utility that the person obtains
from alternative s if he went to college in the ﬁrst period and had job
Cj
. Conditional on these previous choices,
j in the second period is U3s
Cj
Cj
> U3t
for all s = t and s, t ∈ S.
the person chooses option s if U3s
Similar notation and behavior applies conditional on other choices in
the ﬁrst and second periods.
In the second period, the person recognizes that his job choice will
aﬀect his retirement-age options. He knows he will maximize among
the available options when retirement age arrives. Suppose he chose
college in the ﬁrst period. In the second period, he knows that the
Cj
.
utility he will obtain in the third period if he chooses job j is maxs U3s
The total utility of choosing job j in the second period, given that he
C + θmaxs U Cj ,
chose college in the ﬁrst period, is therefore T UjC = U2j
3s
where θ weights period three relative to period two. He chooses job j if
T UjC > T UkC for all k = j and j, k ∈ J. Similar notation and behavior
occurs if he chose to work in the ﬁrst period.
Consider now the ﬁrst period. He knows that, if he chooses college,
he will choose the job that maximizes his utility from jobs conditional
on going to college, and then will choose the retirement-age option that
maximizes his utility conditional on that chosen job. The total utility
from college is
T UC

= U1c + λmaxj T UjC




Cj
C
= U1c + λmaxj U2j
+ θmaxs U3s
.

This expression is similar to that in the two-period model except that it
includes an additional layer of maximization: the maximization for the
third period is contained in each maximization for the second period.
A similar term gives the total utility of working in the ﬁrst period,
T UW . The person chooses college if T UC > T UW .
This completes the description of the person’s behavior. The reC and
searcher observes a portion of each utility function, U1C , U1W , U2j
W ∀j ∈ J and U Cj and U W j ∀s ∈ S, j ∈ J. The unobserved portions
U2j
3s
3s
are collected labeled by the vector ε with density f (ε). The probability
that the person chooses college is


PC
where

=

I(ε)f (ε)dε

7.7. DYNAMIC OPTIMIZATION

201

I(ε) = 1
if





Cj
Cj
V1C + ε1C + λmaxj V2jC + εC
2j + θmaxs (V3s + ε32 )





Wj
Wj
> V1W + ε1W + λmaxj V2jW + εW
2j + θmaxs (V3s + ε32 )

This expression is the same as in the two-period model except that
now the term inside the indicator function has an extra level of maximization. An accept-reject simulator is obtained by: (1) draw from
Cj
f (ε), (2) calculate the third period utility U3s
for each s, (3) identify
C
the maximum over s, (4) calculate T U2j with this maximum, (5) reC over j, (6)
peat steps 2-5 for each j and identify the maximum of T U2j
calculate T UC using this maximum, (7) repeat steps 2-6 for T UW , (8)
determine whether T UC > T UW and set I = 1 if it is, (9) repeat steps
1-8 many times and average the results. Convenient error partitioning can also be used. For example if all errors are iid extreme value,
then the ﬁrst-period choice probabilities, conditional on draws of the
second- and third-period errors, are logit; the second-period probabilities, conditional on the third-period errors, are logit; and the third
period probabilities are logit.
We can now generalize these concepts and introduce some widelyused terminology. Note that the analysis of the person’s behavior and
the simulation of the choice probabilities by the researcher start with
the last period and work backwards in time to the ﬁrst period. This
process is called backwards recursion. Suppose there are J alternatives
in each of T equal-length time periods. Let a sequence of choices up to
period t be denoted {i1 , i2 , · · · , it }. The utility that the person obtains
in period t from alternative j is Utj (i1 , i2 , · · · , it−1 ), which depends on
all previous choices. If the person chooses alternative j in period t, he
will obtain this utility plus the future utility of choices conditioned on
this choice. The total utility (current and future) that the person obtains from choosing alternative j in period t is T Utj (i1 , i2 , · · · , it−1 ). He
chooses the alternative in the current period that provides the greatest
total utility. Therefore the total utility he receives from his optimal
choice in period t is T Ut (i1 , i2 , · · · , it−1 ) = maxj T Utj (i1 , i2 , · · · , it−1 ).
This total utility from the optimal choice at time t, T Ut , is called the
valuation function at time t.
The person chooses optimally in the current period with knowledge
that he will choose optimally in the future. This fact establishes a con-

202

CHAPTER 7. VARIATIONS ON A THEME

venient relation between the valuation function in successive periods.
In particular,
T Ut (i1 , · · · , it−1 ) = maxj [Ujt (i1 , · · · , it−1 ) + δT Ut+1 (i1 , · · · , it = j)]
where δ is a parameter that discounts the future. T Ut+1 on the right
hand side is the total utility that the person will obtain in period t + 1
onward if he chooses alternative j in period t (i.e., if it = j). The
equation states that the total utility that the person obtains from optimizing behavior from period t onwards, given previous choices, is the
maximum over j of: the utility from j in period t plus the discounted
total utility from optimizing behavior from period t + 1 onwards conditional on choosing j in period t. This relation is Bellman’s equation
(1957) applied to discrete choice with perfect information.
T Utj (i1 , · · · , it−1 ) is sometimes called the conditional valuation function, conditional on choosing alternative j in period t. A Bellman
equation also operates for this term:
T Utj (i1 , · · · , it−1 ) = Ujt (i1 , · · · , it−1 + δmaxk [T Ut+1,k (i1 , · · · , it = j)] .
Since by deﬁnition T Ut (i1 , · · · , it−1 ) = maxj [T Utj (i1 , · · · , it−1 )], the
Bellman equation in terms of conditional valuation function is equivalent to the Bellman equation in terms of the unconditional valuation
function.
If T is ﬁnite, the Bellman equation can be applied with backwards
recursion to calculate T Utj for each time period. At t = T , there is
no future time period, and so T UT j (i1 , · · · , iT −1 ) = UT j (i1 , · · · , iT −1 ).
Then T UT −1,j (i1 , · · · , iT −2 ) is calculated from T UT j (i1 , · · · , iT −1 ) using Bellman’s equation. And so on forward to t = 1. Note that
Utj (i1 , · · · , it−1 ) must be calculated for each t, j, and, importantly, for
each possible sequence of past choices, i1 , · · · , it−1 . With J alternatives in T time periods, the recursion requires calculation of (J T )T
utilities (that is, J T possible sequences of choices, with each sequence
containing T one-period utilities.) To simulate the probabilities, the
researcher must calculate these utilities for each draw of unobserved
factors. And these probabilities must be simulated for each value of
the parameters in the numerical search for the estimates. This huge
computational burden is called the curse of dimensionality and is the
main stumbling block to application of the procedures with more than
a few time periods and/or alternatives. We discuss in the next subsection procedures that have been suggested to avoid or mitigate this

7.7. DYNAMIC OPTIMIZATION

203

curse, after showing that the curse is even greater when uncertainty is
considered.

7.7.3

Uncertainty about future impacts

In the analysis so far we have assumed that the decision-maker knows
the utility for each alternative in each future time period and how this
utility is aﬀected by prior choices. Usually, the decision-maker does
not possess such foreknowledge. A degree of uncertainty shrouds the
future impacts of current choices.
The behavioral model can be adapted to incorporate uncertainty.
For simplicity, return to the two-period model for our high school student. In the ﬁrst period, the student does not know for sure the secondC and U W ∀j. For example, the student does not
period utilities, U2j
2j
know, before going to college, how strong the economy, and hence his
job possibilities, will be when he graduates. These utilities can be
C (e) where e refers colexpressed as functions of unknown factors: U2j
lectively to all factors in period two that are unknown in period one.
These unknown factors will become known (that is, will be revealed)
when the student reaches the second period, but are unknown to the
person in the ﬁrst period. The student has a subjective distribution on
e that reﬂects the likelihood that he ascribes to the unknown factors
taking a particular realization in the second period. This density is
labeled g(e). He knows that, whatever realization of e actually occurs,
he will, in the second period, choose the job that gives him the maxiC (e) in the second
mum utility. That is, he will receive utility maxj U2j
period if he chooses college in the ﬁrst period and the unknown factors
end up being e. In the ﬁrst period, when evaluating whether to go to
college, he takes the expectation of this future utility over all possible
realizations of the unknown factors, using his subjective distribution
over these realizations. The expected utility that he will obtain in
the
second period
# if he chooses college in the ﬁrst period is therefore
"
C (e)) g(e)d(e). The total expected utility from choosing
maxj (U2j
college in the ﬁrst period is then:
 "

T EUC = U1C + λ

#

C
maxj (U2j
(e)) g(e)d(e)

T EUW is deﬁned similarly. The person chooses college if T EUC >
T EUW . In the second period, the unknown factors become known, and

CHAPTER 7. VARIATIONS ON A THEME

204

C (e∗) > U C (e∗)
the person chooses job j if he had chosen college if U2j
2k
for all k = j, where e∗ is the realization that actually occurred.
Turning to the researcher, we have an extra complication introduced by g(e), the decision-maker’s subjective distribution for unknown factors. In addition to not knowing utilities in their entirety,
the researcher has only partial knowledge of the decision-maker’s subjective probability g(e). This lack of information is usually represented
through parameterization. The researcher speciﬁes a density, labeled
h(e | θ), that depends on unknown parameters θ. The researcher then
assumes that the person’s subjective density is the speciﬁed density
evaluated at the true parameters θ∗ . That is, the researcher assumes
h(e | θ∗ ) = g(e). Stated more persuasively and accurately: the true
parameters are, by deﬁnition, the parameters for which the researcher’s
speciﬁed density h(e | θ) becomes the density g(e) that the person actually used. With a suﬃciently ﬂexible h, any g can be represented as
h evaluated at some parameters, which are called the true parameters.
These parameters are estimated along with the parameters that enter
utility. (Other ways of representing the researcher’s lack of knowledge
about g(e) can be speciﬁed; however, they are generally more complex.)
Utilities are decomposed into their observed and unobserved portions, with the unobserved portions collectively called ε with density
f (ε). The probability that the person goes to college is

PC

= P rob(T EUC > T EUW )
 

=



I(V1c + ε1C + λ



{maxj (V2jC (e) + εC
2j (e))}h(e | θ)d(e))

f (ε)dε.

The probablity can be approximated by simulating the inside integral
within the simulation of the outside integral. (1) Take a draw of ε.
(2a) Take a draw of e from h(e | θ). (2b) Using this draw, calculate
the term in squiggly brackets. (2c) Repeat steps 2a-b many times and
average the results. (3) Using the value from 2c, calculate the term
in square brackets. (4) Repeat steps 1-3 many times and average the
results. As the reader can see, the curse of dimensionality grows worse.
Several authors have suggested ways to reduce the computational
burden. Keane and Wolpin (1994) calculate the valuation function
at selected realizations of the unknown factors and past choices; they
then approximate the valuation function at other realizations and past
choices through interpolating from the calculated valuations. Rust

7.7. DYNAMIC OPTIMIZATION

205

(1997) suggests simulating future paths and using the average over
these simulated paths as an approximation in the valuation function.
Hotz and Miller (1993) and Hotz et al. (1993) show that there is a
correspondence between the valuation function in each time period
and the choice probabilities in future periods. This correspondence
allows the valuation functions to be calculated with these probabilities
instead of backwards recursion.
Each of these procedures has limitations and is applicable in only
certain situations, which the authors themselves describe. As Rust
(1994) has observed, it is unlikely that a general-purpose breakthrough
will arise that makes estimation simple for all forms of dynamic optimization models. Inevitably the researcher will need to make tradeoﬀs
in specifying the model to assure feasibility, and the most appropriate
speciﬁcation and estimation method will depend on the particulars of
the choice process and the goals of the research. In this regard, I have
found that two simpliﬁcations are very powerful in that they often provide a large gain in computational feasibility for a relatively small loss
(and sometimes a gain) in content.
The ﬁrst suggestion is for the researcher to consider ways to capture
the nature of the choice situation with as few time periods as possible.
Sometimes, in fact usually, time periods will need to be deﬁned not
by the standard markers, such as year or month, but rather in a way
that is more structural to the decision process. For example, for the
high school student deciding whether to go to college, it might seem
natural to say that the student makes a choice each year among the
jobs and schooling options that are available in that year, given his
past choices. Indeed, this statement is true: the student does indeed
make annual (or even monthly, weekly, daily) choices. However, such a
model would clearly face the curse of dimensionality. In contrast, the
speciﬁcation that we discussed above involves only two time periods,
or three if retirement is considered. Estimation is quite feasible for this
speciﬁcation. In fact, the two-period model might be more accurate
than an annual model: students deciding on college probably think in
terms of the college years and their post-college options, rather than
trying to anticipate their future choices in each future year. McFadden
and Train (1996) provide an example of how an dynamic optimization
model with only a few well-considered periods can accurately capture
the nature of the choice situation.
A second powerful simpliﬁcation was ﬁrst noted by Rust (1987).

CHAPTER 7. VARIATIONS ON A THEME

206

Suppose that the factors that the decision-maker does not observe
beforehand are also the factors that the researcher does not observe
(either before or after), and that these factors are thought by the
decision-maker to be iid extreme value. Under this admittedly restrictive assumption, the choice probabilities take a closed form that
is easy to calculate. The result can be readily derived for our model of
college choice. Assume that the student, when in the ﬁrst period, decomposes second-period utility into an known and unknown part, e.g.,
C (e) = V C + eC , and assumes that eC follows an extreme value disU2j
2j
2j
2j
tribution independent of all else. This unknown factor becomes known
to the student in the second period, such that second-period choice
C ∀j. However, in the ﬁrst period
entails maximization over known U2j
it is unknown. Recall from section 3.5 that the expected maximum of
utilities that are iid extreme value takes the familiar log-sum formula.
In our context, this result means that




E maxj (V2jC + εC
2j )




C
V2j

= αln 

e



j

which we can label LS2C . LS2W is derived similarly. The person chooses
college if then
T EUC
U1C + λLS2C

> T EUW
> U1W + λLS2W

Note that this decision-rule is in closed form: the integral over unknown future factors becomes the log-sum formula. Consider now the
researcher. Each ﬁrst-period utility is decomposed into an observed
and unobserved part, U1C = V1C + ε1C , U1W = V1W + ε1W , and we
assume that the unobserved portions are iid extreme value. For the
second-period utilities, we make a fairly restrictive assumption. We assume that the part of utility that the researcher does not observe is the
same as the part of utility that the student does not know beforehand.
C = V C + εC ∀j, where the researcher’s εC is
That is, we assume U2j
2j
2j
2j
.
Under
this
assumption,
the
researcher
the same as the student’s eC
2j
can calculate the log-sum term for future utility, LC2C and LS2W , exactly, since these terms depend only on the observed portion of utility
in the second period, V2jC ∀j, which is observed by the researcher and
known beforehand by the decision-maker. The probability of the stu-

7.7. DYNAMIC OPTIMIZATION

207

dent choosing college is then
PC

= P rob(T EUC > T EUW )
= P rob(U1C + λLS2C > U1W + λLS2W
= P rob(V1C + ε1C + λLS2C > V1W + ε1W + λLS2W
C

=

eV1C +λLS2
C

W

eV1C +LS2 + eV1W +λLS2

.

The model takes the same form as the upper part of a nested logit
model: the ﬁrst-period choice probability is the logit formula with
a log-sum term included as an extra explanatory variable. Multiple
periods are handled the same way as multi-level nested logits.
It is doubtful that the researcher, in reality, observes everything
that the decision-maker knows beforehand. However, the simpliﬁcation that arises from this assumption is so great, and the curse of
dimensionality that would arise otherwise is so severe, that proceeding
as if it were true is perhaps worthwhile in many situations.

208

CHAPTER 7. VARIATIONS ON A THEME

Part II

Estimation

209

Chapter 8

Numerical Maximization
8.1

Motivation

Most estimation involves maximization of some function, such as the
likelihood function, the simulated likelihood function, or squared moment conditions. This chapter describes numerical procedures that are
used to maximize a likelihood function. Analogous procedures apply
when maximizing other functions.
Knowing and being able to apply these procedures is critical in our
new age of discrete choice modeling. In the past, researchers adapted
their speciﬁcations to the few convenient models that were available.
These models were included in commercially available estimation packages, such that the researcher could estimate the models without knowing the details of how the estimation was actually performed from a
numerical perspective. The thrust of the wave of discrete choice methods is to free the researcher to specify models that are tailor-made to
her situation and issues. Exercising this freedom means that the researcher will often ﬁnd herself specifying a model that is not exactly
the same as any in commercial software. The researcher will need to
write special code for her special model.
The purpose of this chapter is to assist in this exercise. Though not
usually taught in econometrics courses, the procedures for maximization are fairly straightforward and easy to implement. Once learned,
the freedom they allow is invaluable.
211

212

8.2

CHAPTER 8. NUMERICAL MAXIMIZATION

Notation


The log-likelihood function takes the form LL(β) = N
n=1 lnPn (β)/N
where Pn (β) is the probability of the observed outcome for decisionmaker n, N is the sample size, and β is a K ×1 vector of parameters. In
this chapter, we divide the log-likelihood function by N , such that LL
is the average log-likelihood in the sample. Doing so does not aﬀect the
location of the maximum (since N is ﬁxed for a given sample) and yet
facilitates interpretation of some of the procedures. All the procedures
operate the same whether or not the log-likelihood is divided by N .
The reader can verify this fact as we go along by observing that N
cancels out of the relevant formulas.
The goal is to ﬁnd the value of β that maximizes LL(β). In terms
of Figure 8.1, the goal is to locate β̂. Note in this ﬁgure that LL is
always negative, since the likelihood is a probability between 0 and 1
and the log of any number between 0 and 1 is negative. Numerically,
the maximum can be found by “walking up” the likelihood function
until no further increase can be found. The researcher speciﬁes starting values β0 . Each iteration, or step, moves to a new value of the
parameters at which LL(β) is higher than at the previous value. Denote the current value of β as βt , which is attained after t steps from
the starting values. The question is: what is the best step we can take
next, that is, what is the best value for βt+1 ?
The gradient at βt is the vector of ﬁrst derivatives of LL(β) evaluated at βt :


gt =

∂LL(β)
∂β



.
βt

This vector tells us which way to step in order to go up the likelihood
function. The Hessian is the matrix of second derivatives:


Ht =

∂gt
∂β 





=
βt

∂ 2 LL(β)
∂β∂β 



.
βt

The gradient has dimension K × 1 and the Hessian is K × K. As we
will see, the Hessian can help us to know how far to step, given that
the gradient tells us in which direction to step.

8.3. ALGORITHMS
βt

213
^

β
β

LL(β)

Figure 8.1: Maximum likelihood estimate.

8.3

Algorithms

Of the numerous maximization algorithms that have been developed
over the years, I describe below only the most prominent, with an
emphasis on the pedagogical value of the procedures as well as their
practical use. Readers who are induced to explore further will ﬁnd
the treatments by Judge et al. (1985, Appendix B) and Ruud (2000)
rewarding.

8.3.1

Newton-Raphson

To determine the best value of βt+1 , take a second order Taylor’s approximation of LL(βt+1 ) around LL(βt ):
1
LL(βt+1 ) = LL(βt ) + (βt+1 − βt ) gt + (βt+1 − βt ) Ht (βt+1 − βt ). (8.1)
2
Now ﬁnd the value of βt+1 that maximizes this approximation to
LL(βt+1 ):
∂LL(βt+1 )
= gt + Ht (βt+1 − βt ) = 0.
∂βt+1
Ht (βt+1 − βt ) = −gt

CHAPTER 8. NUMERICAL MAXIMIZATION

214

(βt+1 − βt ) = −Ht−1 gt

βt+1 = βt + (−Ht−1 )gt .

The Newton-Raphson procedure uses this formula. The step from the
current value of β to the new value is (−Ht−1 )gt , that is, the gradient
vector premultiplied by the negative of the inverse of the Hessian.
This formula is intuitively meaningful. Consider K = 1, as illustrated in Figure 8.2. The slope of the log-likelihood function is gt . The
βt

βt
β

β

Positive slope

LL(β)

move forward

Negative slope

move backward

LL(β)

Figure 8.2: Direction of step follows the slope.
second derivative is the Hessian Ht , which is negative for this graph
since the curve is drawn to be concave. The negative of this negative
Hessian is positive and represents the degree of curvature. That is,
(−Ht ) is the positive curvature. Each step of β is the slope of the loglikelihood function divided by its curvature. If the slope is positive, β is
raised as in the ﬁrst panel, and β is lowered if the slope if negative as in
the second panel. The curvature determines how large a step is made.
If the curvature is great, meaning that the slope changes quickly as in
the ﬁrst panel of Figure 8.3, then the maximum is likely to be close
and so a small step is taken (dividing the gradient by a large number
gives a small number). Conversely, if the curvature is small, meaning
that the slope is not changing much, then the maximum seems to be
further away and so a larger step is taken.
Three issues are relevant to the Newton-Raphson (N-R) procedure.

8.3. ALGORITHMS
βt

215

^

β

βt

^

β
β

β

Greater curvature
smaller step

Less curvature
larger step

LL(β)

LL(β)

Figure 8.3: Step size is inversely related to curvature.
Quadratics
If LL(β) were exactly quadratic in β, then the N-R procedure would
reach the maximum in one step from any starting value. This fact can
easily be veriﬁed with K = 1. If LL(β) is quadratic, then it can be
written as:
LL(β) = a + bβ + cβ 2 .
The maximum is:
∂LL(β)
∂β

= b + 2cβ = 0

b
.
2c
The gradient and Hessian are gt = b + 2cβt and Ht = 2c, and so N-R
gives us:
β̂ = −

βt+1 = βt − Ht−1 gt
1
= βt − (b + 2cβt )
2c
b
− βt
= βt −
2c
b
= − = β̂.
2c
Most log-likelihood functions are not quadratic, and so the N-R
procedure takes more than one step to reach the maximum. However,
knowing how N-R behaves in the quadratic case helps in understanding
its behavior with non-quadratic LL, as we will see below.

CHAPTER 8. NUMERICAL MAXIMIZATION

216
Step-size

It is possible for the N-R procedure, as for other procedure below, to
step past the maximum and move to a lower LL(β). Figure 8.4 depicts
the situation. The actual LL is given by the solid line. The dotted line
is a quadratic function that has the slope and curvature that LL has
at the point βt . The N-R procedure moves to the top of the quadratic,
to βt+1 . However, LL(βt+1 ) is lower than LL(βt ) in this case.

βt

βt+1
β
Quadratic

LL(βt)
LL(βt+1)

Actual LL

LL(β)

Figure 8.4: Step may go beyond maximum to lower LL.
To account for this possibility, the step is multiplied by a scalar λ
in the N-R formula:
βt+1 = βt + λ(−Ht )−1 gt .
The vector (−Ht )−1 gt is called the direction and λ is called the stepsize. (This terminology is standard even though (−Ht )−1 gt contains
step-size information through Ht , as explained above in relation to
Figure 8.3.) The step-size λ is reduced to assure that each step of
the N-R procedure provides an increase in LL(β). The adjustment is
performed separately in each iteration, as follows.
Start with λ = 1. If LL(βt+1 ) > LL(βt ), move to βt+1 and start a
new iteration. If LL(βt+1 ) < LL(βt ), then set λ = 1/2 and try again.
If with λ = 1/2, LL(βt+1 ) is still below LL(βt ), then set λ = 1/4
and try again. Continue this process until a λ is found for which
LL(βt+1 ) > LL(βt ). If this process results in a tiny λ, then little

8.3. ALGORITHMS

217

progress is made in ﬁnding the maximum. This can be taken as a
signal to the researcher that a diﬀerent iteration procedure might be
needed.
An analogous step-size adjustment can be made in the other direction, that is, by increasing λ when appropriate. A case is shown
in Figure 8.5. The top of the quadratic is obtained with a step-size

βt

βt+1

for λ=1

βt+1

for λ=2

βt+1

for λ=4

β

Actual LL
Quadratic

LL(β)

Figure 8.5: Double λ as long as LL rises.
of λ = 1. However, the LL(β) is not quadratic and its maximum is
further away. The step-size can be adjusted upward as long as the
LL(β) continues to rise. That is, calculate βt+1 with λ = 1 at βt+1 . If
LL(βt+1 ) > LL(βt ), then try λ = 2. If the βt+1 based on λ = 2 gives
a higher value of the log-likelihood function than with λ = 1, then try
λ = 4. And so on, doubling λ as long as doing so further raises the
likelihood function. Each time, LL(βt+1 ) with a doubled λ is compared
to its value at the previously tried λ, rather than with λ = 1, in order
to assure that each doubling raises the likelihood function further than
it had previously been raised with smaller λ’s. In Figure 8.5, a ﬁnal
step-size of 2 is used, since the likelihood function with λ = 4 is lower
than when λ = 2, even though it is higher than with λ = 1.
The advantage of this approach of raising λ is that it usually reduces the number of iterations that are needed to reach the maximum.
New values of λ can be tried without re-calculating gt and Ht , while
each new iteration requires calculation of these terms. Adjusting λ can

218

CHAPTER 8. NUMERICAL MAXIMIZATION

therefore quicken the search for the maximum.
Concavity
If the log-likelihood function is globally concave, then the N-R procedure is guaranteed to provide an increase in the likelihood function
at each iteration. This fact is demonstrated as follows. LL(β) being
concave means that its Hessian is negative deﬁnite at all values of β.
(In one dimension, the slope of LL(β) is declining such that the second
derivative is negative.) If H is negative deﬁnite, then H −1 is also negative deﬁnite, and (−H −1 ) is positive deﬁnite. By deﬁnition, a symmetric matrix M is positive deﬁnite if x M x > 0 for any x = 0. Consider
a ﬁrst-order Taylor’s approximation of LL(βt+1 ) around LL(βt ):
LL(βt+1 ) = LL(βt ) + (βt+1 − βt ) gt .
Under the N-R procedure, βt+1 − βt = λ(−Ht−1 )gt . Substituting gives:
LL(βt+1 ) = LL(βt ) + (λ(−Ht−1 )gt ) gt
= LL(βt ) + λgt (−Ht−1 )gt .
Since −H −1 is positive deﬁnite, the quantity gt (−Ht−1 )gt > 0 and
LL(βt+1 ) > LL(βt ). Note that since this comparison is based on a
ﬁrst-order approximation, an increase in LL(β) might only be obtained
in a small neighborhood of βt . That is, the value of λ that provides an
increase might be small. However, an increase is indeed guaranteed at
each iteration if LL(β) is globally concave.
Suppose the log-likelihood function has regions that are not concave. In these areas, the N-R procedure can fail to ﬁnd an increase.
If the function is convex at βt , then the N-R procedure moves in the
opposite direction of the slope of the log-likelihood function. The situation is illustrated in Figure 8.6 for K = 1. The N-R step with one
parameter is LL (β)/(−LL (β)), where the prime denotes derivatives.
The second derivative is positive at βt since the slope is rising. Therefore, −LL (β) is negative, and the step is in the opposite direction of
the slope. With K > 1, if the Hessian is positive deﬁnite at βt , then
(−Ht−1 ) is negative deﬁnite, and N-R steps in the opposite direction
of gt .
The sign of the Hessian can be reversed in these situations. However, there is no reason for using the Hessian where the function is
not concave, since the Hessian in convex regions does not provide any

8.3. ALGORITHMS

219

βt
β

LL(β)

Figure 8.6: N-R in convex portion of LL.

useful information on where the maximum might be. There are easier
ways to ﬁnd an increase in these situations than calculating the Hessian and reversing its sign. This issue is part of the motivation for
other procedures.
The N-R procedure has two drawbacks. First, calculation of the
Hessian is usually computationally intensive. Procedures that avoid
calculating the Hessian at every iteration can be much faster. Second,
as we have just shown, the N-R procedure does not guarantee an increase in each step if the log-likelihood function is not globally concave.
When (−Ht−1 ) is not positive deﬁnite, an increase is not guaranteed.
Other approaches use approximations to the Hessian that address
these two issues. The methods diﬀer in the form of the approximation.
Each procedure deﬁnes a step as:

βt+1 = βt + λMt gt ,
where Mt is a K ×K matrix. For N-R, Mt = −H −1 . Other procedures
use Mt ’s that are easier to calculate than the Hessian and are necessarily positive deﬁnite so as to guarantee an increase at each iteration
even in convex regions of the log-likelihood function.

CHAPTER 8. NUMERICAL MAXIMIZATION

220

8.3.2

BHHH

The N-R procedure does not utilize the fact that the function being
maximized is actually the sum of log-likelihoods over a sample of observations. The gradient and Hessian are calculated just as one would do
in maximizing any function. This characteristic of N-R provides generality, in that the N-R procedure can be used to maximize any function,
not just a log-likelihood. However, as we will see, maximization can
be faster if we utilize the fact that the function being maximized is a
sum of terms in a sample.
We need some additional notation to reﬂect the fact that the loglikelihood function is a sum over observations. The score of an observation is the derivative of that observation’s log likelihood with respect
to the parameters: sn (βt ) = ∂lnPn (β)/∂β evaluated at βt . The gradient, which we deﬁned above and used for the N-R procedure, is the

average score: gt = n sn (βt )/N . The outer product of observation
n’s score is the K × K matrix:


s1n s1n
 s1 s2

sn (βt )sn (βt ) =  n n
 ···
s1n sK
n

s1n s2n
s2n s2n

···
···

s2n sK
n

K
· · · sK
n sn



s1n sK
n

s2n sK
n 



where skn is the k-th element of sn (βt ) with the dependence on βt
omitted for convenience. The average outer product in the sample is

Bt = n sn (βt )sn (βt ) /N . This average outer product is related to
the covariance matrix: if the average score were zero, then B would
be the covariance matrix of scores in the sample. Often Bt is called
the “outer product of the gradient.” This term can be confusing since
Bt is not the outer product of gt . However, the term reﬂects the fact
that the score is an observation-speciﬁc gradient and Bt is the average
outer product of these observation-speciﬁc gradients.
At the parameters that maximize of the likelihood function, the
average score is indeed zero. The maximum occurs where the slope is
zero, which means that the gradient, i.e., the average score, is zero.
Since the average score is zero, the outer product of the scores, Bt ,
becomes the variance of the scores. That is, at the maximizing values
of the parameters, Bt is the variance of scores in the sample.
The variance of the scores provides important information for locating the maximum of the likelihood function. In particular, this variance provides a measure of the curvature of the log-likelihood function,

8.3. ALGORITHMS

221

similar to the Hessian. Suppose that everyone in the sample has similar scores. Since everyone is fairly similar, the sample contains very
little information. The log-likelihood function is fairly ﬂat in this situation, reﬂecting the fact that the sample contains little information
such that diﬀerent values of the parameters ﬁt the data about the same.
The ﬁrst panel of Figure 8.7 depicts this situation: with a fairly ﬂat
log-likelihood, diﬀerent values of β give similar values of LL(β). The
β

β

LL(β)

LL nearly flat near
maximum

LL(β)

LL highly curved
near maximum

Figure 8.7: Shape of log-likelihood function near maximum.
curvature is small when the variance of the scores is small. Conversely,
the scores diﬀering greatly over observations means that the observations are quite diﬀerent and the sample provides considerable amount
of information. The log-likelihood function is highly peaked, reﬂecting
the fact that the sample provides good information on the values of
β. Moving away from the maximizing values of β causes a large loss
of ﬁt. The second panel of Figure 8.7 illustrates this situation. The
curvature is great when the variance of the scores is high.
These ideas about the variance of the scores and their relation
to the curvature of the log-likelihood function are formalized in the
famous “information identity.” This identity states that the covariance
of the scores at the true parameters is equal to the negative of the
expected Hessian. We demonstrate this identity in the last section of
this chapter; Theil (1971) and Ruud (2000) also provide useful and
heuristic proofs. However, even without proof, it makes intuitive sense
that the variance of the scores provides information on the curvature
of the log-likelihood function.
Berndt, Hall, Hall and Hausman (1974), hereafter referred to as
BHHH (and commonly pronounced B-triple H), proposed using this relationship in the numerical search for the maximum of the log-likelihood

222

CHAPTER 8. NUMERICAL MAXIMIZATION

function. In particular, the BHHH procedure uses Bt in the optimization routine in place of −Ht . Each iteration is deﬁned by:
βt+1 = βt + λBt−1 gt .
This step is the same as for N-R except that Bt is used in place of −Ht .
Given the discussion above about the variance of the scores indicating
the curvature of the log-likelihood function, replacing −Ht with Bt
makes sense.
There are two advantages to the BHHH procedure over N-R:
(1) Bt is far faster to calculate that Ht . The scores must be calculated to obtain the gradient for the N-R procedure anyway, and so
calculating Bt as the average outer product of the scores takes hardly
any extra computer time. In contrast, calculating Ht requires calculating the second derivatives of the log-likelihood function.
(2) B is necessarily positive deﬁnite. The BHHH procedure is therefore guaranteed to provide an increase in LL(β) in each iteration, even
in convex portions of the function. Using the proof given above for NR when −Ht is positive deﬁnite, the BHHH step λBt−1 gt raises LL(β)
for a small enough λ.
Our discussion about the relation of the variance of the scores to the
curvature of the log-likelihood function can be stated a bit more precisely. For a correctly speciﬁed model at the true parameters, B → −H
as N → ∞. This relation between the two matrices is an implication of
the information identity, discussed at greater length in the last section.
This convergence suggests that Bt can be considered an approximation
to −Ht . The approximation is expected to be better as sample size
rises. And the approximation can be expected to be better close to the
true parameters, where the expected score is zero and the information
identity holds, than for values of β that are farther from their true
values. That is, Bt can be expected to be a better approximation close
to the maximum of the LL(β) than farther from the maximum.
There are some drawbacks of BHHH. The procedure can give small
steps that raise LL(β) very little, especially when the iterative process
is far from the maximum. This behavior can arise because Bt is not a
good approximation to −Ht far from the true value. Or it might arise
because LL(β) is highly non-quadratic in the area where the problem
is occurring. If the function is highly non-quadratic, N-R does not perform well as explained above; since BHHH is an approximation to N-R,

8.3. ALGORITHMS

223

BHHH would not perform well even if Bt were a good approximation
to −Ht .

8.3.3

BHHH-2

The BHHH procedure relies on the matrix Bt which, as we have described, captures the covariance of the scores when the average score
is zero (i.e., at the maximizing value of β.) When the iterative process
is not at the maximum, the average scores is not zero and Bt does not
represent the covariance of the scores.
A variant on the BHHH procedure is obtained by subtracting out
the mean score before taking the outer product. For any level of the
average score, the covariance of the scores over the sampled decisionmakers is
(sn (βt ) − gt )(sn (βt ) − gt ) /N
Wt =
n

where the gradient gt is the average score. Wt is the covariance of the
scores around their mean, and Bt is the average outer product of the
scores. Wt and Bt are the same when the mean gradient is zero (i.e.,
at the maximizing value of β), but diﬀer otherwise.
The maximization procedure can use Wt instead of Bt :
βt+1 = βt + λWt−1 gt .
This procedure, which I call BHHH-2, has the same advantages as
BHHH. Wt is necessarily positive deﬁnite, since it proportional to a
covariance matrix, and so the procedure is guaranteed to provide an
increase in LL(β) at every iteration. Also, for a correctly speciﬁed
model at the true parameters, W → −H as N → ∞, such that Wt
can be considered an approximation to −Ht . The information identity
establishes this equivalence, as for B.
For β’s that are close to the maximizing value, BHHH and BHHH-2
give nearly the same results. They can diﬀer greatly at values far from
the maximum. Experience indicates, however, that the two methods
are fairly similar in that either both of them work eﬀectively for a given
likelihood function, or neither of them does. The main value of BHHH2 is pedagogical, to elucidate the relation between the covariance of
the scores and the average outer product of the scores. This relation is
critical in the analysis of the information identity in the last section.

CHAPTER 8. NUMERICAL MAXIMIZATION

224

8.3.4

Steepest Ascent

This procedure is deﬁned by the iteration formula:
βt+1 = βt + λgt .
The deﬁning matrix for this procedure is the identity matrix I. Since I
is positive deﬁnite, the method guarantees an increase in each iteration.
It is called “steepest ascent” because it provides the greatest possible
increase in LL(β) for the distance between βt and βt+1 , at least for
small enough distance. Any other step of the same distance provides
less increase. This fact is demonstrated as follows. Take a ﬁrst-order
Taylor’s expansion of LL(βt+1 ) around LL(βt ): L(βt+1 ) = βt + (βt+1 −
βt )gt . Maximize this expression for
√ LL(βt+1 ) subject to the Euclidian
distance from βt to βt+1 being k. That is, maximize subject to
(βt+1 − βt ) (βt+1 − βt ) = k. The Lagrangian is
L = LL(βt ) + (βt+1 − βt )gt −

1
[(βt+1 − βt ) (βt+1 − βt ) − k]
2λ

∂L
1
= gt − (βt+1 − βt ) = 0
∂βt+1
λ
βt+1 − βt = λgt
βt+1 = βt + λgt
which is the formula for steepest ascent.
While at ﬁrst encounter, one might think that the method of steepest ascent is the best possible procedure since it gives the greatest possible increase in the log-likelihood function at each step. However, the
method’s property is actually less grand than this statement implies.
Note that the derivation relies on a ﬁrst-order approximation that is
only accurate in a neighborhood of βt . The correct statement of the
result is that there is some suﬃciently small distance for which the
method of steepest ascent gives the greatest increase for that distance.
This distinction is critical. Experience indicates that the step-sizes
are often very small with this method. The fact that the ascent is
greater than for any other step of the same distance is not particularly
comforting when the steps are so small. Usually, BHHH and BHHH-2
converge more quickly than the method of steepest ascent.

8.3. ALGORITHMS

8.3.5

225

DFP and BFGS

The methods of Davidon-Fletcher-Powell (DFP) and Broyden-FletcherGoldfarb-Shanno (BFGS) calculate the approximate Hessian is a way
that uses information at more than one point on the likelihood function. Recall that N-R uses the actual Hessian at βt to determine the
step to βt+1 , and BHHH and BHHH-2 use the gradient matrix at βt to
approximate the Hessian. Only information at βt is being used to determine the step in these procedures. If the function is quadratic, then
information at one point on the function provides all the information
that is needed about the shape of the function. These methods work
well, therefore, when the log-likelihood function is close to quadratic.
In contrast, the DFP and BFGS procedures use information at several
points to obtain a sense of the curvature of the log-likelihood function.
The Hessian is the matrix of second derivatives. As such, it gives
the amount by which the slope of the curve changes as one moves along
the curve. The Hessian is deﬁned for inﬁnitesimally small movements.
Since we are interested in making large steps, understanding how the
slope changes for non-inﬁnitesimal movements is useful. An “arc” Hessian can be deﬁned on the basis of how the gradient changes from one
point to another. For example, for function f (x), suppose the slope at
x = 3 is 25 and at x = 4 the slope is 19. The change in slope for a one
unit change in x is −6. In this case, the arc Hessian is −6, representing
the change in the slope as a step is taken from x = 3 to x = 4.
The procedures of DFP and BFGS use these concepts to approximate the Hessian. The gradient is calculated at each step in the iteration process. The diﬀerence in the gradient between the various points
that have been reached is used to calculate an arc Hessian over these
points. This arc Hessian reﬂects the actual change in gradient that
occurs for actual movement on the curve, as opposed to the Hessian
which simply reﬂects the change in slope for inﬁnitesimally small steps
around that point. When the log-likelihood function is non-quadratic,
the Hessian at any point provides little information about the shape
of the function. The arc Hessian provides better information.
At each iteration, the DFP and BFGS procedures update the arc
Hessian using information that is obtained at the new point, that is,
using the new gradient. The two procedures diﬀer in how the updating in performed; see Greene (2000) for details. Both methods are
extremely eﬀective, usually far more eﬃcient that N-R, BHHH, BHHH-

226

CHAPTER 8. NUMERICAL MAXIMIZATION

2, or steepest ascent. BFGS reﬁnes DFP, and my experience indicates
that it nearly always works better. BFGS is the default algorithm in
the optimization routines of many commercial software packages.

8.4

Convergence criterion

In theory the maximum of LL(β) occurs when the gradient vector is
zero. In practice, the calculated gradient vector is never exactly zero:
it can be very close, but a series of calculations on a computer cannot
produce a result of exactly zero (unless of course, the result is set to
zero through a Boolean operator or by multiplication by zero, neither
of which arises in calculation of the gradient.) The question arises:
when are we suﬃciently close to the maximum to justify stopping the
iterative process?
The statistic mt = gt (−Ht−1 )gt is often used to evaluate convergence. The researcher speciﬁes a small value for m, such as m̆ = .0001,
and determines in each iteration whether gt (−Ht−1 )gt < m̆. If this
inequality is satisﬁed, the iterative process stops and the parameters
at that iteration are considered the converged values, that is, the estimates. For procedures other than N-R that use an approximate Hessian in the iterative process, the approximation is used in the convergence statistic to avoid calculating the actual Hessian. Close to the
maximum, where the criterion becomes relevant, each form of approximate Hessian that we have discussed is expected to be similar to the
actual Hessian.
The statistic mt is the test statistic for the hypothesis that all
elements of the gradient vector are zero. The statistic is distributed
chi-squared with K degrees of freedom. However, the convergence
criterion m̆ is usually set far more stringently (that is, lower) than the
critical value of a chi-squared at standard levels of signiﬁcance, so as to
assure that the estimated parameters are very close to the maximizing
values. Usually, the hypothesis that the gradient elements are zero
cannot be rejected for a relatively wide area around the maximum. The
distinction can be illustrated for an estimated coeﬃcient that has a tstatistic of 1.96. The hypothesis cannot be rejected that this coeﬃcient
is any value between zero and twice its estimated value. However,
we would not want convergence to be deﬁned as having reached any
parameter value within this range.
It is tempting to view small changes in βt from one iteration to the

8.5. LOCAL VERSUS GLOBAL MAXIMUM

227

next, and correspondingly small increases in LL(βt ), as evidence that
convergence has been achieved. However, as stated above, the iterative
procedures may produce small steps because the likelihood function is
not close to a quadratic rather than because of nearing the maximum.
Small changes in βt and LL(βt ) accompanied by a gradient vector that
is not close to zero indicates that the numerical routine is not eﬀective
at ﬁnding the maximum.
Convergence is sometimes assessed on the basis of the gradient
vector itself rather than through the test statistic mt . There are two
procedures: (1) determine whether each element of the gradient vector
is smaller in magnitude than some value that the researcher speciﬁes,
and (2) divide each element of the gradient vector by the corresponding
element of β and determine whether each of these quotients is smaller
in magnitude than some value speciﬁed by the researcher. The second approach normalizes for the units of the parameters, which are
determined by the units of the variables that enter the model.

8.5

Local versus global maximum

All of the methods that we have discussed are susceptible to converging
at a local maximum that is not the global maximum, as shown in Figure
8.8. When the log-likelihood function is globally concave, as for logit
with linear-in-parameters utility, then there is only one maximum and
the issue doesn’t arise. However, most discrete choice models are not
globally concave.
A way to investigate the issue is to use a variety of starting values
and observe whether convergence occurs at the same parameter values.
For example, in Figure 8.8, starting at β0 will lead to convergence
at β1 . Unless other starting values were tried, the researcher would
mistakenly believe that the maximum of LL(β) had been achieved.
Starting at β2 , convergence is achieved at β̂. By comparing the LL(β̂)
with LL(β1 ), the researcher ﬁnds that β1 is not the maximizing value.
Liu and Mahmassani (2000) propose a way to select starting values
that involves the researcher setting upper and lower bounds on each
parameter and randomly choosing values within those bounds.

CHAPTER 8. NUMERICAL MAXIMIZATION

228

β0

β1

β
^

β2
β

LL(β)

Figure 8.8: Local versus global maximum

8.6

Variance of the Estimates

In standard econometric courses, it is shown that, for a correctly speciﬁed model,
√
d
N (β̂ − β ∗ ) → N(0, (−H)−1 )
as N → ∞, where β ∗ is the true parameter vector, β̂ is the maximum
likelihood estimator, and H is the expected Hessian in the population.
The negative of the expected Hessian, −H, is often called the information matrix. Stated in words: the sampling distribution of the diﬀerence between the estimator and the true value, normalized for sample
size, converges asymptotically to a normal distribution centered on
zero and with covariance equal to the inverse of√the information matrix, −H−1 . Since the asymptotic covariance of N (β̂ − β ∗ ) is −H−1 ,
the asymptotic covariance of β̂ itself is −H−1 /N .
The bold-face type in these expressions indicates that H is the average in the population, as opposed to H which is the average Hessian
in the sample. The researcher calculates the asymptotic covariance by
using H as an estimate of H. That is, the asymptotic covariance of β̂
is calculated as −H −1 /N where H is evaluated at β̂.
Recall that W is the covariance of the scores in the sample. At the
maximizing values of β, B is also the covariance of the scores. By the
information identity discussed above and explained in the last section,
−H, which is the (negative of the) average Hessian in the sample,

8.7. INFORMATION IDENTITY

229

converges to the covariance of the scores for a correctly speciﬁed model
at the true parameters. In calculating the asymptotic covariance of the
estimates β̂, any of these three matrices can be used as an estimate of
−H. The asymptotic variance of β̂ is calculated as W −1 /N , B −1 /N ,
or −H −1 /N , where each of these matrices is evaluated at β̂.
If the model is not correctly speciﬁed, then the asymptotic covariance of β̂ is more complicated. In particular, for any model for which
the expected score is zero at the true parameters,
√
d
N (β̂ − β ∗ ) → N(0, H−1 VH−1 )
where V is the variance of the scores in the population. When the
model is correctly speciﬁed, the matrix −H = V by the information
identity, such that H−1 VH−1 = −H−1 and we get the formula for
a correctly speciﬁed model. However, if the model is not correctly
speciﬁed, this simpliﬁcation does not occur. The asymptotic distribution of β̂ is H−1 VH−1 /N . This matrix is called the ”robust covariance
matrix” since it is valid whether or not the model is correctly speciﬁed.
To estimate the robust covariance matrix, the researcher must calculate the Hessian H. If a procedure other than N-R is being used to
reach convergence, the Hessian need not be calculated at each iteration; however, it must be calculated at the ﬁnal iteration. Then the
asymptotic covariance is calculated as H −1 W H −1 , or with B instead
of W . This formula is sometimes called the “sandwich” estimator of
the covariance, since the Hessian-inverse appears on both sides.

8.7

Information Identity

The information identity states that, for a correctly speciﬁed model at
the true parameters, V = −H where V is the covariance of the scores
in the population and H is the average Hessian in the population. The
score for a person is the vector of ﬁrst derivatives of the the person’s
lnP (β) with respect to the parameters, and the Hessian is the matrix of second derivatives. The information identity states that, in the
population, the covariance of the ﬁrst derivatives equals the average
second derivatives (actually, the negative of these second derivatives.)
This is a startling fact, not something that would be expected or even
believed if there were not proof. It has implications throughout econometrics. The implications that we have used in the previous sections
of this chapter are easily derivable from the identity. In particular:

230

CHAPTER 8. NUMERICAL MAXIMIZATION

(1) At the maximizing value of β, W → −H as N → ∞, where W
is the sample covariance of the scores and H is the sample average of
each observation’s Hessian. As sample size rises, the sample covariance
approaches the population covariance: W → V. Similarly, the sample
average of the Hessian approaches the population average: H → H.
Since V = −H by the information identity, W approaches the same
matrix that −H approaches, and so they approach each other.
(2) At the maximizing value of β, B → −H as N → ∞, where
B is the sample average of the outer product of the scores. At β̂, the
average score in the sample is zero, such that B is the same as W . The
result for W applies for B.
We now demonstrate the information identity. We need to expand our notation to account for the population instead of simply the
sample. Let Pi (x, β) be the probability that a person who faces explanatory variables x chooses alternative i given the parameters β.
Of the people in the population who face variables x, the share who
choose alternative i is this probability calculated at the true parameters: Si (x) = Pi (x, β ∗ ) where β ∗ are the true parameters. Consider
now the gradient of lnPi (x, β) with respect to β. The average gradient
in the population is


g=
i

∂lnPi (x, β)
Si (x)f (x)dx
∂β

(8.2)

where f (x) is the density of explanatory variables in the population.
This expression can be explained as follows. The gradient for people
who face x and choose i is ∂lnP∂βni (β) . The average gradient is the
average of this term over all values of x and all alternatives i. The
share of people who face a given value of x is given by f (x), and the
share of people who face this x that choose i is Si (x). So, Si (x)f (x)
is the share of the population who face x and choose i and therefore
i (x,β)
. Summing this term over all values of i and
have gradient ∂lnP∂β
integrating over all values of x (assuming the x’s are continuous) gives
the average gradient, as expressed in (8.2).
The average gradient in the population is equal to zero at the true
parameters. This fact can be considered either the deﬁnition of the
true parameters or the result of a correctly speciﬁed model. Also, we
know that Si (x) = Pi (x, β ∗ ). Substituting these facts into (8.2), we

8.7. INFORMATION IDENTITY
have:



0=
i

231

∂lnPi (x, β)
Pi (x, β)f (x)dx,
∂β

where all terms are evaluated at β ∗ . We now take the derivative of
this equation with respect to the parameters:




0=
i



∂lnPi (x, β) ∂Pi (x, β)
∂ 2 lnPi (x, β)
Pi (x, β) +
f (x)dx.

∂β∂β
∂β
∂β 

Since ∂lnP/∂β = (1/P )∂P/∂β by the rules of derivatives, we can
i (x,β)
i (x,β)
substitute ∂ lnP∂β
Pi (x, β) for ∂P∂β
in the last term in parentheses:






0=
i



∂ 2 lnPi (x, β)
∂lnPi (x, β) ∂lnPi (x, β)
Pi (x, β) +
Pi (x, β) f (x)dx.

∂β∂β
∂β
∂β 

Rearranging,
−


i

∂ 2 lnPi (x, β)
Pi (x, β)f (x)dx =
∂β∂β 


i

∂lnPi (x, β) ∂lnPi (x, β)
Pi (x, β)f (x)dx.
∂β
∂β 

Since all terms are evaluated at the true parameters, we can replace
Pi (x, β) with Si (x) to obtain:
−


i

∂ 2 lnPi (x, β)
Si (x)f (x)dx =
∂β∂β 


i

∂lnPi (x, β) ∂lnPi (x, β)
Si (x)f (x)dx.
∂β
∂β 

The left hand side is the negative of the average Hessian in the population, −H. The right hand side is the average outer product of the
gradient, which is the covariance of the gradient since the average gradient is zero: V. Therefore, −H = V, the information identity. As
stated above, the matrix −H is often called the information matrix.

232

CHAPTER 8. NUMERICAL MAXIMIZATION

Chapter 9

Drawing from Densities
9.1

Introduction

Simulation consists of drawing from a density, calculating a statistic
for each draw, and averaging the results. In all
cases, the researcher

wants to calculate an average of the form t̄ = t(ε)f (ε) dε, where t(·)
is a statistic of interest and f (·) is a density. To approximate this
average through simulation, the researcher must be able to take draws
from the density f (·). For some densities, this task is simple. However,
in many situations, it is not immediately clear how to draw from the
relevant density. Furthermore, even with simple densities, there might
be ways of taking draws that provide a better approximation to the
integral than a sequence of purely random draws.
We explore these issues in this chapter. In the ﬁrst sections, we
describe the most prominent methods that have been developed for
taking purely random draws from various kinds of densities. These
methods are presented in a progressive sequence, starting with simple procedures that work with a few convenient densities and moving
to ever more complex methods that work with less convenient densities. The discussion culminates with the Metropolis-Hastings algorithm, which can be used with (practically) any density. The chapter
then turns to the question of whether and how a sequence of draws can
be taken that provides a better approximation to the relevant integral
than a purely random sequence. We discuss antithetics, systematic
sampling, and Halton sequences and show the value that these types
of draws provide in estimation of model parameters.
233

234

CHAPTER 9. DRAWING FROM DENSITIES

9.2

Random Draws

9.2.1

Standard normal and uniform

If the researcher wants to take a draw from a standard normal density
(that is, a normal with zero mean and unit variance) or a standard
uniform density (uniform between 0 and 1), the process from a programming perspective is very easy. Most statistical packages contain
random number generators for these densities. The researcher simply
calls these routines to obtain a sequence of random draws. In the sections below, we refer to a draw of a standard normal as η and a draw
of a standard uniform as µ.
The draws from these routines are actually called “pseudo-random
numbers” because nothing that a computer does is truly random.
There are many issues involved in the design of these routines. The
intent in their design is to produce numbers that exhibit the properties
of random draws. The extent to which this intent is realized depends,
of course, on how one deﬁnes the properties of “random” draws. These
properties are diﬃcult to deﬁne precisely since randomness is a theoretical concept that has no operational counterpart in the real world.
From a practical perspective, my advice is the following: unless one
is willing to spend considerable time investigating and resolving (literally, re-solving) these issues, it is probably better to use the available
routines rather than write a new one.

9.2.2

Transformations of standard normal

Some random variables are transformations of a standard normal. For
example, a draw from a normal density with mean b and variance
s2 is obtained as ε = b + sη. A draw from a lognormal density is
obtained by exponentiating a draw from a normal density: ε = e(b+sη) .
The moments of the lognormal are functions of the mean and variance
of the normal that is exponentiated. In particular, the mean of ε is
exp(b + (s2 /2)) and its variance is exp(2b + s2 ) · (exp(s2 ) − 1). Given
values for the mean and variance of the lognormal, the appropriate
values of b and s to use in the transformation can be calculated. It
is more common, however, to treat b and s as the parameters of the
lognormal and calculate its mean and variance from these parameters.

9.2. RANDOM DRAWS

9.2.3

235

Inverse cumulative for univariate densities

Consider a random variable with density f (ε) and corresponding cumulative distribution F (ε). If F is invertible (that is, if F −1 can be
calculated), then draws of ε can be obtained from draws of a standard
uniform. By deﬁnition, F (ε) = k means that the probability of obtaining a draw equal to or below ε is k, where k is between zero and
one. A draw µ from the standard uniform provides a number between
zero and one. We can set F (ε) = µ and solve for the corresponding ε:
ε = F −1 (µ). When ε is drawn in this way, the cumulative distribution
of the draws is equal to F , such that the draws are equivalent to draws
directly from F . An illustration is provided in Figure 9.1. A draw µ1
from a standard uniform translates into the value of ε labeled ε1 , at
which F (ε1 ) = µ1 .

F (ε)
1

µ1
ε1

ε

f (ε)

Area = µ1

ε
Figure 9.1: Draw of µ1 from uniform and create ε1 = F −1 (µ).
The extreme value distribution, which is the basis for multinomial
logit models, provides an example. The density is f (ε) = exp(−ε) ·

236

CHAPTER 9. DRAWING FROM DENSITIES

exp(−exp(−ε)) with cumulative distribution F (ε) = exp(−exp(−ε)).
A draw from this density is obtained as ε = − ln(− ln(µ)).
Note that this procedure works only for univariate distributions. If
there are two or more elements of ε, then F −1 (µ) is not unique, since
various combinations of the elements of ε have the same cumulative
probability.

9.2.4

Truncated univariate densities

Consider a random variable that ranges from a to b with density proportional to f (ε) within this range. That is, the denisty is (1/k)f (ε) for a ≤
ε ≤ b, and 0 otherwise, where k is the normalizing
constant that inb
sures that the density integrates to 1: k = a g(ε) dε = F (b) − F (a).
A draw from this density can be obtained by applying the procedure
in section 9.2.3 while assuring that the draw is within the appropriate
range.
Draw µ from a standard uniform density. Calculate the weighted
average of F (a) and F (b) as µ̄ = (1 − µ)F (a) + µF (b). Then calculate
ε = F −1 (µ̄). Since µ̄ is between F (a) and F (b), ε is necessarily between
a and b. Essentially, the draw of µ determines how far to go between
a and b. Note that the normalizing constant k is not used in the
calculations and therefore need not be calculated. Figure 9.2 illustrates
the process.

9.2.5

Choleski transformation for multivariate normals

As described in section 9.2.2, a univariate normal with mean b and
variance s2 is obtained as ε = b + sµ where µ is standard normal. An
analogous procedure can be used to draw from a multivariate normal.
Let ε be a vector with K elements distributed N (b, Ω). A Choleski factor of Ω is deﬁned as a lower-triangular matrix L such that LL = Ω. It
is often called the generalized square root of Ω or generalized standard
deviation of ε. With K = 1 and variance s2 , the Choleski factor is s,
which is just the standard deviation of ε. Most statistical and matrix
manipulation packages have routines to calculate a Choleski factor for
any positive deﬁnite, symmetric matrix.
A draw of ε from N (b, Ω) is obtained as follows. Take K draws
from a standard normal, and label the vector of these draws η =
η1 , . . . , ηK  . Calculate ε = b + Lη. We can verify the properties
of ε. It is normally distributed since the sum of normals is normal.

9.2. RANDOM DRAWS

237

F (ε)

F (b)
µ1
F (a)
ε
f (ε)

a

ε1

b

ε

Figure 9.2: Draw of µ̄1 between F (a) and F (b) gives draw ε1 from f (ε)
between a and b.

CHAPTER 9. DRAWING FROM DENSITIES

238

Its mean is b: E(ε) = b + LE(η) = b. And its covariance is Ω:
Var(ε) = E(Lη(ηL) ) = LE(ηη  )L = LVar(η)L = LIL = LL = Ω.
To be concrete, consider a three dimensional ε with zero mean. A
draw of ε is calculated as










ε1
s11 0
0
η1

 


 ε2  =  s21 s22 0   η2 
ε3
η3
s31 s32 s33
or
ε1 = s11 η1
ε2 = s21 η1 + s22 η2
ε3 = s31 η1 + s32 η2 + s33 η3 .
From this we see that Var(ε1 ) = s211 , Var(ε2 ) = s221 + s222 , and
Var(ε3 ) = s231 + s232 + s233 . Also, Cov(ε1 , ε2 ) = s11 s21 , and so on.
The elements ε1 and ε2 are correlated because of the common inﬂuence of η1 on both of them. They are not perfectly correlated because
η2 enters ε2 without aﬀecting ε1 . Similar analysis applies to ε1 and
ε3 , and ε2 and ε3 . Essentially, the Choleski factor expresses K correlated terms as arising from K independent components, with each
component “loading” diﬀerently onto each term. For any pattern of
covariance, there is some set of loadings from independent components
that reproduces that covariance.

9.2.6

Accept-reject for truncated multivariate densities

The procedure in section 9.2.4 for drawing from truncated densities
applies only to univariate distributions. With multivariate densities,
drawing from a truncated support is more diﬃcult. We describe an
accept-reject procedure that can always be applied. However, as we
will see, there are disadvantages of the approach that might cause a
researcher to choose another approach when possible.
Suppose we want to draw from multivariate density g(ε) within the
range a ≤ ε ≤ b where a and b are vectors with the same length as
ε. That is, we want to draw from f (ε) = k1 g(ε) if a ≤ ε ≤ b, and =
0 otherwise , where k is the normalizing constant. We can obtain draws
from f by simply drawing from g and retaining (“accepting”) the draws
that are within the relevant range and discarding (“rejecting”) the
draws that are outside the range. The advantage of this procedure
is that it can be applied whenever it is possible to draw from the

9.2. RANDOM DRAWS

239

untruncated density. Importantly, the normalizing constant, k, does
not need to be known for the truncated density. This fact is useful
since the normalizing constant is usually diﬃcult to calculate.
The disadvantage of the procedure is that the number of draws that
are accepted (that is, the number of draws from f that are obtained)
is not ﬁxed but rather is itself random. If R draws are taken from g,
then the expected number of accepts is kR. This expected number is
not known without knowing k, which, as stated, is usually diﬃcult to
calculate. It is therefore hard to determine an appropriate number of
draws to take from g. More importantly, the actual number of accepted
draws will generally diﬀer from the expected number. In fact, there is
a positive probability of obtaining no accepts from a ﬁxed number of
draws. When the truncation space is small (or, more precisely, when k
is small), obtaining no accepts, and hence no draws from the truncated
density, is a likely event.
This diﬃculty can be circumvented by drawing from g until a certain number of accepted draws is obtained. That is, instead of setting
in advance the number of draws from g that will be taken, the researcher can set the number of draws from f that are obtained. Of
course, the researcher will not know how long it will take to attain the
set number.
In most situations, other procedures can be applied more easily
to draw from a multivariate truncated density. Nevertheless, it is important to remember that, when nothing else seems possible with a
truncated distribution, the accept-reject procedure can be applied.

9.2.7

Importance sampling

Suppose ε has a density f (ε) that cannot be easily drawn from by the
other procedures. Suppose further that there is another density, g(ε),
that can easily be drawn from. Draws from f (ε) can be obtained as
follows. Take a draw from g(ε) and label it ε1 . Weight the draw by
f (ε1 )/g(ε1 ). Repeat this process many times. The set of weighted
draws is equivalent to a set of draws from f .
To verify this fact, we show that the cumulative distribution of the
weighted draws from g is the same as the cumulative distribution of
draws from f . Consider the share of draws from g that are below some

CHAPTER 9. DRAWING FROM DENSITIES

240

value m, with each draw weighted by f /g. This share is:
 



f (ε)
I(ε < m)g(ε) dε =
g(ε)
 m

=

−∞

 m 
−∞



f (ε)
g(ε) dε
g(ε)

f (ε) dε = F (m) .

In simulation, draws from a density are used to calculate the average of a statistic over that density. Importance sampling can be seen
as a change in the statistic and a corresponding change in the density
that makes the density easy to draw from. Suppose we want to calculate t(ε)f (ε) dε, but ﬁnd it hard to draw from f . We can multiply
the integrand
by g ÷ g without changing its value, such that the inte
(ε)
gral is t(ε) fg(ε)
g(ε) dε. To simulate the integral, we take draws from
g, calculate t(ε)[f (ε)/g(ε)] for each draw, and average the results. We
have simply transformed the integral so that it is easier to simulate.
The density f is called the target density, and g is called the proposal density. The requirements for importance sampling are that (1)
the support of g(ε) needs to cover the support of f , so that any ε that
could arise with f can also arise with g, and (2) the ratio f (ε)/g(ε)
must be ﬁnite for all values of ε, so that this ratio can always be calculated.
A useful illustration of importance sampling arises with multivariate truncated normals. Suppose we want to draw from N (0, Ω) but
with each element being positive (i.e., truncated below at zero.) The
density is
1
(− 12 ε Ω−1 ε)
f (ε) =
1
1 e
k(2π) 2 K |Ω| 2
for ε ≥ 0 and 0 otherwise, where K is the dimension of ε and k is the
normalizing constant. (We assume for the purposes of this example
that k is known. In reality, calculating k might take simulation in
itself.) Drawing from this density is diﬃcult because the elements of ε
are correlated as well as truncated. However, we can use the procedure
in section 9.2.4 to draw independent truncated normals and then apply
importance sampling to create the correlation. Draw K univariate
normals truncated below at zero, using the procedure in section 9.2.4.
These draws collectively constitute a draw of a K-dimensional vector
ε from the positive quadrant support with density
g(ε) =

1
m(2π)

1 

1
K
2

e(− 2 ε ε)

9.2. RANDOM DRAWS

241

where m = 1/2K . For each draw, assign the weight
1
f (ε)
m

−1
= |Ω|(− 2 ) eε (Ω −I)ε) .
g(ε)
k

The weighted draws are equivalent to draws from N (0, Ω) truncated
below at zero.
As a sidelight, note that the accept-reject procedure in section 9.2.6
is a type of importance sampling. The truncated distribution is the
target and the untruncated distribution is the proposal density. Each
draw from the untruncated density is weighted by a constant if the
draw is within the truncation space and weighted by zero if the draw
is outside the truncation space. Weighting by a constant or zero is
equivalent to weighting by one (accept) or zero (reject).

9.2.8

Gibbs sampling

For multinomial distributions, it is sometimes diﬃcult to draw directly
from the joint density and yet easy to draw from the conditional density
of each element given the values of the other elements. Gibbs sampling,
a term that was apparently introduced by Geman and Geman (1984),
can be used in these situations. A general explanation is provided by
Casella and George (1992), which the reader can use, if interested, to
supplement the more concise description that I give below.
Consider two random variables ε1 and ε2 . Generalization to higher
dimension is obvious. The joint density is f (ε1 , ε2 ) and the conditional
densities are f (ε1 |ε2 ) and f (ε2 |ε1 ). Gibbs sampling proceeds by drawing iteratively from the conditional densities: drawing ε1 conditional
on a value of ε2 , drawing ε2 conditional on this draw of ε1 , drawing
a new ε1 conditional on the new value of ε2 , and so on. This process
converges to draws from the joint density.
To be more precise: (1) Choose an initial value for ε1 , called ε01 .
Any value with non-zero density can be chosen. (2) Draw a value
of ε2 , called ε02 , from f (ε2 |ε01 ). (3) Draw a value of ε1 , called ε11 , from
f (ε1 |ε02 ). (4) Draw ε12 , from f (ε2 |ε11 ). And so on. The values of εt1 , from
t−1
t
f (ε1 |εt−1
2 ) and the values of ε2 , from f (ε2 |ε1 ) constitute a sequence
in t. For suﬃciently high t (that is, for suﬃciently many iterations),
the sequence converges to draws from the joint density f (ε1 , ε2 ).
As an example, consider two standard normal deviates that are
independent except that they are truncated on the basis of their sum:

242

CHAPTER 9. DRAWING FROM DENSITIES

ε2

m
m

ε1

Figure 9.3: Truncated normal density.
ε1 + ε2 ≤ m. Figure 9.3 depicts the truncated density. The circles
denote contours of the untruncated density and the shaded area represents the truncated density. To derive the conditional densities, consider ﬁrst the untruncated normals. Since the two deviates are independent, the conditional density of each is the same as its unconditional
density. That is, ignoring truncation, ε1 |ε2 ∼ N (0, 1). The truncation
rule is ε1 + ε2 ≤ m which can be re-expressed as ε1 ≤ m − ε2 . Therefore, ε1 |ε2 is distributed as a univariate standard normal truncated
from above at m − ε2 . Given ε2 , a draw of ε1 is obtained with the procedure in section 9.2.4: ε1 = Φ−1 (µΦ(m − ε2 )), where µ is a standard
uniform draw and Φ(·) is the cumulative standard normal distribution.
Draws from ε2 conditional on ε1 are obtained analogously. Drawing
sequentially from these conditional densities eventually provides draws
from the joint truncated density.

9.2.9

Metropolis-Hastings algorithm

If all else fails, the Metropolis-Hastings (M-H) algorithm can be used
to obtain draws from a density. Initially developed by Metropolis et
al. (1953) and generalized by Hastings (1970), the M-H algorithm
operates as follows. The goal is to obtain draws from f (ε). (1) Start
with a value of the vector ε, labeled ε0 . (2) Choose a “trial” value of ε1
as ε̃1 = ε0 + η where η is drawn from a distribution g(η) that has zero
mean. Usually a normal distribution is speciﬁed for g(η). (3) Calculate
the density at the trial value ε̃1 and compare it to the density at the

9.2. RANDOM DRAWS

243

original value ε0 . That is, compare f (ε̃1 ) with f (ε0 ). If f (ε̃1 ) > f (ε0 ),
then accept ε̃1 , label it ε1 , and move to step 4. If f (ε̃1 ) ≤ f (ε0 ),
1)
then accept ε̃1 with probability ff (ε̃
, and reject it with probability
(ε0 )
1

)
. To determine whether to accept or reject ε̃1 in this case,
1 − ff (ε̃
(ε0 )
1

)
, then keep ε̃1 . Otherwise,
draw a standard uniform µ. If µ ≤ ff (ε̃
(ε0 )
reject ε̃1 . If ε̃1 is accepted, then label it ε1 . If ε̃1 is rejected, then
use ε0 as ε1 . (4) Choose a trial value of ε2 as ε̃2 = ε1 + η, where η is
a new draw from g(η). (5) Apply the rule in step 3 to either accept
ε̃2 as ε2 or reject ε̃2 and use ε1 as ε2 . (6) Continue this process for
many iterations. The sequence εt becomes equivalent to draws from
f (ε) for suﬃciently large t. The draws are serially correlated, since
each draw depends on the previous draw. In fact, when a trial value is
rejected the current draw is the same as the previous draw. This serial
correlation needs to be considered when using these draws.
The M-H algorithm can be applied with any density that can be
calculated. The algorithm is particularly useful when the normalizing
constant for a density is not known or cannot be easily calculated.
Suppose that we know that ε is distributed proportional to f ∗ (ε). This
means that the density of ε is f (ε) = k1 f ∗ (ε), where the normalizing
constant k = f ∗ (ε) dε assures that f integrates to 1. Usually k
cannot be calculated analytically, for the same reason that we need to
simulate integrals in other settings. Luckily, the M-H algorithm does
not utilize k. A trial value of εt is tested by ﬁrst determining whether
f (ε̃t ) > f (εt−1 ). This comparison is unaﬀected by the normalizing
constant, since the constant enters the denominator on both sides.
Then, if f (ε̃t ) ≤ f (εt−1 ), we accept the trial value with probability
f (ε̃t )
. The normalizing constant drops out of this ratio.
f (εt−1 )
The M-H algorithm is actually more general than I describe here,
though in practice it is usually applied as I describe. Chib and Greenberg (1995) provide an excellent description of the more general algorithm as well as an explanation of why it works. Under the more
general deﬁnition, Gibbs sampling is a special case of the M-H algorithm, as Gelman (1992) pointed out. The M-H algorithm and Gibbs
sampling are often called Markov Chain Monte Carlo (MCMC, or MCsquared) methods; a description of their use in econometrics is provided
by Chib and Greenberg (1996). The draws are Markov chains because
each value depends only on the immediately preceding one, and the
methods are Monte Carlo because random draws are taken. We ex-

244

CHAPTER 9. DRAWING FROM DENSITIES

plore further issues about the M-H algorithm, such as how to choose
g(ε), in the context of its use with hierarchical Bayes procedures (in
chapter 12).

9.3

Variance Reduction

The use of independent random draws in simulation is appealing because it is conceptually straightforward and the statistical properties
of the resulting simulator are easy to derive. However, there are other
ways to take draws that can provide greater accuracy for a given number of draws. We examine these alternative methods in the following
sections.
Recall that the objective is to approximate an integral of the form

t(ε)f (ε)dε. In taking a sequence of draws from the density f (· · ·),
two issues are at stake: coverage and covariance. Consider coverage
ﬁrst. The integral is over the entire density f . It seems reasonable that
a more accurate approximation would be obtained by evaluating t(ε)
at values of ε that are spread throughout the domain of f . With independent random draws, it is possible that the draws will be clumped
together, with no draws from large areas of the domain. Procedures
that guarantee better coverage can be expected to provide a better
approximation.
Covariance is another issue. With independent draws, the covariance over draws is zero. The variance of a simulator based on R independent draws is therefore the variance based on 1 draw divided by
R. If the draws are negatively correlated instead of independent, then
the variance of the simulator is lower. Consider R = 2. The variance
of ť = [t(ε1 ) + t(ε2 )]/2 is [V (t(ε1 ) + V (t(ε2 ) + 2Cov(t(ε1 ), t(ε2 ))]/4. If
the draws are independent, then the variance is V (t(εr ))/2. If the two
draws are negatively correlated with each other, the covariance term
is negative and the variance becomes less than V (t(εr ))/2. Essentially,
when the draws are negatively correlated within an unbiased simulator, a value above t̄ = Er (t(ε)) for one draw will tend to be associated
with a value for the next draw that is below Er (t(ε)), such that their
average is closer to the true value t̄.
The same concept arises when simulators are summed over observations. For example, the simulated log-likelihood function is a sum
over observations of the log of simulated probabilities. If the draws
for each observation’s simulation are independent of the draws for the

9.3. VARIANCE REDUCTION

245

other observations, then the variance of the sum is simply the sum of
the variances. If the draws are taken in a way that creates negative
correlation over observations, then the variance of the sum is lower.
For a given observation, the issue of covariance is related to coverage. By inducing a negative correlation between draws, better coverage
is usually assured. With R = 2, if the two draws are taken independently, then both could end up being at the low side of the distribution.
If negative correlation is induced, then the second draw will tend to
be high if the ﬁrst draw is low, which provides better coverage.
We describe below methods to attain better coverage for each observation’s integral and to induce negative correlation over the draws
for each observation as well as over observations. We assume for the
sake of discussion that the integral is a choice probability and that the
sum over observations is the simulated log-likelihood function. However, the concepts apply to other integrals, such as scores, and to other
sums, such as moment conditions and market shares. Also, unless otherwise noted, we illustrate the methods with only two random terms
so that the draws can be depicted graphically. The random terms are
labeled εa and εb , and collectively as ε = εa , εb  . A draw of ε from its
density f (ε) is denoted εr = εar , εbr  for r = 1, . . . , R. Thus, εa3 , e.g.,
is the third draw of the ﬁrst random term.

9.3.1

Antithetics

Antithetic draws, suggested by Hammersley and Morton (1956), are
obtained by creating various types of mirror images of a random draw.
For a symmetric density that is centered on zero, the simplest antithetic
variate is created by reversing the sign of all elements of a draw. Figure
9.4 illustrates. Suppose a random draw is taken from f (ε) and the
value ε1 = εa1 , εb1  is obtained. The second “draw”, which is called
the antithetic of the ﬁrst draw, is created as ε2 = −εa1 , −εb1  . Each
draw from f creates a pair of “draws”, the original draw and its mirror
image (mirrored through the origin). To obtain a total of R draws, R/2
draws are taken independently from f and the other R/2 are created
as the negative of the original draws.
When the density is not centered on zero, the same concept is
applied but through a diﬀerent process. For example, the standard
uniform density is between 0 and 1, centered on 0.5. A draw is taken,
labeled µ1 , and its antithetic variate is created as µ2 = 1 − µ1 . The

246

CHAPTER 9. DRAWING FROM DENSITIES

εb

ε1

εa

ε2

Figure 9.4: Reverse sign of both elements.
variate is the same distance from 0.5 as the original draw, but on the
other side of 0.5. In general, for any univariate density with cumulative
function F (ε), the antithetic of a draw ε is created as F −1 (1−F (ε)). In
the case of a symmetric density centered on zero, this general formula
is equivalent to simply reversing the sign. In the remaining discussion
we assume that the density is symmetric and centered on zero, which
makes the concepts easier to express and visualize.
The correlation between a draw and its antithetic variate is exactly -1, such that the variance of their sum is zero: V (ε1 + ε2 ) =
V (ε1 ) + V (ε2 ) + 2Cov(ε1 , ε2 ) = 0. This fact does not mean that there
is no variance in the simulated probability that is based on these draws.
The simulated probability is a non-linear function of the random terms,
and so the correlation between P (ε1 ) and P (ε2 ) is less than one. The
variance of the simulated probability P̌ = (1/2)[P (ε1 ) + P (ε2 )] is
greater than zero. However, the variance of the simulated probabilities
is less than (1/2)Vr (P (εr )), which is the variance with two independent
draws.
As shown in Figure 9.4, reversing the sign of a draw gives evaluation
points in opposite quadrants. The concept can be extended to obtain
draws in each quadrant. A draw is taken and then antithetic draws are
created by reversing the sign of each element alone (leaving the sign
of the other elements unchanged), reversing the sign of each pair of
elements, each triplet of elements, and so on. For ε with two elements,
this process creates three antithetic draws for each independent draw.

9.3. VARIANCE REDUCTION

247

For ε1 = εa1 , εb1  , the antithetic draws are
ε2 = −εa1 , εb1 
ε3 =  εa1 , −εb1 

ε4 = −εa1 , −εb1  .
These draws are shown in Figure 9.5. Each quadrant contains a draw.

ε2

εb

ε1

εa

ε4

ε3

Figure 9.5: Reverse sign of each element then both.
Better coverage and higher negative correlation can be obtained by
shifting the position of each element as well as reversing their signs. In
Figure 9.5, ε1 and ε2 are fairly close together, as are ε3 and ε4 . This
placement leaves large uncovered areas between ε1 and ε3 and between
ε2 and ε4 . Orthogonal draws with even placement can be obtained
by switching element εa1 with εb1 while also reversing the signs. The
antithetic draws are
ε2 = −εb1 , εa1 
ε3 =  εb1 , −εa1 

ε4 = −εa1 , −εb1  ,
which are illustrated in Figure 9.6. These concepts can, of course, be
extended to any number of dimensions. For M -dimensional ε, each
random draw creates 2M antithetic draws (including the original one),
with one in each quadrant.

248

CHAPTER 9. DRAWING FROM DENSITIES

εb

ε1

ε2
εa
ε3
ε4

Figure 9.6: Switch positions and reverse signs.
Comparisons performed by Vijverberg (1997) and Sándor and András
(2001) show that antithetics substantially improve the estimation of
probit models. Similarly, Geweke (1988) has shown their value when
calculating statistics based on Bayesian posteriors.

9.3.2

Systematic sampling

Coverage can also be improved through systematic sampling (McGrath,
1970), which creates a grid of points over the support of the density
and randomly shifts the entire grid. Consider draws from a uniform
distribution between 0 and 1. If four draws are taken independently,
the points could look like those in the top part of Figure 9.7, which
provide fairly poor coverage. Instead the unit interval is divided into
four segments and draws taken in a way that assures one draw in each
segment with equal distance between the draws. Take a draw from a
uniform between 0 and .25 (by drawing from a standard uniform and
dividing the result by 4.) Label the draw ε1 . Three other draws are
created as
ε2 = .25 + ε1
ε3 = .50 + ε1
ε4 = .75 + ε1
These draws look like those in the bottom part of Figure 9.7, which
provide better coverage than independent draws.

9.3. VARIANCE REDUCTION

0

0

249

Random draws

1/ 4

1/ 2

3/ 4

1

1

Systematic draws

Figure 9.7: Draws from standard uniform.
The issue arises of how ﬁnely to segment the interval. For example,
to obtain a total of 100 draws, the unit interval can be divided into 100
segments. A draw between 0 and 0.01 is taken and then the other 99
draws are created from this one draw. Instead, the unit interval can be
divided into fewer than 100 draws and more independent draws taken.
If the interval is divided into four segments, then 25 independent draws
are taken between 0 and 0.25, and three draws in the other segments
are created for each of the independent draws. There is a tradeoﬀ
that the researcher must consider in deciding how ﬁne a grid to use in
systematic sampling. More segments provide more even coverage for a
given total number of draws. However, fewer segments provide more
randomness to the process. In our example with R = 100, there is only
one random draw when 100 segments are used, whereas there are 25
random draws when four segments are used.
The randomness of simulation draws is a necessary component in
the derivation of the asymptotic properties of the simulation-based
estimators, as described in Chapter 10. Many of the asymptotic properties rely on the concept that the number of random draws increases
without bound with sample size. The asymptotic distributions become
relatively accurate only when enough random draws have been taken.
Therefore, for a given total number of draws, the goal of better coverage, which is attained with a more ﬁnely deﬁned segmentation, needs
to be traded-oﬀ against the goal of having enough randomness for the
asymptotic formulas to apply, which is attained with a more coarsely
deﬁned segmentation. The same issue applies to the antithetics discussed above.
Systematic sampling can be performed in multiple dimensions. Consider a two-dimensional uniform on the unit square. A net is created

250

CHAPTER 9. DRAWING FROM DENSITIES

by dividing each dimension into segments. As shown in Figure 9.8,
when each dimension is divided into four segments, the unit square is
partitioned into 16 areas. A draw between 0 and .25 is taken for each
element, giving ε1 = εa1 , εb1  , where 0 < εa1 < 0.25 and 0 < εb1 < 0.25.
This draw falls somewhere in the bottom-left area in Figure 9.8. Fifteen other draws are then created as the “origin” of each area plus
εa1 , εb1  . For example, the point that is created for the bottom-right
area is ε4 = (0.75 + εa1 ), (0 + εb1 ) .

ε13

ε14

ε15

ε16

3/4

ε9

ε10

ε11

ε12

1/2

ε5

ε6

ε7

ε8

1/4

ε1

ε2

ε3

ε4

1/ 4

1/ 2

3/ 4

Figure 9.8: Systematic draws in two dimensions.
These draws are deﬁned for a uniform distribution. When f represents another density, the points are transformed using the method
described in section (9.2.3). In particular, let F be the cumulative distribution associated with univariate density f . Systematic draws from
f are created by transforming each systematic draw from a uniform
by F −1 . For example, for a standard normal, four equal-sized segments of the density are created with breakpoints: Φ−1 (0.25) = −.67,
Φ−1 (0.5) = 0, and Φ−1 (0.75) = .67. As shown in Figure 9.9, these segments are equal-sized in the sense that each contains the same mass.
The draws for the standard normal are created by taking a draw from
a uniform between 0 and 0.25, labeled µ1 . The corresponding point
on the normal is ε1 = Φ−1 (µ1 ), which falls in the ﬁrst segment. The
points for the other three segments are created as: ε2 = Φ−1 (0.25+µ1 ),
ε3 = Φ−1 (0.5 + µ1 ), and ε4 = Φ−1 (0.75 + µ1 ).
Draws of multi-dimensional random terms are obtained similarly,

9.3. VARIANCE REDUCTION

ε1 _

0.67

251

ε2

0

ε3

0.67

ε4

Figure 9.9: Systematic draws for univariate normal.
provided that the elements are independent. For example, if ε consists
of two elements each of which is standard normal, then draws analogous
to those in Figure 9.8 are obtained as follows: Draw µa1 and µb1 from
a uniform between 0 and 0.25. Calculate ε1 as Φ−1 (µa1 ), Φ−1 (µb1 ) .
Calculate the other 15 points as εr as Φ−1 (xr + µa1 ), Φ−1 (yr + µb1 ) ,
where xr , yr  is the origin of area r in the unit square.
The requirement that the elements of ε be independent is not restrictive. Correlated random elements are created through transformations of independent elements, such as the Choleski transformation.
The independent elements are drawn from their density and then the
correlation is created inside the model.
Obviously, numerous sets of systemtically sampled draws can be
obtained to gain more randomization. In two dimensions with four
segments in each dimension, 64 draws are obtained by taking 4 independent draws in the 0 to 1/4 square and creating 15 other draws from
each. This procedure provides greater randomization but less ﬁne coverage than deﬁning the draws in terms of 8 segments in each dimension
such that each random draw in the 0 to 1/8 square translates into 64
systematic draws.
The draws for the normal distribution that are created as just described are not symmetric around zero. An alternative approach can
be used to assure such symmetry. For a uni-dimensional normal, 4
draws that are symmetric around zero are obtained as follows. Draw
a uniform between 0 and 0.25, labeled µ1 . Create the draw from the
normal as ε1 = Φ−1 (µ1 ). Create the draw for the second segment as
ε2 = Φ−1 (0.25 + µ1 ). Then create the draws for the third and fourth
segments as the negative of these draws: ε3 = −ε2 and ε4 = −ε1 . Fig-

252

CHAPTER 9. DRAWING FROM DENSITIES

ure 9.10 illustrates the draws using the same µ1 as for Figure 9.9. This
procedure combines systematic sampling with antithetics. It can be
extended to multiple dimensions by creating systematic draws for the
positive quadrant and then creating antithetic variates for the other
quadrants.

ε1 _

0.67

ε2

0

ε3

0.67

ε4

Figure 9.10: Symmetric systematic draws.

9.3.3

Halton sequences

Halton sequences (Halton, 1960) provide coverage and, unlike the other
methods we have discussed, induce a negative correlation over observations. A Halton sequence is deﬁned in terms of a given number,
usually a prime. The sequence is most easily understood though an
example. Consider the prime 3. The Halton sequence for 3 is created by dividing the unit interval into three parts with breaks at 13
and 23 , as shown in the top panel of Figure 9.11. The ﬁrst terms in
the sequence are these breakpoints: 13 , 23 . Then each of the three segments is divided into thirds, and the breakpoints for these segments
are added to the sequences in a particular way. The sequence becomes: 13 , 23 , 19 , 49 , 79 , 29 , 59 , 89 Note that the lower breakpoints in all three
segments ( 19 , 49 , 79 ) are entered in the sequence before the higher breakpoints ( 29 , 59 , 89 .) Then each of the 9 segments is divided into thirds,
with the breakpoints added to the sequences. The sequence becomes:
1 2 1 4 7 2 5 8 1 10 19 4 13
3 , 3 , 9 , 9 , 9 , 9 , 9 , 9 , 27 , 27 , 27 , 27 , 27 , and so on. This process is continued for as many points as the researcher wants to obtain.
From a programming perspective, it is easy to create a Halton
sequence. The sequence is created iteratively. At each iteration t, the
sequence is denoted st , which is a series of numbers. The sequence is

9.3. VARIANCE REDUCTION

253

a

b

1/3

2/3

c

a d

b e

1/9

4/9

7/9

c

f a d

g b e

h

2/9

5/9

8/9

Figure 9.11: Halton sequence for prime 3.
extended in each iteration with the new sequence being st+1 = {st , st +
1/3t , st + 2/3t }. Start with 0 as the initial sequence: s0 = {0}. The
number zero is not actually part of a Halton sequence, but considering
to be the ﬁrst element facilitates creation of the sequence, as we will
see. It can be dropped after the entire sequence is created. In the ﬁrst
iteration, add 1/31 (= 13 ) and then 2/31 (= 23 ) to this sequence and
append the results, to get {0, 13 , 23 }. The sequence has three elements.
In the second iteration, add 1/32 (= 19 ) and then 2/32 (= 29 ) to each
element of the sequence and append the results:
0
1/3
2/3
0
1/3
2/3
0
1/3
2/3

+
+
+
+
+
+

1/9
1/9
1/9
2/9
2/9
2/9

=

0
1/3
1/3
1/9
4/9
7/9
2/9
5/9
7/9

The new sequence consists of nine elements.

254

CHAPTER 9. DRAWING FROM DENSITIES

1
1
) and then 2/33 (= 27
) to
In the third iteration, add 1/33 (= 27
each element of this sequence and append the results:

0
1/3
2/3
1/9
4/9
7/9
2/9
5/9
8/9
0
1/3
2/3
1/9
4/9
7/9
2/9
5/9
8/9
0
1/3
2/3
1/9
4/9
7/9
2/9
5/9
8/9

+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+

1/27
1/27
1/27
1/27
1/27
1/27
1/27
1/27
1/27
2/27
2/27
2/27
2/27
2/27
2/27
2/27
2/27
2/27

=

0
1/3
2/3
1/9
4/9
7/9
2/9
5/9
8/9
1/27
10/27
19/27
4/27
13/27
22/27
7/27
16/27
25/27
2/27
11/27
20/27
5/27
14/27
23/27
8/27
17/27
26/27

The sequence now consists of 27 elements. In the fourth iteration, add
1
2
) and then 2/34 (= 81
) to each element of the sequence and
1/34 (= 81
append the results. And so on.
Note that the sequence cycles over the unit interval every 3 num-

9.3. VARIANCE REDUCTION

255

bers:

0
1/9
2/9
1/27
4/27
7/27
2/27
5/27
8/27

1/3
4/9
5/9
10/27
13/27
16/27
11/27
14/27
17/27

2/3
7/9
8/9
19/27
22/27
25/27
20/27
23/27
26/27

Within each cycle the numbers are ascending.
Halton sequences for other prime numbers are created similarly.
1 9
, 16 . . . . In general, the seThe sequence for 2 is { 12 , 14 , 34 , 18 , 58 , 38 , 78 , 16
quence for prime k is created iteratively, with the sequence at iteration
t + 1 being st+1 = {st , st + 1/k t , st + 2/k t , . . . , st + (k − 1)/k t }. The
sequence contains cycles of length k, where each cycle consists of k
ascending points on the unit interval equidistant from each other.
Since a Halton sequence is deﬁned on the unit interval, its elements
can be considered as well-placed “draws” from a standard uniform
density. The Halton draws provide better coverage than random draws,
on average, because they are created to progressively ﬁll-in the unit
interval evenly and evermore densely. The elements in each cycle are
equidistant apart, and each cycle covers the unit interval in the areas
not covered by previous cycles.
When using Halton draws for a sample of observations, one long
Halton sequence is usually created and then part of the sequence is used
for each observation. The initial elements of the sequence are discarded
for reasons we will discuss. The remaining elements are then used in
groups, with each group of elements constituting the “draws” for one
observation. For example, suppose there are two observations, and the
researcher wants R = 5 draws for each. If the prime 3 is used, and the
researcher decides to discard the ﬁrst 10 elements, then a sequence of

256

CHAPTER 9. DRAWING FROM DENSITIES

length 20 is created. This sequence is:
0
1/3
2/3
1/9
4/9
7/9
2/9
5/9
8/9
1/27 10/27 19/27
4/27 13/27 22/27
7/27 16/27 25/27
2/27 11/27.
After eliminating the ﬁrst 10 elements, the Halton draws for the ﬁrst
19 4 13 22
observation are { 10
27 , 27 , 27 , 27 , 27 } and the Halton draws for the second
7 16 25 2 11
, 27 , 27 , 27 , 27 }. These draws are illustrated in Figobservation are { 27
ure 9.12. Note that the gaps in coverage for the ﬁrst observation are
1st observation

27

7
/2
22 27
/
19
7
/2
13 27
/
10

4/
2nd observation

25
7

/2

7
/2
16
7
/2
11 7
2
7/
27

2/

Figure 9.12: Halton draws for two observations.
ﬁlled by the draws for the second observation. For example, the large
4
and 10
gap between 27
27 for the ﬁrst observation is ﬁlled in by the mid7
point of this gap, 27 , for the second observation. The gap between 13
27
16
and 19
27 is ﬁlled in by its midpoint, 27 , for the second observation. And
so on. The pattern by which Halton sequences are created make it such
that each subsequence ﬁlls in the gaps of the previous subsequences.
Because of this ﬁlling-in property, simulated probabilities based
on Halton draws tend to be self-correcting over observations. The
draws for one observation tend to be negatively correlated with those
for the previous observation. In our example, the average of the ﬁrst
observation’s draws is above 0.5 while the average of the draws for
the second observation is below 0.5. This negative correlation reduces
error in the simulated log-likelihood function.
When the number of draws used for each observation rises, the coverage for each observation improves. The negative covariance across

9.3. VARIANCE REDUCTION

257

observations diminishes, since there are fewer gaps in each observation’s coverage to be ﬁlled in by the next observation. The selfcorrecting aspect of Halton draws over observations is greatest when
few draws are used for each observation such that the correction is
most needed. However, accuracy improves with more Halton draws
since coverage is better for each observation.
As described so far, the Halton draws are for a uniform density. To
obtain a sequence of points for other univariate densities, the inverse
cumulative distribution is evaluated at each element of the Halton
sequence. For example, suppose the researcher wants draws from a
standard normal density. A Halton sequence is created for, say, prime
3 and the inverse cumulative normal is taken for each element. The
resulting sequence is:
Φ−1 (1/3)
Φ−1 (2/3)
Φ−1 (1/9)
Φ−1 (4/9)
Φ−1 (7/9)
....

=

−.43
.43
−1.2
−.14
.76

This sequence is depicted in Figure 9.13. It can be considered the same
as for the unit interval, as dividing the density into three segments of
equal mass, with breakpoints at -.43 and +.43, and then dividing each
segment into three subsegments of equal mass, and so on.

1.
2

76
0.
43
0.
14
0.
14
_ 0.
43

76

_ 0.

_ 0.

2

_ 1.

Figure 9.13: Halton draws for a standard normal.

258

CHAPTER 9. DRAWING FROM DENSITIES

Halton sequences in multiple dimensions are obtained by creating
a Halton sequence for each dimension with a diﬀerent prime for each
dimension. For example, a sequence in two dimensions is obtained by
creating pairs from the Halton sequence for primes 2 and 3. The points
are
ε1

=  12 , 13 

ε2

=  14 , 23 

ε3

=  34 , 19 

ε4

=  18 , 49 

ε5

=  58 , 79 

ε6 =  38 , 29 
...
This sequence is depicted in Figure 9.14. To obtain draws for a two-

ε5

ε2

2/ 3
ε4

ε1

1/ 3
ε6

ε3

1/ 2

Figure 9.14: Halton sequence in two dimensions for primes 2 and 3.
dimensional independent standard normal, the inverse cumulative nor-

9.3. VARIANCE REDUCTION

259

mal is taken of each element of these pairs. The draws are
0,
ε1 = 
ε2 =  −.67,
ε3 = 
.67,
ε4 =  −1.15,
ε5 = 
.32,
ε6 =  −.32,
...

−.43 
.43 
−1.2 
−.14 
.76 
−.76 

which are shown in Figure 9.15.

εb

ε5
ε2
εa
ε4
ε1
ε6
ε3

Figure 9.15: Halton sequence for 2-dimensional standard normal.
When creating sequences in several dimensions, it is customary
to eliminate the initial part of the series. The initial terms of two
Halton sequences are highly correlated, through at least the ﬁrst cycle
of each sequence. For example, the sequences for 7 and 11 begin with
1 2 3 4 5 6
{ 17 , 27 , 37 , 47 , 57 , 67 } and { 11
, 11 , 11 , 11 , 11 , 11 . . .}. These ﬁrst elements fall
in a line in two dimensions, as shown in Figure 9.16. The correlation
dissipates after each sequence has cycled through the unit interval since
sequences with diﬀerent primes cycle at diﬀerent rates. Discarding the
initial part of the sequence eliminates the correlated portion. The

260

CHAPTER 9. DRAWING FROM DENSITIES

number of initial elements to discard needs to be at least as large as
the largest prime that is used in creating the sequences.

Figure 9.16: First six elements of Halton sequence for primes 7 and 11.
The potential for correlation is the reason that prime numbers are
used to create the Halton sequences instead of non-primes. If a nonprime is used, then there is a possibility that the cycles will coincide
throughout the entire sequence, rather than for just the initial elements. For example, if Halton sequences are created for 3 and 6, the
sequence for 3 cycles twice for every one cycle of the sequence for 6.
Since the elements within a cycle are ascending, the elements in each
cycle of the sequence for 3 are correlated with the elements in the
cycle of the sequence for 6. Using only prime numbers avoids this
overlapping of cycles.
The superior coverage and the negative correlation over observations that are obtained with Halton draws combine to make Halton
draws far more eﬀective than random draws for simulation. Spanier
and Maize (1991) have shown that a small number of Halton draws provide relatively good integration. In the context of discrete choice models, Bhat (2001) found that 100 Halton draws provided more precise
results for his mixed logit than 1000 random draws. In fact, the simulation error with 125 Halton draws was half as large as with 1000 random
draws and somewhat smaller than with 2000 random draws. Train
(2000), Munizaga and Alvarez-Daziano (2001), and Hensher (2001)

9.3. VARIANCE REDUCTION

261

conﬁrm these results on other datasets.
As illustration, consider the mixed logit model that is described
extensively in Chapter 11. Brieﬂy, the model is for household’s choice
of electricity supplier. In a stated preference survey, respondents were
presented with a series of hypothetical choice situations. In each situation, four energy suppliers were described and the respondent was
asked which company he/she would choose. The suppliers were differentiated on the basis of their price, whether the company required
the customer to sign a long-term contract, whether the supplier was
the local energy utility, whether the supplier was a well-known company, and whether the supplier oﬀered time-of-day (TOD) or seasonal
rates. A mixed logit model was estimated with these six characteristics as explanatory variables. The coeﬃcient of each variable was
assumed to be normally distributed, except for the price coeﬃcient
which was assumed to be ﬁxed. The model therefore contained ﬁve
random terms for simulation. A complete description of the data, the
estimated model, and its implications are given in Chapter 11, where
the content of the model is relevant to the topic of that chapter. For
now, we are concerned only with the issue of Halton draws compared
to random draws.
To investigate this issue, the model was estimated with 1000 random draws and then with 100 Halton draws. More speciﬁcally, the
model was estimated ﬁve times using ﬁve diﬀerent sets of 1000 random draws. The mean and standard deviation of the estimated parameters from these ﬁve runs were calculated. The model was then
estimated ﬁve times with Halton sequences. The ﬁrst model used the
primes 2,3,5,7,11 for the ﬁve dimensions of simulation. The order of the
primes was switched for the other models, such that the dimension for
which each prime was used changed in the ﬁve runs. The average and
standard deviation of the ﬁve sets of estimated were then calculated.
The means of the parameter estimates over the ﬁve runs are given
in Table 9.1. The mean for the runs based on random draws are given
in the ﬁrst column, and the means for the runs based on Halton draws
are given in the second column. The two sets of means are very similar.
This result indicates that the Halton draws provide the same estimates,
on average, as random draws.
The standard deviations of the parameter estimates are given in
Table 9.2. For all but one of the 11 parameters, the standard deviations
are lower with 100 Halton draws than with 1000 random draws. For

262

CHAPTER 9. DRAWING FROM DENSITIES

Table 9.1: Means of Parameter Estimates
1000 random draws 100 Halton draws
Price
-0.8607
-0.8588
Contract length
Mean
-0.1955
-0.1965
Std. Dev.
0.3092
0.3158
Local utility
Mean
2.0967
2.1142
Std. Dev.
1.0535
1.0236
Known company
Mean
1.4310
1.4419
Std. Dev.
0.8208
0.6894
TOD rates
Mean
-8.3760
-8.4149
Std. Dev.
2.4647
2.5466
Seasonal rates
Mean
-8.6286
-8.6381
Std. Dev.
1.8492
1.8977

8 of the parameters, the standard deviations are half as large. Given
that both sets of draws give essentially the same means, the lower
standard deviations with the Halton draws indicates that a researcher
can expect to be closer to the expected values of the estimates using
100 Halton draws than 1000 random draws.
These results show the value of Halton draws. Computer time can
be reduced by a factor of ten by using Halton draws in lieu of random
draws, without reducing, and in fact increasing, accuracy.
These results need to be viewed with caution, however. The use
of Halton draws and other quasi-random numbers in simulation-based
estimation is fairly new and not completely understood. For example,
an anomaly arose in the analysis that serves as a helpful warning. The
model was re-estimated with 125 Halton draws instead of 100. It was
estimated ﬁve times under each of the ﬁve orderings of the prime numbers as described above. Four of the ﬁve runs provided very similar
estimates. However, the ﬁfth run gave estimates that were noticeably
diﬀerent from the others. For example, the estimated price coeﬃcient
for the ﬁrst four runs was -0.862, -0.865, -0.863, and -0.864, respectively, while the ﬁfth gave -0.911. The standard deviations over the ﬁve

9.3. VARIANCE REDUCTION

263

Table 9.2: Standard deviations of Parameter Estimates
1000 random draws 100 Halton draws
Price
0.0310
0.0169
Contract length
Mean
0.0093
0.0045
Std. Dev.
0.0222
0.0108
Local utility
Mean
0.0844
0.0361
Std. Dev.
0.1584
0.1180
Known company
Mean
0.0580
0.0242
Std. Dev.
0.0738
0.1753
TOD rates
Mean
0.3372
0.1650
Std. Dev.
0.1578
0.0696
Seasonal rates
Mean
0.4134
0.1789
Std. Dev.
0.2418
0.0679
sets of estimates were lower than with 1000 random draws, conﬁrming
the value of the Halton draws. However, the standard deviations were
greater with 125 Halton draws than with 100 Halton draws, due to the
last run with 125 draws providing such diﬀerent results. The reason
for this anomaly has not been determined. Its occurrence indicates the
need for further investigation of the properties of Halton sequences in
simulation-based estimation.

9.3.4

Randomized Halton draws

Halton sequences are systematic rather than random. However, the
asymptotic properties of simulation-based estimators are derived under
the concept that the draws are random. There are two ways that
this issue can be addressed. First, one can realize that draws from
a random number generator are not actually random either. They
are systematic, like anything done by a computer. A random number
generator creates draws that have the characteristics of truly random
draws, but the fact that they are systematic is why they are called
“pseudo-random draws.” In this regard, therefore, Halton draws can
be seen as a systematic way of approximating integration that is more

264

CHAPTER 9. DRAWING FROM DENSITIES

precise than using pseudo-random draws, which are also systematic.
Neither matches the theoretical concept of randomness, and, in fact,
it is not clear that the theoretical concept actually has a real-world
counterpart. Both meet the basic underlying goal of approximating an
integral over a density.
Second, Halton sequences can be transformed in a way that makes
them random, at least in the same way that pseudo-random numbers
are random. Bhat (forthcoming) describes the process, based on procedures introduced by Tuﬃn (1996):
1. Take a draw from a standard uniform density. Label this random
draw as µ.
2. Add µ to each element of the Halton sequence. If the resulting
element exceeds one, subtract 1 from it. Otherwise, keep the
resulting element as is (without subtracting 1).
The formula for this transformation is sn = mod(so + µ), where so
is the original element of the Halton sequence, sn is the transformed
element, and mod takes the fractional part of the term in parentheses.
The transformation is depicted in Figure 9.17. Suppose the draw of
µ from the uniform density is 0.40. The number .33 is the ﬁrst element
of the Halton sequence for prime 3. This element is transformed, as
shown in the top panel, to .33 + .40 = .73, which is just a .40 move
up the line. The number .67 is the second element of the sequence.
It is transformed by adding .4 and then, since the result exceeds 1,
by subtracting 1 to get 0.07. (.67 + .40 − 1 = .07). As shown in the
bottom panel, this transformation is visualized as moving the original
point up by a distance of .40, but wrapping around when the end of
the unit interval is reached. The point moves up .33 to where the line
ends, and then wraps to the start of the line and continues to move up
another .07, for a total movement of .40.
Figure 9.18 depicts the transformation for the ﬁrst ﬁve elements
of the sequence. The relation between the points and the degree of
coverage are the same before and after the transformation. However,
since the transformation is based on the random draw of µ, the numerical values of the transformed sequence are random. The resulting
sequence is called a randomized Halton sequence. It has the same
properties of coverage and negative correlation over observations as
the original Halton draws, since the relative placement of the elements
are the same; however, it is now random.

9.3. VARIANCE REDUCTION

265
0.40

73
0.

33
0.

0.33

0.07

67
0.

07
0.

Figure 9.17: Random transformation of Halton draws with µ = 0.40.

78
0.
67
0.

44
0.
33
0.

84

73

0.

0.

51

0.

18
0. 7
0
0.

Transformed
sequence

11
0.

Original
sequence

Figure 9.18: Randomization of Halton sequence in one dimension.
With multiple dimensions, the sequence used for each dimension is
transformed separately based on its own draw from the standard uniform density. Figure 9.19 represents a transformation of a 2-dimensional
sequence of length 3 deﬁned in primes 2 and 3. The sequence in prime
3 is given by the x-axis and obtains a random draw of 0.40. The sequence for prime 2 obtains a draw of 0.35. Each point in the original
2-dimensional sequence is moved to the left by .40 and up by .35, wrapping as needed. The relation between the points in each dimension is
maintained, and yet the sequence is now random.

9.3.5

Scrambled Halton draws

Another issue with Halton draws arises when they are used in high
dimensions. For simulation of high-dimensional integrals, Halton sequences based on large primes are necessary. For example, with 15
dimensions, the primes up to 47 are needed. However, Halton draws
deﬁned by large primes can be highly correlated with each other over
large portions of the sequence. The correlation is not conﬁned to the
initial elements as described above, and so cannot be eliminated by

CHAPTER 9. DRAWING FROM DENSITIES

266

3/4
Original
Sequence

c
a

1/ 2

0.35
0.40
b

1/ 4

1/ 3

2/ 3

a
3/4
b
Transformed
Sequence

1/ 2
1/ 4

c
1/ 3

2/ 3

Figure 9.19: Randomization of Halton sequence in two dimensions.

9.3. VARIANCE REDUCTION

267

discarding these elements. Two sequences deﬁned by large and similar
primes periodically become “in synch” with each other and stay that
way for many cycles.
Bhat (forthcoming) describes the problem and an eﬀective solution.
Figure 9.20 reproduces a graph from his paper that depicts the Halton
sequence for primes 43 and 47. Cleary, these sequences are highly
correlated.

Dimension 15

1

0

0

Dimension 14

1

Figure 9.20: Standard Halton sequence.
This correlation can be removed while retaining the desirable coverage of Halton sequences by “scrambling” the digits of each element of
the sequences. The scrambling can be done in various ways. Braatan
and Weller (1979) describe a procedure that is most easily explained
through an example. Consider the Halton sequence for prime 3:
1 2 1 4 7 2 5 8
, , , , , , , ,....
3 3 9 9 9 9 9 9
Recall that the sequence is created by dividing the unit interval into
three segments, which we label A, B, and C in Figure 9.21. Each

268

CHAPTER 9. DRAWING FROM DENSITIES
A

B

C

AA BA CA AB BB CB AC BC CC

Figure 9.21: Segments for scrambling the Halton sequence.
segment is divided into three subsegments, labeled AA (for subsegment
A of segment A), BA (subsegment B of segment A), CA, AB, BB, CB,
AC, BC, and CC. The Halton sequence is the starting point of each
segment arranged alphbetically and ignoring A (i.e., ignore A, 13 for B,
2
3 for C), followed by the starting point of each subsegment arranged
alphabetically and ignoring A (i.e., ignore AA, AB and AC, 19 for
BA, 49 for BB, 79 for BC, 29 for CA, 59 for CB, and 89 for CC.) Note
that the segments/subsegments starting with A are ignored because
the starting point for those segments/ subsegments are either 0 (for
segment A) or are already included in the sequence (e.g., the starting
point of subsegment AB is the same as the starting point of the segment
B).
The scrambled sequence is obtained by reversing B and C, that is,
by considering C to be before B in the alphabet. The alphabetical
listing is now: segments A C B, subsegments AA AC AB CA CC CB
BA BC BB. The sequence is then created the same way as before but
with this new alphabetical ordering: ignore A, 23 for C, 13 for B, ignore
AA,AC and AB, 29 for CA, 89 for CC, 59 for CB, 19 for BA, 79 for BC, 49
for BB. The orginal and scrambled sequences are:
original scrambled
1/3
2/3
2/3
1/3
1/9
2/9
4/9
8/9
7/9
5/9
2/9
1/9
5/9
7/9
8/9
4/9
Diﬀerent permutations of the letters are used for diﬀerent primes.
Figure 9.22, from Bhat (2001), shows the scrambled sequence for primes
43 and 47. The points are not correlated like in the original sequence.

9.3. VARIANCE REDUCTION

269

Bhat demonstrates that scrambled sequences perform well for highdimensional integrals in the same way that unscrambled ones do for
low-dimensional integrals.

Dimension 15

1

0

0

Dimension 14

1

Figure 9.22: Scrambled Halton sequence.

9.3.6

Other procedures

We have described only a few of the most prominent and straightforward antithetic and quasi-random procedures. More complex procedures, with desirable theoretical properties, are described by Niederreiter (1978), Niederreiter (1988), Morokoﬀ and Caﬂisch (1995), Joe and
Sloan (1993), and Sloan and Wozniakowski (1998), to name only a few
in this burgeoning area of research. As we have seen with Halton sequences, fairly simple procedures can provide large improvements over
random draws. Comparisons performed by Sándor and András (2001)
on probit and Sándor and Train (2002) on mixed logit indicate that
the accuracy of simulation-based estimation of discrete choice models
can be improved even further with the more complex procedures. It is

270

CHAPTER 9. DRAWING FROM DENSITIES

important to remember, however, in the excitement of these methods,
that accuracy can always be improved by simply using more draws.
The researcher needs to decide whether learning and coding new methods of taking draws is more expedient, given her time constraints, than
simply running her model with more draws.

Chapter 10

Simulation-Assisted
Estimation
10.1

Motivation

So far we have examined how to simulate choice probabilities but have
not investigated the properties of the parameter estimators that are
based on these simulated probabilities. In the applications we have
presented, we simply inserted the simulated probabilities into the loglikelihood function and maximized this function the same as if the
probabilities were exact. This procedure seems intuitively reasonable.
However, we have not actually shown, at least so far, that the resulting
estimator has any desirable properties, such as consistency, asymptotic
normality, or eﬃciency. We have also not explored the possibility that
other forms of estimation might perhaps be preferable when simulation
is used rather than exact probabilities.
The purpose of this chapter is to examine various methods of estimation in the context of simulation. We derive the properties of
these estimators and show the conditions under which each estimator is consistent and asymptotically equivalent to the estimator that
would arise with exact values rather than simulation. These conditions
provide guidance to the researcher on how the simulation needs to be
performed to obtain desirable properties of the resultant estimator.
The analysis also illuminates the advantages and limitations of each
form of estimation, thereby facilitating the researcher’s choice among
methods.
We consider three methods of estimation:
271

272

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

1. Maximum Simulated Likelihood: MSL. This procedure is the
same as maximum likelihood (ML) except that simulated probabilities are used in lieu of the exact probabilities. The properties
of MSL have been derived by, for example, Gourieroux and Monfort (1993), Lee (1995), and Hajivassiliou and Ruud (1994).
2. Method of Simulated Moments: MSM. This procedure, suggested
by McFadden (1989), is a simulated analog to the traditional
method of moments (MOM). Under traditional MOM for discrete
choice, residuals are deﬁned as the diﬀerence between the 0-1 dependent variable that identiﬁes the chosen alternative and the
probability of the alternative. Exogenous variables are identiﬁed
that are uncorrelated with the model residuals in the population.
The estimates are the parameter values that make the variables
and residuals uncorrelated in the sample. The simulated version
of this procedure calculates residuals with the simulated probabilities rather than the exact probabilities.
3. Method of Simulated Scores: MSS. As discussed in Chapter 8, the
gradient of the log-likelihood of an observation is called the score
of the observation. The method of scores ﬁnds the parameter
values that set the average score to zero. When exact probabilities are used, the method of scores is the same as maximum
likelihood since the log-likelihood function is maximized when
the average score is zero. Hajivassiliou and McFadden (1998)
suggested using simulated scores instead of the exact ones. They
showed that, depending on how the scores are simulated, MSS
can diﬀer from MSL and, importantly, can attain consistency
and eﬃciency under more relaxed conditions.
In the next section we deﬁne these estimators more formally and
relate them to their non-simulated counterparts. We then describe the
properties of each estimator in two stages. First, we derive the properties of the traditional estimator based on exact values. Second, we
show how the derivation changes when simulated values are used rather
than exact values. We show that the simulation adds extra elements
to the sampling distribution of the estimator. The analysis allows us
to identify the conditions under which these extra elements disappear
asymptotically such that the estimator is asymptotically equivalent to
its non-simulated analog. We also identify more relaxed conditions un-

10.2. DEFINITION OF ESTIMATORS

273

der which the estimator, though not asymptotically equivalent to its
non-simulated counterpart, is nevertheless consistent.

10.2

Deﬁnition of estimators

10.2.1

Maximum simulated likelihood: MSL

The log-likelihood function is
lnPn (θ)

LL(θ) =
n

where θ is a vector of parameters, Pn (θ) is the (exact) probability
of the observed choice of observation n, and the summation is over a
sample of N independent observations. The maximum likelihood (ML)
estimator is the value of θ that maximizes LL(θ). Since the gradient of
LL(θ) is zero at the maximum, the ML estimator can also be deﬁned
as the value of θ at which
sn (θ) = 0,
n

where sn (θ) = ∂lnPn (θ)/∂θ is the score for observation n.
Let P̌n (θ) be a simulated approximation to Pn (θ). The simulated

log-likelihood function is SLL(θ) = n lnP̌n (θ), and the maximum
simulated likelihood (MSL) estimator is the value of θ that maximizes
SLL(θ). Stated equivalently, the estimator is the value of θ at which

n šn (θ) = 0, where šn (θ) = ∂lnP̌n (θ)/∂θ.
A preview of the properties of MSL can be given now, with a full
explanation reserved for the next section. The main issue with MSL
arises because of the log transformation. Suppose P̌n (θ) is an unbiased
simulator of Pn (θ), such that Er P̌n (θ) = Pn (θ) where the expectation
is over draws used in the simulation. All of the simulators that we have
considered are unbiased for the true probability. However, since the
log operation is a non-linear transformation, lnP̌n (θ) is not unbiased
for lnPn (θ) even though P̌n (θ) is unbiased for Pn (θ). The bias in the
simulator of lnPn (θ) translates into bias in the MSL estimator. This
bias diminishes as more draws are used in the simulation.
To determine the asymptotic properties of the MSL estimator, the
question arises of how the simulation bias behaves when sample size
rises. The answer depends critically on the relationship between the

274

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

number of draws that are used in the simulation, labeled R, and the
sample size, N . If R is considered ﬁxed, then the MSL estimator
does not converge to the true parameters because of the simulation
bias in lnP̌n (θ). Suppose instead that R rises with N ; that is, the
number of draws rises with sample size. In this case, the simulation
bias disappears as N (and hence R) rises without bound.√ MSL is
consistent in this case. As we will see, if R rises faster than N , MSL
is not only consistent but also eﬃcient, asymptotically equivalent to
maximum likelihood on the exact probabilities.
In summary: If R is ﬁxed, then MSL is inconsistent. If R rises
√ at
any rate with N , then MSL is consistent. If R rises faster than N ,
then MSL is asymptotically equivalent to ML.
The primary limitation of MSL is that it is inconsistent for ﬁxed R.
The other estimators that we consider are motivated by the desire for a
simulation-based estimator that is consistent for ﬁxed R. Both MSM
and MSS, if structured appropriately, attain this goal. This beneﬁt
comes at a price, however, as we see in the discussion below.

10.2.2

Method of simulated moments: MSM

The traditional method of moments (MOM) is motivated by the recognition that the residuals of a model are necessarily uncorrelated in the
population with factors that are exogenous to the behavior being modeled. The MOM estimator is the value of the parameters that make
the residuals in the sample uncorrelated with the exogenous variables.
For discrete choice models, MOM is deﬁned as the parameters that
solve the equation:
[dnj − Pnj (θ)]znj = 0
n

(10.1)

j

where:
dnj is the dependent variable that identiﬁes the chosen alternative:
dnj = 1 if n chose j and zero otherwise, and
znj is a vector of exogenous variables called instruments.
The residuals are [dnj −Pnj (θ)], and the MOM estimator is the parameter values at which the residuals are uncorrelated with the instruments
in the sample.

10.2. DEFINITION OF ESTIMATORS

275

This MOM estimator is analogous to MOM estimators for standard
regression models. A regression model takes the form: yn = xn β + εn .
The MOM estimator for this regression is the β at which
(yn − xn β)zn = 0
n

for a vector of exogenous instruments zn . When the explanatory variables in the model are exogenous, then they serve as the instruments.
The MOM estimator in this case becomes the ordinary least squares
estimator:
(yn − xn β)xn = 0
n

xn xn β

xn yn =
n

n



xn xn

β̂ =

−1 

n



xn yn ,
n

which is the formula for the least squares estimator. When instruments
are speciﬁed to be something other than the explanatory variables, the
MOM estimator becomes the standard instrumental variables estimator:
(yn − xn β)zn = 0
n

zn xn β

z n yn =
n

n



zn xn

β̂ =
n

−1 



z n yn ,
n

which is the formula for the instrumental variables estimator. This
estimator is consistent if the instruments are independent of ε in the
population. The estimator becomes more eﬃcient the more highly
correlated the instruments are with the explanatory variables in the
model. When the explanatory variables, xn , are themselves exogenous,
then the ideal instruments (i.e., those that give the highest eﬃciency)
are the explanatory variables themselves, zn = xn .
For discrete choice models, MOM is deﬁned analogously and has
a similar relation to other estimators, especially ML. The researcher
identiﬁes instruments znj that are exogenous and hence independent

276

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

in the population of the residuals [dnj − Pnj (θ)]. The MOM estimator
is the value of θ at which the sample correlation between instruments
and residuals is zero. Unlike the linear case, equation (10.1) cannot be
solved explicitly for θ̂. Instead, numerical procedures are used to ﬁnd
the value of θ that solves this equation.
As with regression, ML for a discrete choice model is a special case
of MOM. Let the instruments be the scores: znj = ∂lnPnj (θ)/∂θ. With
these instruments, MOM is the same as ML:
[dnj − Pnj (θ)]znj


n





j

= 0



∂lnPnj (θ) 
∂lnPnj (θ)  

dnj
−
Pnj (θ)
= 0
∂β
∂β
n
j
j
n

∂lnPni (θ)
−
∂β
n

Pnj (θ)

1 ∂Pnj (θ)
Pnj (θ) ∂θ

= 0

sn (θ) −

∂Pnj (θ)
∂θ

= 0

j

n

n

j

sn (θ) = 0,
n

which is the deﬁning condition for ML. In the third line, i is the chosen
alternative, recognizing that dnj = 0 for all j = i. The fourth line uses
the fact that the sum of ∂Pnj /∂θ over alternatives is zero since the
probabilities must sum to 1 before and after the change in θ.
Since MOM becomes ML and hence is fully eﬃcient when the instruments are the scores, the scores are called the ideal instruments.
MOM is consistent whenever the instruments are independent of the
model residuals. It becomes more eﬃcient the higher the correlation
between the instruments and the ideal instruments.
An interesting simpliﬁcation arises with standard logit. For the
standard logit model, the ideal instruments are the explanatory variables themselves. As shown in (3.7.1), the ML estimator for standard
 
logit is the value of θ that solves n j [dnj − Pnj (θ)]xnj = 0 where
xnj are the explanatory variables. This is a MOM estimator with the
explanatory variables as instruments.
A simulated version of MOM, called method of simulated moments
(MSM), is obtained by replacing the exact probabilities Pnj (θ) with
simulated probabilities P̌nj (θ). The MSM estimator is the value of θ

10.2. DEFINITION OF ESTIMATORS

277

that solves:
[dnj − P̌nj (θ)]znj = 0
n

j

for instruments znj . As with its non-simulated analog, MSM is consistent if znj is independent of [dnj − P̌nj (θ)].
The important feature of this estimator is that P̌nj (θ) enters the
equation linearly. As a result, if P̌nj (θ) is unbiased for Pnj (θ), then
[dnj − P̌nj (θ)]znj is unbiased for [dnj − Pnj (θ)]znj . Since there is no
simulation bias in the estimation condition, the MSM estimator is
consistent, even when the number of draws R is ﬁxed. In contrast,
MSL contains simulation bias due to the log transformation of the
simulated probabilities. By not taking a non-linear transformation of
the simulated probabilities, MSM avoids simulation bias.
MSM still contains simulation noise (variance due to simulation).
This noise becomes smaller as R rises and disappears when R rises
without bound. As a result, MSM is asymptotically equivalent to
MOM if R rises with N .
Just like its unsimulated analog, MSM is less eﬃcient than MSL
unless the ideal instruments are used. However, the ideal instruments
are functions of lnPnj . They cannot be calculated exactly for any but
the simplest models, and, if they are simulated based on the simulated
probability, simulation bias is introduced by the log operation. MSM
is usually applied with non-ideal weights, which means that there is a
loss of eﬃciency. MSM with ideal weights that are simulated without
bias becomes MSS, which we discuss below.
In summary: MSM has the advantage over MSL of being consistent
with a ﬁxed number of draws. However, there is no free lunch, and the
cost of this advantage is a loss of eﬃciency when non-ideal weights are
used.

10.2.3

Method of simulated scores: MSS

MSS provides a possibility of attaining consistency without a loss of
eﬃciency. The cost of this double advantage is numerical: the versions
of MSS that provide eﬃciency have fairly poor numerical properties
such that calculation of the estimator can be diﬃcult.
The method of scores is deﬁned by the condition
sn (θ) = 0
n

278

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

where sn (θ) = ∂lnPn (θ)/∂θ is the score for observation n. This is the
same deﬁning condition as ML: when exact probabilities are used, the
method of scores is simply ML.
The method of simulated scores replaces the exact score with a
simulated counterpart. The MSS estimator is the value of θ that solves
šn (θ) = 0
n

where šn (θ) is a simulator of the score. If šn (θ) is calculated as
the derivative of the log of the simulated probability, i.e., šn (θ) =
∂lnP̌n (θ)/∂θ, then MSS is the same as MSL. However, the score can
be simulated in other ways. When the score is simulated in other ways,
MSS diﬀers from MSL and has diﬀerent properties.
Suppose that an unbiased simulator of the score can be constructed.

With this simulator, the deﬁning equation n šn (θ) = 0 does not
incorporate any simulation bias, since the simulator enters the equation
linearly. MSS is therefore consistent with a ﬁxed R. The simulation
noise decreases as R rises, such that MSS is asymptotically eﬃcient,
equivalent to MSL, when R rises with N . In contrast, MSL uses the
biased score simulator šn (θ) = ∂lnP̌n (θ)/∂θ, which is biased due to
the log operator. MSS with an unbiased score simulator is therefore
better that MSL with its biased score simulator in two regards: it is
consistent under less stringent conditions (with ﬁxed R versus R rising
with N ) and is eﬃcient under less stringent
√ conditions (R rising at any
rate with N versus R rising faster than N .)
The diﬃculty with MSS comes in ﬁnding an unbiased score simulator. The score can be rewritten as
sn (θ) =

1 ∂Pnj
∂lnPnj (θ)
=
.
∂θ
Pnj (θ) ∂θ

An unbiased simulator for the second term ∂Pnj /∂θ is easily obtained
by taking the derivative of the simulated probability. Since diﬀerentiation is a linear operation, ∂ P̌nj /∂θ is unbiased for ∂Pnj /∂θ if P̌nj (θ)
is unbiased for Pnj (θ). Since the second term in the score can be simulated without bias, the diﬃculty arises in ﬁnding an unbiased simulator
for the ﬁrst term 1/Pnj (θ). Of course, simply taking the inverse of the
simulated probability does not provide an unbiased simulator, since
1/Er P̌nj (θ) = 1/Pnj (θ). Like the log operation, an inverse introduces
bias.

10.2. DEFINITION OF ESTIMATORS

279

One proposal is based on the recognition that 1/Pnj (θ) is the expected number of draws of the random terms that are needed before an
“accept” is obtained. Consider drawing balls from an urn that contains
many balls of diﬀerent colors. Suppose the probability of obtaining a
red ball is 0.20. That is, one-ﬁfth of the balls are red. How many
draws would it take, on average, to obtain a red ball? The answer is
1/.2=5. The same idea can be applied to choice probabilities. Pnj (θ)
is the probability that a draw of the random terms of the model will
result in alternative j having the highest utility. The inverse 1/Pnj (θ)
can be simulated as follows:
1. Take a draw of the random terms from their density.
2. Calculate the utility of each alternative with this draw.
3. Determine whether alternative j has the highest utility.
4. If so, call the draw an “accept.” If not, then call the draw a
“reject” and repeat steps 1 to 3 with a new draw. Deﬁne B r as
the number of draws that are taken until the ﬁrst “accept” is
obtained.
5. Perform steps 1 to 4 R times, obtaining B r for r = 1, . . . , R. The

r
simulator of 1/Pnj (θ) is (1/R) R
r=1 B .
This simulator is unbiased for 1/Pnj (θ). The product of this simulator with the simulator ∂ P̌nj /∂θ provides an unbiased simulator of the
score. MSS based on this unbiased score simulator is consistent for
ﬁxed R and asymptotically eﬃcient when R rises with N .
Unfortunately, the simulator of 1/Pnj (θ) has the same diﬃculties as
the accept-reject simulators that we discussed in section (5.6). There is
no guarantee than an accept will be obtained within any given number
of draws. Also, the simulator is not continuous in parameters. The
discontinuity hinders the numerical procedures that are used to locate
the parameters that solve the MSS equation.
In summary, there are advantages and disadvantages of MSS relative to MSL, just as there are for MSM. Understanding the capabilities
of each estimator allows the researcher to make an informed choice
among them.

280

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

10.3

The central limit theorem

Prior to deriving the properties of our estimators, it is useful to review
the central limit theorem. This theorem provides the basis for the
distributions of the estimators.
One of the most basic concepts in statistics is that, if we take
draws from a distribution with mean µ and variance σ, the mean of
these draws will be normally distributed with mean µ and variance
σ/N , where N is a large number of draws. This concept is the central
limit theorem, stated intuitively rather than precisely. We will provide
a more complete and precise expression of these ideas.

Let t = (1/N ) n tn , where each tn is a draw a from a distribution
with mean µ and variance σ. The realization of the draws are called
the sample, and t is the sample mean. If we take a diﬀerent sample
(i.e., obtain diﬀerent values for the draws of each tn ), then we will get
a diﬀerent value for the statistic t. Our goal is to derive the sampling
distribution of t.
For most statistics, we cannot determine the sampling distribution
exactly for a given sample size. Instead, we examine how the sampling
distribution behaves as sample size rises without bound. A distinction
is made between the limiting distribution and the asymptotic distribution of a statistic. Suppose that, as sample size rises, the sampling
distribution of statistic t converges to a ﬁxed distribution. For example, the sampling distribution of t might become arbitrarily close to a
normal with mean t∗ and variance σ. In this case, we say that N (t∗ , σ)
is the limiting distribution of t and that t converges in distribution to
d
N (t∗ , σ). We denote this situation as t → N (t∗ , σ).
In many cases, a statistic will not have a limiting distribution. As N
rises, the sampling distribution keeps changing. The mean of a sample
of draws is an example of a statistic without a limiting distribution. As
stated above, if t is the mean of a sample of draws from a distribution
with mean µ and variance σ, then t is normally distributed with mean µ
and variance σ/N . The variance decreases as N rises. The distribution
changes as N rises, becoming more and more tightly dispersed around
the mean. If a limiting distribution were to be deﬁned in this case, it
would have to be the degenerate distribution at µ: as N rises without
bound, the distribution of t collapses on µ. This limiting distribution is
useless in understanding the variance of the statistic, since the variance
of this limiting distribution is zero. What do we do in this case to

10.3. THE CENTRAL LIMIT THEOREM

281

understand the properties of the statistic?
If our original statistic does not have a limiting distribution, then
we often can transform the statistic in such a way that the transformed
statistic has a limiting distribution. Suppose, as in in our example of
a sample mean, that the statistic we are interested in does not have a
limiting distribution because its variance decreases as N rises. In that
case, we can consider a transformation of the statistic
that normalizes
√
for sample size. In particular, we can consider N (t − µ). Suppose
that this statistic does indeed have a limiting distribution, for example
√
d
N (t − µ) → N (0, σ). In this case, we can derive the properties of
our original statistic from the limiting distribution of the transformed
statistic. Recall from basic principles of probabilities that, for ﬁxed a
and b, if a(t − b) is distributed normal with zero mean and variance σ,
then t itself is distributed normal with mean b and variance σ/a2 . This
concept
√ can be applied to our limiting distribution. For large enough
N , N (t − µ) is distributed approximately N (0, σ). Therefore, for
large enough N , t is distributed approximately N (µ, σ/N ). We denote
a
this as t ∼ N (µ, σ/N ). Note that this is not the limiting distribution
of t, since t has no nondegenerate limiting distribution. Rather, it
is called the asymptotic
distribution of t, derived from the limiting
√
distribution of N (t − µ).
We can now restate precisely our concepts about the sampling distribution of a sample mean. The central limit theorem states the following. Suppose t is the mean of a sample of N draws from a distribu√
d
tion with mean µ and variance σ. Then N (t − µ) → N (0, σ). With
a
this limiting distribution, we can say that t ∼ N (µ, σ/N ).
There is another, more general version of the central limit theorem.
In the version just stated, each tn is a draw from the same distribution.
Suppose tn is a draw from a distribution with mean µ and variance
σn , for n = 1, . . . , N . That is, each tn is from a diﬀerent distribution;
the distributions have the same mean but diﬀerent variances.
√ The
generalized version of the central limit theorem states that N (t −

d
µ) → N (0, σ), where σ is now the average variance: σ = (1/N ) n σn .
a
Given this limiting distribution, we can say that t ∼ N (µ, σ/N ). We
will use both versions of the central limit theorem when deriving the
distributions of our estimators.

282

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

10.4

Properties of traditional estimators

In this section, we review the procedure for deriving the properties of
estimators and apply that procedure to the traditional, non-simulationbased estimators. This discussion provides the basis for analyzing the
properties of the simulation-based estimators in the next section.
The true value of the parameters is denoted θ∗ . The ML and MOM
estimators are roots of an equation that takes the form
gn (θ̂)/N = 0.

(10.2)

n

That is, the estimator θ̂ is the value of the parameters that solve this
equation. We divide by N , even though this division does not aﬀect
the root of the equation, since doing so facilitates our derivation of
the properties of the estimators. The condition states that the average
value of gn (θ) in the sample is zero at the parameter estimates. For
ML, gn (θ) is the score ∂lnPn (θ)/∂θ. For MOM, gn (θ) is the set of ﬁrst

moments of residuals with a vector of instruments, j (dnj − Pnj )znj .
Equation (10.2) is often called the moment condition. In its nonsimulated form, the method of scores is the same as ML and therefore
need not be considered separately in this section. Note that we call
(10.2) an equation even though it is actually a set of equations, since
gn (θ) is a vector. The parameters that solve these equations are the
estimators.
At any particular value of θ, the mean and variance of gn (θ) can be
calculated for the sample. Label the mean as g(θ) and the variance as
W (θ). We are particularly interested in the sample mean and variance
of gn (θ) at the true parameters, θ∗ , since our goal is to estimate these
parameters.
The key to understanding the properties of an estimator comes in
realizing that each gn (θ∗ ) is a draw from a distribution of gn (θ∗ )’s in
the population. We do not know the true parameters, but we know
that each observation has a value of gn (θ∗ ) at the true parameters. The
value of gn (θ∗ ) varies over people in the population. So, by drawing
a person into our sample, we are essentially drawing a value of gn (θ∗ )
from its distribution in the population.
The distribution of gn (θ∗ ) in the population has a mean and variance. Label the mean of gn (θ∗ ) in the population as g and its variance
in the population as W. The sample mean and variance at the true

10.4. TRADITIONAL ESTIMATORS

283

parameters, g(θ∗ ) and W (θ∗ ), are the sample counterparts to the population mean and variance, g and W.
We assume that g = 0. That is, we assume that the average of
gn (θ∗ ) in the population is zero at the true parameters. Under this
assumption, the estimator provides a sample analog to this population
expectation: θ̂ is the value of the parameters at which the sample
average of gn (θ) equals zero, as given in the deﬁning condition 10.2.
For ML, the assumption that g = 0 simply states that the average
score in the population is zero, when evaluated at the true parameters.
In a sense, this can be considered the deﬁnition of the true parameters,
namely: θ∗ are the parameters at which the log-likelihood function for
the entire population obtains its maximum and hence has zero slope.
The estimated parameters are the values that make the slope of the
likelihood function in the sample zero. For MOM, the assumption is
satisﬁed if the instruments are independent of the residuals. In a sense,
the assumption with MOM is simply a reiteration that the instruments
are exogenous. The estimated parameters are the values that make the
instruments and residuals uncorrelated in the sample.
We now consider the population variance of gn (θ∗ ), which we have
denoted W. When gn (θ) is the score, as in ML, this variance takes a
special meaning. As shown in section (8.7), the information identity
states that V = −H where


−H = −E

∂ 2 lnPn (θ∗ )
∂θ∂θ



is the information matrix and V is the variance of the scores evaluated
at the true parameters: V = V ar(∂lnPn (θ∗ )/∂θ). When gn (θ) is
the score, we have W = V by deﬁnition and hence W = −H by
the information identity. That is, when gn (θ) is the score, W is the
information matrix. For MOM with non-ideal instruments, W = −H,
such that W does not equal the information matrix.
Why does this distinction matter? We will see that knowing whether
W equals the information matrix allows us to determine whether the
estimator is eﬃcient. The lowest variance that any estimator can
achieve is −H−1 /N . For a proof, see, for example, Greene (2000) or
Ruud (2000). An estimator is eﬃcient if its variance attains this lower
bound. As we will see, this lower bound is achieved when W = −H
but not when W = −H.
Our goal is to determine the properties of θ̂. We derive these prop-

284

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

erties in a two-step process. First, we examine the distribution of g(θ∗ ),
which, as stated above, is the sample mean of gn (θ∗ ). Second, the distribution of θ̂ is derived from the distribution of g(θ∗ ). This two step
process is not necessarily the most direct way of examining traditional
estimators. However, as we will see in the next section, it provides a
very convenient way for generalizing to simulation-based estimators.
Step 1: The distribution of g(θ∗ ).
Recall that the value of gn (θ∗ ) varies over decision-makers in the population. When taking a sample, the researcher is drawing values of
gn (θ∗ ) from its distribution in the population. This distribution has
zero mean by assumption and variance denoted W. The researcher
calculates the sample mean of these draws, g(θ∗ ). By the central limit
√
d
theorem, N (g(θ∗ ) − 0) → N (0, W) such that the sample mean has
a
distribution g(θ∗ ) ∼ N (0, W/N ).
Step 2: Derive the distribution of θ̂ from the distribution of
g(θ∗ ).
We can relate the estimator θ̂ to its deﬁning term g(θ) as follows. Take
a ﬁrst order Taylor’s expansion of g(θ̂) around g(θ∗ ):
g(θ̂) = g(θ∗ ) + D[θ̂ − θ∗ ]

(10.3)

where D = ∂g(θ∗ )/∂θ . By deﬁnition of θ̂ (that is, by deﬁning condition
10.2), g(θ̂) = 0 so that the right-hand-side of this expansion is 0. Then:
0 = g(θ∗ ) + D[θ̂ − θ∗ ]
√

(θ̂ − θ∗ ) = −D−1 g(θ∗ )
√
N (θ̂ − θ∗ ) =
N (−D−1 )g(θ∗ ).

(10.4)

Denote the mean of ∂gn (θ∗ )/∂θ in the population as D. The sample mean of ∂gn (θ∗ )/∂θ is D, as deﬁned above. The sample mean D
converges to the population mean D when sample size rises. We know
√
d
from step 1 that N g(θ∗ ) → N (0, W). Using this fact in (10.4), we
have:
√
d
N (θ̂ − θ∗ ) → N (0, D−1 WD−1 ).
(10.5)
This limiting distribution tells us that θ̂ ∼ N (θ∗ , D−1 WD−1 /N ).
a

10.5. SIMULATION-BASED ESTIMATORS

285

We can now observe the properties of the estimator. The asymptotic distribution of θ̂ is centered on the true value and its variance
decreases as sample size rises. As a result, θ̂ converges in probability
p
to θ∗ as sample rise rises without bound: θ̂ → θ. The estimator is
therefore consistent. The estimator is asymptotically normal. And
its variance is D−1 WD−1 /N which can be compared with the lowest
possible variance, −H−1 /N , to determine whether it is eﬃcient.
For ML, gn (·) is the score, such that the variance of gn (θ∗ ) is the
variance of the scores: W = V. Also, the mean derivative of gn (θ∗ )
is the mean derivative of the scores: D = H = E(∂ 2 lnPn (θ∗ )/∂θ∂θ )
where the expectation is over the population. By the information identity, V = −H. The asymptotic variance of θ̂ becomes D−1 WD−1 /N =
H−1 VH−1 /N = H−1 (−H)H−1 /N = −H−1 /N , which is the lowest
possible variance of any estimator. ML is therefore eﬃcient. Since
V = −H, the variance of the ML estimator can also expressed as
V−1 /N , which has a readily interpretable meaning: the variance of
the estimator is equal to the variance of the scores evaluated at the
true parameters, divided by sample size.
For MOM, gn (·) is a set of moments. If the ideal instruments are
used, then MOM becomes ML and is eﬃcient. If any other instruments are used, then MOM is not ML. In this case, W is the population variance of the moments and D is the mean derivatives of the
moments, rather than the variance and mean derivatives of the scores.
The asymptotic variance of θ̂ does not equal −H−1 /N . MOM without
ideal weights is therefore not eﬃcient.

10.5

Properties of simulation-based estimators

Suppose that the terms that enter the deﬁning equation for an estimator are simulated rather than calculated exactly. Let ǧn (θ) denote the
simulated value of gn (θ) and ǧ(θ) the sample mean of these simulated
values, such that ǧ(θ) is the simulated version of g(θ). Denote the
number of draws used in simulation for each n as R, and assume that
independent draws are used for each n (e.g., separate draws are taken
for each n.) Assume further that the same draws are used for each
value of θ when calculating ǧn (θ). This procedure prevents “chatter”
in the simulation, such that the diﬀerence between ǧ(θ1 ) and ǧ(θ2 ) for
two diﬀerent values of θ is not due to diﬀerent draws.
These assumptions on the simulation draws are easy for the re-

286

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

searcher to implement and simplify our analysis considerably. For interested readers, Lee (1992) examines the situation when the same
draws are used for all observations. Pakes and Pollard (1989) provide
a way to characterize an equicontinuity condition that, when satisﬁed,
facilitates analysis of simulation-based estimators. McFadden (1989)
characterizes this condition in a diﬀerent way and shows that it can be
met by using the same draws for each value of θ, which is the assumption that we make. McFadden (1996) provides a helpful synthesis that
includes a discussion of the need to prevent chatter.
The estimator is deﬁned by the condition ǧ(θ̂) = 0. We derive the
properties of θ̂ in the same two steps as for the traditional estimators.
Step 1: The distribution of ǧ(θ∗ ).
To identify the various components of this distribution, let us reexpress ǧ(θ∗ ) by adding and subtracting some terms and rearranging:
ǧ(θ∗ ) = ǧ(θ∗ ) + g(θ∗ ) − g(θ∗ ) + Er ǧ(θ∗ ) − Er ǧ(θ∗ )
= g(θ∗ ) + [Er ǧ(θ∗ ) − g(θ∗ )] + [ǧ(θ∗ ) − Er ǧ(θ∗ )]
where g(θ∗ ) is the non-simulated value and Er ǧ(θ∗ ) is the expectation
of the simulated value over the draws used in the simulation. Adding
and subtracting terms obviously does not change ǧ(θ∗ ). Yet, the subsequent rearrangement of the terms allows us to identify components
that have intuitive meaning.
The ﬁrst term g(θ∗ ) is the same as arises for the traditional estimator. The other two terms are extra elements that arise because of the
simulation. The term Er ǧ(θ∗ ) − g(θ∗ ) captures the bias, if any, in the
simulator of g(θ∗ ). It is the diﬀerence between the true value of g(θ∗ )
and the expectation of the simulated value. If the simulator is unbiased for g(θ∗ ), then Er ǧ(θ∗ ) = g(θ∗ ) and this term drops out. Often,
however, the simulator will not be unbiased for g(θ∗ ). For example,
with MSL, ǧn (θ) = ∂lnP̌n (θ)/∂θ where P̌n (θ) is an unbiased simulator
of Pn (θ). Since P̌n (θ) enters nonlinearly via the log operator, ǧn (θ) is
not unbiased. The third term, ǧ(θ∗ ) − Er ǧ(θ∗ ), captures simulation
noise, that is, the deviation of the simulator for given draws from its
expectation over all possible draws.
Combining these concepts, we have
ǧ(θ) = A + B + C,

(10.6)

10.5. SIMULATION-BASED ESTIMATORS

287

where
A

is

the same as in the traditional estimator,

B

is

simulation bias,

C

is

simulation noise.

To see how the simulation-based estimators diﬀer from their traditional
counterparts, we examine the simulation bias B and noise C.
Consider ﬁrst the noise. This term can be re-expressed as:
C = ǧ(θ∗ ) − Er ǧ(θ∗ )
1
ǧn (θ∗ ) − Er ǧn (θ∗ )
=
N n
=

dn /N
n

where dn is the deviation of the simulated value for observation n from
its expectation. The key to understanding the behavior of the simulation noise comes in noting that dn is simply a statistic for observation
n. The sample constitutes N draws of this statistic, one for each observation: dn ∀n = 1, . . . , N . The simulation noise C is the average
of these N draws. As such, the central limit theorem gives us the
distribution of C.
In particular: For a given observation, the draws that are used
in simulation provide a particular value of dn . If diﬀerent draws had
been obtained, then a diﬀerent value of dn would have been obtained.
There is a distribution of values of dn over the possible realizations of
the draws used in simulation. The distribution has zero mean, since
the expectation over draws is subtracted out when creating dn . Label
the variance of the distribution as Sn /R, where Sn is the variance when
one draw is used in simulation. There are two things to note about
this variance. First, Sn /R is inversely related to R, the number of
draws that are used in simulation. Second, the variance is diﬀerent for
diﬀerent n. Since gn (θ∗ ) is diﬀerent for diﬀerent n, the variance of the
simulation deviation also diﬀers.
We take a draw of dn for each of N observations; the overall simulation noise, C, is the average of these N draws of observation-speciﬁc
simulation noise. As just stated, each dn is a draw from a distribution
with zero mean and variance Sn /R. The generalized version of the central limit theorem tells us the distribution of a sample average of draws

288

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

from distributions that have the same mean but diﬀerent variances. In
our case,
√
d
N C → N (0, S/R)
a

where S is the population mean of Sn . Then C ∼ N (0, S/N R).
The most relevant characteristic of the asymptotic distribution of
C is that it decreases as N increases, even when R is ﬁxed. Simulation noise disappears as sample size increases, even without increasing
the number of draws used in simulation. This is a very important
and powerful fact. It means that increasing the sample size is a way
to decrease the eﬀects of simulation on the estimator. The result is
intuitively meaningful. Essentially, simulation noise cancels out over
observations. The simulation for one observation might, by chance,
make that observation’s ǧn (θ) too large. However, the simulation for
another observation is likely, by chance, to be too small. By averaging
the simulations over observations, the errors tend to cancel each other.
As sample size rises, this canceling out property becomes more powerful until, with large enough samples, simulation noise is negligible.
Consider now the bias. If the simulator ǧ(θ) is unbiased for g(θ),
then the bias term B in (10.6) is zero. However, if the simulator is
biased, as with MSL, then the eﬀect of this bias on the distribution of
ǧ(θ∗ ) must be considered.
Usually, the deﬁning term gn (θ) is a function of a statistic, n ,
that can be simulated without bias. For example, with MSL, gn (θ) is
a function of the choice probability, which can be simulated without
bias; in this case n is the probability. More generally, n can be
any statistic that is simulated without bias and serves to deﬁne gn (θ).
We can write the dependence in general as gn (θ) = g( n (θ)) and the
unbiased simulator of n (θ) as ˇn (θ) where Er ˇn (θ) = n (θ).
We can now re-express ǧn (θ) by taking a Taylor’s expansion around
the unsimulated value gn (θ):
ǧn (θ) = gn (θ) +

∂g( n (θ)) ˇ
1 ∂ 2 g( n (θ)) ˇ
[ n (θ) − n (θ)] +
[ n (θ) − n (θ]2
∂ n
2
∂ 2n

1
ǧn (θ) − gn (θ) = gn [ ˇn (θ) − n (θ)] + gn [ ˇn (θ) − n (θ)]2 .
2
where gn and gn are simply shorthand ways to denote the ﬁrst and
second derivatives of gn ( (·)) with respect to . Since ˇn (θ) is unbiased

10.5. SIMULATION-BASED ESTIMATORS

289

for n (θ), we know Er gn [ ˇn (θ) − n (θ)] = gn [Er ˇn (θ) − n (θ)] = 0. As
a result, only the variance term remains in the expectation:
Er ǧn (θ) − gn (θ) =
=

1 
g Er [ ˇn (θ) − n (θ)]2
2 n
1 
g V arr ˇn (θ).
2 n

Denote V arr ˇn (θ) = Qn /R to reﬂect the fact that the variance is
inversely proportional to the number of draws used in the simulation.
The simulation bias is then
Er ǧ(θ) − g(θ) =
=
=

1
N
1
N
Z
R

Er ǧn (θ) − gn (θ)
n

gn
n

Qn
2R

where Z is the sample average of gn Qn /2.
Since B = Z/R, the value of this statistic normalized for sample
size is:
√
√
N
Z.
(10.7)
NB =
R
√
If R is ﬁxed, then B is non-zero. Even worse, N B rises with N ,
such that it has no limiting value. Suppose that R is considered to rise
p
with N . The bias term then disappears asymptotically: B = Z/R →
0. However,
the normalized bias term does not
√ necessarily
√ disappear.
√
p
of
this
term,
N
B
=
(
N /R)Z → 0
Since N enters the numerator
√
√
only if R rises faster than N , such that the
√ ratio N /R√approaches
zero as N increases. If R rises slower than N , the ratio N /R rises,
such that the normalized bias term does not disappear but in fact gets
larger and larger as sample size increases.
We can now collect our results for the distribution of the deﬁning
term normalized by sample size:
√
√
N ǧ(θ∗ ) = N (A + B + C),
(10.8)
where
√
d
N A → N (0, W), the same as in the traditional estimator,

290
√

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION
√

N
Z, capturing simulation bias,
NB =
R
√
d
N C → N (0, S/R), capturing simulation noise.

Step 2: Derive distribution of θ̂ from distribution of ǧ(θ∗ ).
As with the traditional estimators, the distribution of θ̂ is directly
related to the distribution of ǧ(θ∗ ). Using the same Taylor’s expansion
as in (10.3), we have
√
√
√
N (θ̂ − θ∗ ) = −Ď−1 N ǧ(θ∗ ) = −Ď−1 N (A + B + C)(10.9)
where Ď is the derivative of ǧ(θ∗ ) with respect to the parameters, which
converges to its expectation Ď as sample size rises. The estimator itself
is expressed as
(10.10)
θ̂ = θ∗ − Ď−1 (A + B + C)
We can now examine the properties of our estimators.

10.5.1

Maximum simulated likelihood

For MSL, √
ǧn (θ) is not unbiased for gn (θ). The bias term in (10.9) is
√
√N B = ( N /R)Z. Suppose R rises with N . If R rises faster than
N , then
√
√
p
N B = ( N /R)Z → 0,
√
since the ratio N /R falls to zero. Consider now the third term in
√
d
(10.9), which captures simulation noise: N C → N (0, S/R). Since
p
S/R decreases as R rises, we have S/R → 0 as N → ∞ when R rises
with N . The second and third terms disappear, leaving only the ﬁrst
term. This ﬁrst term is the same as appears for the non-simulated
estimator. We have:
√
√
d
N (θ̂ − θ∗ ) = −D−1 N A → N (0, D−1 WD−1 )
=

N (0, H−1 VH−1 )

=

N (0, −H−1 )

where the next to last equality occurs because gn (θ) is the score, and
the last equality is due to the information identity. The estimator is
distributed
a
θ̂ ∼ N (θ∗ , −H−1 /N ).

10.5. SIMULATION-BASED ESTIMATORS

291

This is√the same asymptotic distribution as ML. When R rises faster
than N , MSL is consistent, asymptotically normal and eﬃcient,
asymptotically equivalent to ML.
√
Suppose that R rises
√ with N but at a rate that is slower than N .
larger as N rises. There
In this case, the ratio
√ N /R grows
√ is no limit∗
ing distribution for N (θ̂ − θ ) because the bias term, ( N /R)Z rises
with N . However, the estimator itself √
converges on the true value. θ̂
depends on (1/R)Z, not multiplied by N . This bias term disappears
when R rises at any rate. Therefore, the estimator converges on the
true value, just like its non-simulated counterpart, which means that
θ̂ is consistent.
However, the estimator is not asymptotically normal
√
since N (θ̂ − θ∗ ) has no limiting distribution. Standard errors cannot
be calculated, and conﬁdence intervals cannot
√be constructed.
When R is ﬁxed, the bias rises as N rises. N (θ̂−θ∗ ) does not have
a limiting distribution. Moreover, the estimator itself, θ̂, contains bias
B = (1/R)Z that does not disappear as sample size rises with ﬁxed
R. The MSL estimator is neither consistent nor asymptotically normal
when R is ﬁxed.
The properties of MSL can be summarized as follows:
1. If R is ﬁxed, MSL is inconsistent.
√
2. If R rises slower than N , MSL is consistent but not asymptotically normal.
√
3. If R rises faster than N , MSL is consistent, asymptotically
normal and eﬃcient, equivalent to ML.

10.5.2

Method of simulated moments


For MSM with ﬁxed instruments, ǧn (θ) = j [dnj − P̌nj (θ)]znj , which
is unbiased for gn (θ) since the simulated probability enters linearly.
The bias term is zero. The distribution of the estimator is determined
only by term A, which is the same as in the traditional MOM without
simulation, and term C, which reﬂects simulation noise:
√
√
N (θ̂ − θ∗ ) = −Ď−1 N (A + C).
Suppose that R is ﬁxed. Since Ď converges to its expectation D, we
√
√
d
d
have − N Ď−1 A → N (0, D−1 WD−1 ) and − N Ď−1 C → N (0, D−1 (S/R)D−1 ),
such that
√
d
N (θ̂ − θ∗ ) → N (0, D−1 [W + S/R]D−1 ).

292

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

The asymptotic distribution of the estimator is then
θ̂ ∼ N (θ∗ , D−1 [W + S/R]D−1 /N ).
a

The estimator is consistent and asymptotically normal. Its variance is
greater than its non-simulated counterpart by D−1 SD−1 /RN , reﬂecting simulation noise.
Suppose now that R rises with N at any rate. The extra variance
a
due to simulation noise disappears, such that θ̂ ∼ N (θ∗ , D−1 WD−1 /N ),
the same as its non-simulated counterpart. When non-ideal instruments are used, D−1 WD−1 = −H−1 and so the estimator (in either
its simulated or non-simulated form) is less eﬃcient than ML.
If simulated instruments are used in MSM, then the properties
of the estimator depend on how the instruments are simulated. If the
instruments are simulated without bias and independently of the probability that enters the residual, then this MSM has the same properties
as MSM with ﬁxed weights. If the instruments are simulated with bias
and the instruments are not ideal, then the estimator has the same
properties as MSL except that it is not asymptotically eﬃcient since
the information identity does not apply. MSM with simulated ideal
instruments is MSS, which we discuss next.

10.5.3

Method of simulated scores

With MSS using unbiased score simulators, ǧn (θ) is unbiased for gn (θ),
and, moreover, gn (θ) is the score such that the information identity applies. The analysis is the same as for MSM except that the information
identity makes the estimator eﬃcient when R rises with N . As with
MSM, we have
θ̂ ∼ N (θ∗ , D−1 [W + S/R]D−1 /N )
a

which, since gn (θ) is the score, becomes
θ̂ ∼ N (θ∗ , H−1 [V+S/R]H−1 /N ) = N (θ∗ , −H−1 /N +H−1 SH−1 /RN )
a

When R is ﬁxed, the estimator is consistent and asymptotically normal,
but its covariance is larger than with ML because of simulation noise.
If R rises at any rate with N , then we have
θ̂ ∼ N (0, −H−1 /N ).
a

10.6. NUMERICAL SOLUTION

293

MSS with unbiased score simulators is asymptotically equivalent to
ML when R rises at any rate with N .
This analysis shows that MSS with unbiased score simulators has
better properties than MSL in two regards. First, for ﬁxed R, MSS is
consistent and asymptotically normal while MSL is neither. Second,
for R rising with N , MSS is equivalent to ML no matter how fast R
is
√ rising, while MSL is equivalent to ML only if the rate is faster than
N.
As we discussed in section (10.2.3), ﬁnding unbiased score simulators with good numerical properties is diﬃcult. MSS is sometimes
applied with biased score simulators. In this case, the properties of
the estimator are the same as MSL: the bias in the simulated scores
translates into bias in the estimator which
√ disappears from the limiting
distribution only if R rises faster than N .

10.6

Numerical Solution

The estimators are deﬁned as the value of θ that solves ǧ(θ) = 0,

where ǧ(θ) = n ǧn (θ)/N is the sample average of a simulated statistic
ǧn (θ). Since ǧn (θ) is a vector, we need to solve the set of equations for
the parameters. The question arises: how are these equations solved
numerically to obtain the estimates?
Chapter 8 describes numerical methods for maximizing a function.
These procedures can also be used for solving a set of equations. Let T
be the negative of the inner product of the deﬁning term for an estima

tor: T = −ǧ(θ) ǧ(θ) = −( n ǧn (θ)) ( n ǧn (θ))/N 2 . T is necessarily
less than or equal to zero, since T is the negative of a sum of squares.
T has a highest value of 0, which is attained only when the squared
terms that compose it are all 0. That is, the maximum of T is attained
when ǧ(θ) = 0. Maximizing T is equivalent to solving the equation
ǧ(θ) = 0. The approaches described in Chapter 8, with the exception
of BHHH, can be used for this maximization. BHHH cannot be used
because that method assumes that the function being maximized is a
sum of observation-speciﬁc terms, whereas T takes the square of each
sum of observation-speciﬁc terms. The other approaches, especially
BFGS and DFP, have proven very eﬀective at locating the parameters
at which ǧ(θ) = 0.
With MSL, it is usually easier to maximize the simulated likelihood
function rather than T . BHHH can be used in this case, as well as the

294

CHAPTER 10. SIMULATION-ASSISTED ESTIMATION

other methods.

Chapter 11

Individual-Level
Parameters
11.1

Introduction

Mixed logit and probit models allow random coeﬃcients whose distribution in the population is estimated. Consider, for example, the
model in Chapter 6, of angler’s choice among ﬁshing sites. The sites are
diﬀerentiated on the basis of whether campgrounds are available at the
site. Some anglers like having campgrounds at the ﬁshing sites since
they can use the grounds for overnight stays. Other anglers dislike
the crowds and noise that are associated with campgrounds and prefer
ﬁshing at more isolated spots. To capture these diﬀerences in tastes, a
mixed logit model was speciﬁed that included random coeﬃcients for
the campground variable and other site attributes. The distribution
of coeﬃcients in the population was estimated. Figure 11.1 gives the
estimated distribution of the campground coeﬃcient. The distribution
was speciﬁed to be normal. The mean was estimated as 0.116, and the
standard deviation was estimated as 1.655. This distribution provides
useful information about the population. For example, the estimates
imply that 47 percent of the population dislike having campgrounds
at their ﬁshing sites, while the other 53 percent like having them.
The question arises: where in the distribution of tastes does a
particular angler lie? Is there a way to determine whether a given
person tends to like or dislike having campgrounds at ﬁshing sites?
A person’s choices reﬂect their own tastes. Stated in reverse, a person’s choices reveal something about their tastes, which the researcher
295

296

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

st. dev.
= 1.655

0

mean
= 0.116

Figure 11.1: Distribution of coeﬃcient of campgrounds in population
of all anglers.
can, in principle, discover. If the researcher observes that a particular
angler consistently chooses sites without campgrounds, even when the
cost of driving to these sites is higher, then the researcher can reasonably infer that this angler dislikes campgrounds. There is a precise
way for performing this type of inference, given by Revelt and Train
(2000).
We explain the procedure in the context of a mixed logit model;
however, any behavioral model that incorporates random coeﬃcients
can be used, including probit. The central concept is a distinction
between two distributions: the distribution of tastes in the population,
and the distribution of tastes in the subpopulation of people who make
particular choices. Denote the random coeﬃcients as vector β. The
distribution of β in the population of all people is denoted g(β | θ)
where θ is the parameters of this distribution, such as the mean and
variance.
A choice situation consists of several alternatives described collectively by variables x. Consider the following thought experiment.
Suppose everyone in the population faced the same choice situation described by the same variables x. Some portion of the population will
choose each alternative. Consider the people who choose alternative i.
The tastes of these people are not all the same: there is a distribution
of coeﬃcients among these people. Let h(β | i, x, θ) denote the distribution of β in the subpopulation of people who, when faced with the

11.1. INTRODUCTION

297

choice situation described by variables x, would choose alternative i.
g(β | θ) is the distribution of β in the entire population. h(β |
i, x, θ) is the distribution of β in the subpopulation of people who
would choose alternative i when facing a choice situation described by
x.
We can generalize the notation to allow for repeated choices. Let y
denote a sequence of choices in a series of situations described collectively by variables x. The distribution of coeﬃcients in the subpopulation of people who would make the sequences of choices y when facing
situations described by x is denoted h(β | y, x, θ).
Note that h(·) conditions on y, while g(·) does not. It is sometimes
useful to call h the conditional distribution and g the unconditional
distribution. Two such distributions are depicted in Figure 11.2. If we
knew nothing about a person’s past choices, then the best we could do
in describing the person’s tastes is to say that the person’s coeﬃcients
lie somewhere in g(β | θ). However, if we have observed that the person
made choices y when facing situations described by x, then we know
that that person’s coeﬃcients are in distribution h(β | y, x, θ). Since h
is tighter than g, we have better information about the person’s tastes
by conditioning on their past choices.
h

g

0

Figure 11.2: Unconditional (population) distribution g and condition
(subpopulation) distribution h for subpopulation of anglers who chose
sites without campgrounds.
Inference of this form has long been conducted with linear regres-

298

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

sion models, where the dependent variable and the distribution of coeﬃcients are both continuous (Griﬃths, 1972; Judge, Hill, Griﬃths,
Lutkepohl and Lee, 1988). Regime-switching models, particularly in
macroeconomics, have used an analogous procedure to assess the probability that an observation is within a given regime (Hamilton and Susmel, 1994; Hamilton, 1996). In these models, the dependent variable is
continuous and the distribution of coeﬃcients is discrete (representing
one set of coeﬃcients for each regime.) In contrast to both of these
traditions, our models have discrete dependent variables. DeSarbo,
Ramaswamy and Cohen (1995) developed an approach in the context
of a discrete choice model with a discrete distribution of coeﬃcients
(that is, a latent class model). They used maximum likelihood procedures to estimate the coeﬃcients for each segment, and then calculated
the probability that an observation is within each segment based on
the observed choices of the observation. The approach that we describe
here applies to discrete choice models with continuous or discrete distributions of coeﬃcients and uses maximum likelihood (or other classical
methods) for estimation. The model of DeSarbo et al. (1995) is a special case of this more general method. Bayesian procedures have been
also developed to perform this inference within discrete choice models
(Rossi, McCulloch and Allenby, 1996; Allenby and Rossi, 1999). We
describe the Bayesian methods in Chapter 12.

11.2

Derivation of conditional distribution

The relation between h and g can be established precisely. Consider a
choice among alternatives j = 1, . . . , J in choice situations t = 1, . . . , T .
The utility that person n obtains from alternative j in situation t is
Unjt = βn xnjt + εnjt
where εnjt ∼ iid extreme value, and βn ∼ g(β | θ) in the population.
The variables xnjt can be denoted collectively for all alternatives and
choice situations as xn . Let yn = yn1 , . . . , ynT  denote the person’s
sequence of chosen alternatives. If we knew βn , then the probability
of the person’s sequence of choices would be a product of logits:
T

P (yn | xn , β) =

Lnt (ynt | β)
t=1

11.2. DERIVATION OF CONDITIONAL DISTRIBUTION
where

299



eβ xnynt t
Lnt (ynt | β) =  β  x .
njt
je
Since we do not know βn , the probability of the person’s sequence of
choices is the integral of P (yn | xn , β) over the distribution of β:
P (yn | xn , θ) =



P (yn | xn , β)g(β | θ)dβ.

(11.1)

This is the mixed logit probability that we discussed in Chapter 6.
We can now derive h(β | yn , xn , θ). By Bayes’ rule,
h(β | yn , xn , θ) × P (yn | xn , θ) = P (yn | xn , β) × g(β | θ).
This equation simply states that the joint density of β and yn can be
expressed as the probability of yn times the probability of β conditional
on yn (which is the left hand side), or with the other direction of conditioning, as the probability of β times the probability of yn conditional
on β (which is the right hand side.) Rearranging:
h(β | yn , xn , θ) =

P (yn | xn , β)g(β | θ)
.
P (yn | xn , θ)

(11.2)

We know all the terms on the right hand side. From these, we can
calculate h.
Equation (11.2) also provides a way to interpret h intuitively. Note
that the denominator P (yn | xn , θ) is the integral of the numerator,
as given by the deﬁnition in (11.1). As such, the denominator is a
constant that makes h integrate to 1, as required for any density. Since
the denominator is a constant, h is proportional to the numerator,
P (yn | xn , β)g(β | yn , xn , θ). This relation makes interpretation of h
relatively easy. Stated in words: the density of β in the subpopulation
of people who would choose sequence yn when facing xn is proportional
to the density of β in the entire population times the probability that
yn would be chosen if the person’s coeﬃcients were β.
Using (11.2), various statistics can be derived conditional on yn .
The mean β in the subpopulation of people who would choose yn when
facing xn is

β̄n =

β · h(β | yn , xn , θ)dβ.

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

300

This mean generally diﬀers from the mean β in the entire population.
Substituting the formula for h,


β̄n =
=

β · P (yn | xn , β)g(β | θ)dβ
P (yn | xn , θ)

β · P (yn | xn , β)g(β | θ)dβ

P (yn | xn , β)g(β | θ)dβ

(11.3)

The integrals in this equation do not have a closed form; however,
they can be readily simulated. Take draws of β from the population
density g(β | θ). Calculate the weighted average of these draws, with
the weight for draw β r being proportional to P (yn | xn , β r ). The
simulated subpopulation mean is
wr β r

β̌n =
r

where the weights are
P (yn | xn , β r )
.
wr = 
r
r P (yn | xn , β )

(11.4)

Other statistics can also be calculated. Suppose the person faces
a new choice situation described by variables xnjT +1 ∀j. If we had
no information on the person’s past choices, then we would assign the
following probability to his choosing alternative i:
P (i | xnT +1 , θ) =
where



LnT +1 (i | β)g(β | θ)dβ

(11.5)



eβ xniT +1
.
LnT +1 (i | β) =  β  x
njT +1
je

This is just the mixed logit probability using the population distribution of β. If we observed the past choices of the person, then the
probability can be conditioned on these choices. The probability becomes:
P (i | xnT +1 , yn , xn , θ) =



LnT +1 (i | β)h(β | yn , xn , θ)dβ.

(11.6)

This is also a mixed logit probability, but using the conditional distribution h instead of the unconditional distribution g. When we do

11.3. IMPLICATIONS OF ESTIMATION OF θ

301

not know the person’s previous choices, we mix the logit formula over
density of β in the entire population. However, when we know the
person’s previous choices, we can improve our prediction by mixing
over the density of β in the subpopulation who would have made the
same choices as this person.
To calculate this probability, we substitute the formula for h from
(11.2):


P (i | xnT +1 , yn , xn , θ) =

LnT +1 (i | β)P (yn | xn , β)g(β | θ)dβ

.
P (yn | xn , β)g(β | θ)dβ

The probability is simulated by taking draws of β from the population
distribution g, calculating the logit formula for each draw, and taking
a weighted average of the results:
wr LnT +1 (i | β r )

P̌niT +1 (yn , xn , θ) =
r

where the weights are given by (11.4).

11.3

Implications of estimation of θ

The population parameters θ are estimated in any of the ways described in Chapter 10. The most common approach is maximum simulated likelihood, with the simulated value of P (yn | xn , θ) entering the
log-likelihood function. An estimate of θ, labeled θ̂, is obtained. We
know that there is sampling variance in the estimator. The asymptotic
covariance of the estimator is also estimated, which we label Ŵ . The
asymptotic distribution is therefore estimated to be N (θ̂, Ŵ ).
The parameter θ describes the distribution of β in the population,
giving, for example, the mean and variance of β over all decisionmakers. For any value of θ, equation (11.2) gives the conditional distribution of β in the subpopulation of people who would make choices
yn when faced with situations described by xn . This relation is exact in the sense that there is no sampling or other variance associated
with it. Similarly, any statistic based on h is exact given a value of θ.
For example, the mean of the conditional distribution, β̄n , is exactly
equation (11.3) for a given value of θ.
Given this correspondence between θ and h, the fact that θ is estimated can be handled in two diﬀerent ways. The ﬁrst approach is
to use the point estimate of θ to calculate statistics associated with

302

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

the conditional distribution h. Under this approach, the mean of the
condition distribution, β̄n , is calculated by inserting θ̂ into (11.3). The
probability in a new choice situation is calculated by inserting θ̂ into
(11.6). If the estimator of θ is consistent, then this approach is consistent for statistics based on θ.
The second approach is to take the sampling distribution of θ̂ into
consideration. Each possible value of θ implies a value of h, and hence
a value of any statistic associated with h, such as β̄n . The sampling
variance in the estimator of θ induces sampling variance in the statistics
that are calculated on the basis of θ. This sampling variance can be
calculated through simulation, by taking draws of θ from its estimated
sampling distribution and calculating the corresponding statistic for
each of these draws.
For example, to represent the sampling distribution of θ̂ in the
calculation of β̄n , the following steps are taken.
1. Take a draw from N (θ̂, Ŵ ), which is the estimated sampling
distribution of θ̂. This step is accomplished as follows. Take
K draws from a standard normal density and label the vector
of these draws η r , where K is the length of θ. Then create
θr = θ̂ + Lη r , where L is the Choleski factor of Ŵ .
2. Calculate β̄nr based on this θr . Since the formula for β̄n involves
integration, we simulate it using formula (11.3).
3. Repeat steps 1 and 2 many times, with the number of times
labeled R.
The resulting values are draws from the sampling distribution of β̄n
induced by the sampling distribution of θ̂. The average of β̄nr over the
R draws of θr is the mean of the sampling distribution of β̄n . The
standard deviation of the draws gives the asymptotic standard error
of β̄n that is induced by the sampling variance of θ̂.
Note that this process involves simulation within simulation. For
each draw of θr , the statistic β̄nr is simulated with multiple draws of β
from the population density g(β | θr ).
Suppose either of these approaches is used to estimate β̄n . The
question arises: can the estimate of β̄n be considered an estimate of
βn ? That is: is the estimated mean of the conditional distribution
h(β | yn , xn , θ), which is conditioned on person n’s past choices, an
estimate of person n’s coeﬃcients?

11.3. IMPLICATIONS OF ESTIMATION OF θ

303

There are two possible answers, depending on how the researcher
views the data generation process. If the number of choice situations
that the researcher can observe for each decision-maker is ﬁxed, then
the estimate of β̄n is not a consistent estimate of βn . When T is ﬁxed,
consistency requires that the estimate converge to the true value when
sample size rises without bound. If sample size rises, but the choice
situations faced by person n is ﬁxed, then the conditional distribution
and its mean does not change. Insofar as person n’s coeﬃcients do
not happen to coincide with the mean of the conditional distribution
(a essentially impossible event), the mean of the conditional distribution will never equal the person’s coeﬃcients no matter how large the
sample is. Raising sample size improves the estimate of θ and hence
provides a better estimate of the mean of the conditional distribution,
since this mean depends only on θ. However, raising sample size does
not make the conditional mean equal to the person’s coeﬃcients.
When the number of choice situations is ﬁxed, then the conditional
mean has the same interpretation as the population mean, but for a
diﬀerent, and less diverse, group of people. When predicting the future
behavior of the person, one can expect to obtain better predictions
using the conditional distribution, as in (11.6), than the population
distribution. In the case study presented below, we show that the
improvement can be large.
If the number of choice situations that a person faces can be considered to rise, then the estimate of β̄n can be considered to be an
estimate of βn . Let T be the number of choice situations that person n
faces. If we observe more choices by the person (i.e., T rises), then we
are better able to identify the person’s coeﬃcients. Figure 11.3 gives
the conditional distribution h(β | yn , xn , θ) for three diﬀerent values
of T . The conditional distribution tends to move toward the person’s
own βn as T rises, and to become more concentrated. As T rises without bound, the conditional distribution collapses onto βn . The mean
of the conditional distribution converges to the true value of βn as the
number of choice situations rises without bound. The estimate of β̄n
is therefore consistent for βn .
In Chapter 12, we describe the Bernstein-von Mises theorem. This
theorem states that, under fairly mild conditions, the mean of a posterior distribution for a parameter is asymptotically equivalent to the
maximum of the likelihood function. The conditional distribution h
is a posterior distribution: by (11.2) h is proportional to a density g,

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

304

g with ten
observed choices
g with one
observed choice

g=h with no
observed choices

Figure 11.3: Conditional distribution with T = 0, 1, and 10.
which can be interpreted as a prior distribution on βn , times the likelihood of person n’s T choices given βn , which is P (yn | xn , βn ). By the
Bernstein-von Mises theorem, the mean of h is therefore an estimator
of βn that is asymptotically equivalent to the maximum likelihood estimator of βn , where the asymptotics are deﬁned as T rising. These
concepts are described more fully in Chapter 12; we mention them now
simply to provide another interpretation of the mean of the conditional
distribution.

11.4

Monte Carlo illustration

To illustrate the concepts, I constructed a hypothetical data set where
the true population parameters θ are known as well as the true βn for
each decision-maker. These data allow us to compare the mean of the
conditional distribution for each decision-maker’s choices, β̄n , with the
βn for that decision-maker. It also allows us to investigate the impact
of increasing the number of choice situations on the conditional distribution. For this experiment, I constructed data sets consisting of 300
“customers” each facing T =1, 10, 20, and 50 choice situations. There
are three alternatives and four variables in each data set. The coeﬃ-

11.4. MONTE CARLO ILLUSTRATION

305

cients for the ﬁrst two variables are held ﬁxed for the entire population
at 1.0, and the coeﬃcients for the last two variables are distributed
normal with a mean and variance of 1.0. Utility is speciﬁed to include
these variables plus a ﬁnal iid term that is distributed extreme value,
such that the model is a mixed logit. The dependent variable for each
customer was created by taking a draw from the density of the random
terms, calculating the utility of each alternative with this draw, and
determining which alternative had the highest utility. To minimize
the eﬀect of simulation noise in the creation of the data, I constructed
50 datasets for each level of T . The results that are reported are the
average over these 50 datasets.
The mean of the conditional distribution for each customer, β̄n ,
was calculated. The standard deviation of β̄n over the 300 customers
was calculated, as well as the average absolute deviation of β̄n from
the customer’s βn (i.e., the average over n of | β̄n − βn |). Table
11.1 presents these statistics. Consider ﬁrst the standard deviation. If
there were no observed choice situations on which to condition (T =
0), then the conditional distribution for each customer would be the
unconditional (population) distribution. Each customer would have
the same β̄n equal to the population mean of β. In this case, the
standard deviation of β̄n would be zero, since all customers have the
same β̄n . At the other extreme, if we observed an unboundedly large
number of choice situations (T → ∞), then the conditional distribution
for each customer would collapse to their own βn . In this case, the
standard deviation of β̄n would equal the standard deviation of the
population distribution of βn , which is 1 in this experiment. For T
between 0 and ∞, the standard deviation of β̄n is between 0 and the
standard deviation of βn in the population.
In Table 11.1, we see that conditioning on only a few choice situations captures a large share of the variation in β’s over customers.
With only one choice situation, the standard deviation of β̄n is over
.4. Since the standard deviation of βn in the population is 1 in this
experiment, this result means that conditioning on one choice situation
captures over 40 percent of the variation in βn . With 10 choices situations, over 80 percent of the variation is captured. There are strongly
decreasing return to observing more choice situations. Doubling from
T = 10 to T = 20 only increases the percent of variation captured from
about .83 to about .89. Increasing T to 50 raises the percent to about
.95.

306

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

Table 11.1: Monte Carlo Illustration
1 choice situation
Standard deviation of β̄n
Absolute diﬀerence between β̄n and βn
10 choice situation
Standard deviation of β̄n
Absolute diﬀerence between β̄n and βn
20 choice situation
Standard deviation of β̄n
Absolute diﬀerence between β̄n and βn
50 choice situation
Standard deviation of β̄n
Absolute diﬀerence between β̄n and βn

1st coef.

2nd coef.

0.413
0.726

0.416
0.718

0.826
0.422

0.826
0.448

0.894
0.354

0.886
0.350

0.951
0.243

0.953
0.243

Consider now the absolute diﬀerence between the mean of the customer’s conditional distribution, β̄n , and the customer’s actual βn .
With no conditioning (T = 0), the average absolute diﬀerence would
be 0.8, which is the expected absolute diﬀerence for deviates that follow
a standard normal as we have in our experiment. With perfect conditioning (T → ∞), β̄n = βn for each customer, and so the absolute
diﬀerence is 0. With only one choice situation, the average absolute
deviation drops from 0.8 (without conditioning) to about 0.72, for a
10 percent improvement. The absolute deviation drops further as the
number of choice situations rises.
Notice that the drop in the absolute deviation is smaller than the
increase in the standard deviation. For example, with one choice situation the absolute deviation moves 10 percent of the way from no
conditioning to perfect knowledge (from .80 with T = 0 to .72 with
T = 1, which is 10 percent of the way to 0 with T → ∞). Yet the
standard deviation moves about 40 percent of the way from no conditioning to perfect knowledge (.4 with T = 1 is 40 percent of the
distance from 0 with T = 0 to 1 with T → ∞). This diﬀerence is due
to the fact that the standard deviation incorporates movement of β̄n
away from βn as well as movement towards βn . This fact is important
to recognize when evaluating the standard deviation of β̄n in empirical applications, where the absolute diﬀerence cannot be calculated
since βn is not known. That is, the standard deviation of β̄n expressed

11.5. AVERAGE CONDITIONAL DISTRIBUTION

307

as a percent of the estimated standard deviation in the population,
is an overestimate of the amount of information that is contained in
the β̄n ’s. With ten choice situations, the average standard deviation
in β̄n is over 80 percent of the value that it would have with perfect
knowledge, and yet the absolute deviation is less than half as high as
would be attained without conditioning.

11.5

Average conditional distribution

For a correctly speciﬁed model at the true population parameters, the
conditional distribution of tastes, aggregated over all customers, equals
the population distribution of tastes. Given a series of choice situations
described by xn , there is a set of possible sequences of choices. Label
these possible sequences as ys for s = 1, . . . , S. Denote the true frequency of ys as m(ys | xn , θ∗ ), which depends on the true parameters
θ∗ . If the model is correctly speciﬁed and consistently estimated, then
P (ys | xn , θ̂) approaches m(ys | xn , θ∗ ) asymptotically. Conditional on
the explanatory variables, the expected value of h(β | ys , xn , θ̂) is then:
Ey h(β | y, xn , θ̂)

P (ys | xn , β)g(β | xn , θ̂)

=
s

→

P (ys | xn , θ̂)

m(yn | xn , θ∗ )

P (ys | xn , β)g(β | xn , θ̂)
s

=

g(β | xn , θ̂).

This relation provides a diagnostic tool (Allenby and Rossi, 1999). If
the average of the sampled customers’ conditional taste distributions
is similar to the estimated population distribution, the model is correctly speciﬁed and accurately estimated. If they are not similar, the
diﬀerence could be due to: (1) speciﬁcation error, (2) an insuﬃcient
number of draws in simulation, (3) an inadequate sample size, and/or
(4) the maximum likelihood routine converging at a local rather than
global maximum.

11.6

Case study: choice of energy supplier

Population distribution
We obtained stated-preference data on residential customers’ choice
of electricity supplier. Surveyed customers were presented with 8-12

308

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

hypothetical choice situations called experiments. In each experiment,
the customer was presented with four alternative suppliers with different prices and other characteristics. The suppliers diﬀered on the
basis of price (ﬁxed price at a given cents per kWh, time-of-day prices
with stated prices in each time period, or seasonal prices with stated
prices in each time period), the length of the contract (during which
the supplier is required to provide service at the stated price and the
customer would need to pay a penalty for leaving the supplier), and
whether the supplier was their local utility, a well-known company
other than their local utility, or an unfamiliar company. The data
were collected by Research Triangle Institute (1997) for the Electric
Power Research Institute and have been used by Goett (1998) to estimate mixed logits. We utilize a speciﬁcation similar to Goett’s, but
we eliminate or combine variables that he found to be insigniﬁcant.
Two mixed logit models were estimated on these data, based on
diﬀerent speciﬁcations for the distribution of the random coeﬃcients.
All choices except the last situation for each customer are used to estimate the parameters of the population distribution, and the customer’s
last choice situation was retained for use in comparing the predictive
ability of diﬀerent models and methods.
Table 11.2 gives the estimated population parameters. The price
coeﬃcient in both models is ﬁxed across the population such that the
distribution of willingness to pay for each non-price attribute (which
is the ratio of the attribute’s coeﬃcient to the price coeﬃcient) has
the same distribution as the attribute’s coeﬃcient. For model 1, all
of the non-price coeﬃcients are speciﬁed to be normally distributed in
the population. The mean m and standard deviation s of each coeﬃcient are estimated. For model 2, the ﬁrst three non-price coeﬃcients
are speciﬁed to be normal, and the fourth and ﬁfth are log-normal.
The fourth and ﬁfth variable are indicators of time-of-day and seasonal rates, and their coeﬃcients must logically be negative for all
customers. The log-normal distribution (with the signs of the variable
reversed) provides for this necessity. The log of these coeﬃcients is
distributed normal with mean m and standard deviation s, which are
the parameters that are estimated. The coeﬃcients themselves have
mean
exp(m + (s2 /2)) and standard deviation equal to the mean times
$
(exp(s2 ) − 1).
The estimates provide the following qualitative results:
• The average customer is willing to pay about a ﬁfth to a quarter

11.6. CASE STUDY

309

Table 11.2: Mixed logit model of energy supplier choice
Model 1
Model 2
Price, in cents per kWh
-0.8574
-0.8827
(0.0488)
(0.0497)
Contract length, in years
m
-0.1833
-0.2125
(0.0289)
(0.0261)
s
0.3786
0.3865
(0.0291)
(0.0278)
Local utility
m
2.0977
2.2297
(0.1370)
(0.1266)
s
1.5585
1.7514
(0.1264)
(0.1371)
Known company
m
1.5247
1.5906
(0.1018)
(0.0999)
s
0.9520
0.9621
(0.0998)
(0.0977)
TOD rate∗
m
-8.2857
2.1328
(0.4577)
(0.0543)
s
2.5742
0.4113
(0.1676)
(0.0397)
Seasonal rate∗
m
-8.5303
2.1577
(0.4468)
(0.0509)
s
2.1259
0.2812
(0.1604)
(0.0217)
Log-likelihood at convergence -3646.51
-3618.92
Standard errors in parentheses.
TOD rates: 11c/kWh 8am-8pm, 5c/kWh 8pm-8am
Seasonal rates: 10c/kWh summer, 8c/kWh winter, 6c/kWh spring-fall

310

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS
cent per kWh in higher price, depending on the model, in order
to have a contract that is shorter by one year. Stated conversely,
a supplier that requires customers to sign a four to ﬁve-year
contract must discount its price by one cent per kWh to attract
the average customer.

• There is considerable variation in customers’ attitudes towards
contract length, with a sizeable share of customers preferring a
longer contract to a shorter contract. A long-term contract constitutes insurance for the customer against price increases with
the supplier being locked into the stated price for the length of
the contract. Such contracts prevent the customer from taking advantage of lower prices that might arise during the term
of the contract. Apparently, many customers value the insurance against higher prices more than they mind losing the option to take advantage of potentially lower prices. The degree
of customer heterogeneity implies that the market can sustain
contracts of diﬀerent lengths with suppliers making proﬁts by
writing contracts that appeal to diﬀerent segments of the population.
• The average customer is willing to pay a whopping 2.5 cents per
kWh more for its local supplier than for an unknown supplier.
Only a small share of customers prefer an unknown supplier to
their local utility. This ﬁnding has important implications for
competition. It implies that entry in the residential market by
previously unknown suppliers will be very diﬃcult, particularly
since the price discounts that entrants can potentially oﬀer in
most markets are fairly small. The experience in California,
where only 1 percent of residential customers have switched away
from their local utility after several years of open access, is consistent with this ﬁnding.
• The average customer is willing to pay 1.8 cents per kWh for a
known supplier relative to an unknown one. The estimated values
of s imply that a sizeable share of customers would be willing to
pay more for a known supplier than for their local utility, presumably because of a bad experience or a negative attitude toward
the local energy utility. These results imply that companies that
are known to customers, such as their long distance carriers, lo-

11.6. CASE STUDY

311

cal telecommunications carriers, local cable companies, and even
retailers like Sears and Home Depot, may be successful in attracting customers for electricity supply relative to companies
that were unknown prior to their entry as an energy supplier.
• The average customer evaluates the TOD rates in a way that is
fairly consistent with time-of-day usage patterns. In model 1, the
mean coeﬃcient of the dummy variable for the TOD rates implies
that the average customer considers these rates to be equivalent
to a ﬁxed price of 9.7 cents per kWh. In model 2, the estimated
mean and standard deviation of the log of the coeﬃcient imply a
median willingness to pay of 8.4 cents and a mean of 10.4 cents,
which span the mean from model 1. 9.5 cents is the average price
that a customer would pay under the TOD rates if 75 percent
of its consumption occurred during the day (between 8AM and
8PM) and the other 25 percent occurred at night. These shares,
while perhaps slightly high for the day, are not unreasonable.
The estimated values of s are highly signiﬁcant, reﬂecting heterogeneity in usage patterns and perhaps in customers’ ability
to shift consumption in response to TOD prices. These values
are larger than reasonable implying that a non-negligible share
of customers treat the TOD prices as being equivalent to a ﬁxed
price that is higher than the highest TOD price or lower than
the lowest TOD price.
• The average customer seems to avoid seasonal rates for reasons
beyond the prices themselves. The average customers treats the
seasonal rates as being equivalent to a ﬁxed ten cents per kWh,
which is the highest seasonal price. A possible explanation for
this result relates to the seasonal variation in customers’ bills.
In many areas, electricity consumption is highest in the summer,
when air-conditioners are being run, and energy bills are therefore higher in the summer than in other seasons, even under ﬁxed
rates. The variation in bills over months without commensurate
variation in income makes it more diﬃcult for customers to pay
for their summer bills. In fact, nonpayment for most energy utilities is most frequent in the summer. Seasonal rates, which apply
the highest price in the summer, increase the seasonal variation
in bills. Customers would rationally avoid a rate plan that exacerbates an already existing diﬃculty. If this interpretation is cor-

312

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS
rect, then seasonal rates combined with bill-smoothing (by which
the supplier carries a portion of the summer bills over to the winter) could provide an attractive arrangement for customers and
suppliers alike.

Model 2 attains the a higher log-likelihood value than model 1,
presumably because the lognormal distribution assures negative coefﬁcients for the TOD and seasonal variables.

Conditional distributions
We now use the estimated models to calculate customers’ conditional
distributions and the means of these distributions. We calculate β̄n for
each customer in two ways. First, we calculate β̄n using equation (11.3)
with the point estimates of the population parameters, θ̂. Second,
we use the procedure in section (11.3) to integrate over the sampling
distribution of the estimated population parameters.
The means and standard deviations of β̄n over the sampled customers calculated by these two methods are given in Tables 11.3 and
11.4, respectively. The price coeﬃcient is not listed in Table 11.3 since
it is ﬁxed across the population. Table 11.4 incorporates the sampling
distribution of the population parameters, which includes variance in
the price coeﬃcient.
Consider the results in Table 11.3 ﬁrst. The mean of β̄n is very
close to the estimated population mean given in Table 11.2. This similarity as expected for a correctly speciﬁed and consistently estimated
model. The standard deviation of β̄n would be zero if there were no
conditioning and would equal the population standard deviation if each
customer’s coeﬃcient were known exactly. The standard deviations in
Table 11.3 are considerably above zero and are fairly close to the estimated population standard deviations in Table 11.2. For example, in
model 1, the conditional mean of the coeﬃcient of contract length has
a standard deviation of 0.318 over customers, and the point estimate
of the standard deviation in the population is 0.379. Thus, variation
in β̄n captures more than 70 percent of the total estimated variation in
this coeﬃcient. Similar results are obtained for other coeﬃcients. This
result implies that the mean of a customer’s conditional distribution
captures a fairly large share of the variation in coeﬃcients across customers and has the potential to be useful in distinguishing customers.

11.6. CASE STUDY

313

Table 11.3: Average β̄n using point estimate θ̂
Model 1
Model 2
Contract length
Mean
-0.2028
-0.2149
Std dev
0.3175
0.3262
Local utility
Mean
2.1205
2.2146
Std dev
1.2472
1.3836
Known company
Mean
1.5360
1.5997
Std dev
0.6676
0.6818
TOD rate
Mean
-8.3194
-9.2584
Std dev
2.2725
3.1051
Seasonal rate
Mean
-8.6394
-9.1344
Std dev
1.7072
2.0560

As discussed in section (11.5), a diagnostic check on the speciﬁcation and estimation of the model is obtained by comparing the sample
average of the conditional distributions with the estimated population
distribution. The means in Table 11.3 represent the means of the sample average of the conditional distributions. The standard deviation
of the sample-average conditional distribution depends on the standard deviation of β̄n which is given in Table 11.3, plus the standard
deviation of βn − β̄n . When this latter portion is added, the standard
deviation of each coeﬃcient matches very closely the estimated population standard deviation. This equivalence suggests that there is not
signiﬁcant speciﬁcation error and that the estimated population parameters are fairly accurate. This suggestion is somewhat tempered,
however, by the results in Table 11.4.
Table 11.4 gives the sample mean and standard deviation of the
mean of the sampling distribution of β̄n that is induced by the sampling distribution of θ̂. The means in Table 11.4 represent the means
of the sample average of h(β | yn , xn , θ̂) integrated over the sampling
distribution of θ̂. For model 1, a discrepancy occurs that indicates
possible misspeciﬁcation. In particular, the means of the TOD and
seasonal rates coeﬃcients in Table 11.4 exceed their estimated popula-

314

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

Table 11.4: Average β̄n with sampling dist. of θ̂
Model 1
Model 2
Price
Mean
-0.8753
-0.8836
Std dev
0.5461
0.0922
Contract length
Mean
-0.2004
-0.2111
Std dev
0.3655
0.3720
Local utility
Mean
2.1121
2.1921
Std dev
1.5312
1.6815
Known company
Mean
1.5413
1.5832
Std dev
0.9364
0.9527
TOD rate
Mean
-9.1615
-9.0216
Std dev
2.4309
3.8785
Seasonal rate
Mean
-9.4528
-8.9408
Std dev
1.9222
2.5615

11.6. CASE STUDY
Table 11.5: Condition means for three customers
Population Customer 1 Customer 2
Contract length
-0.213
0.198
-0.208
Local utility
2.23
2.91
2.17
Known company
1.59
1.79
2.15
TOD rates
-9.19
-5.59
-8.92
Seasonal rates
-9.02
-5.86
-11.1

315

Customer 3
-0.401
0.677
1.24
-12.8
-10.9

tion means in Table 11.2. Interestingly, the means for these coeﬃcients
in Table 11.4 for model 1 are closer to the analogous means for model
2 than to the estimated population means for model 1 in Table 11.2.
Model 2 has the more reasonably shaped lognormal distribution for
these coeﬃcients and obtains a considerably better ﬁt than model 1.
The conditioning in model 1 appears to be moving the coeﬃcients
closer to the values in the better-speciﬁed model 2 and away from its
own misspeciﬁed population distributions. This is an example of how a
comparison of the estimated population distribution with the sample
average of the conditional distribution can reveal information about
speciﬁcation and estimation.
The standard deviations in Table 11.4 are larger than those in Table
11.3. This diﬀerence is due to the fact that the sampling variance in
the estimated population parameters is included in the calculations for
Table 11.4 but not for Table 11.3. The larger standard deviations do
not mean that the portion of total variance in βn that is captured by
variation in β̄n is larger when the sampling distribution is considered
than when not.
Useful marketing information can be obtained by examining the β̄n
of each customer. The value of this information for targeted marketing has been emphasized by Rossi et al. (1996). Table 11.5 gives the
calculated β̄n for the ﬁrst three customers in the data set, along with
the population mean of βn .
The ﬁrst customer wants to enter a long-term contract, compared
with the vast majority of customers who dislike long-term contracts.
He is willing to pay a higher energy price if the price is guaranteed
through a long-term contract. He evaluates TOD and seasonal rates
very generously, as if all of his consumption were in the lowest-priced
period (note that the lowest price under TOD rates is 5 cents per kWh
and the lowest price under seasonal rates is 6 cents per kWh.) That

316

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

is, the ﬁrst customer is willing to pay to be on TOD or seasonal rates
probably more than the rates are actually worth in terms of reduced
energy bills. Finally, this customer is willing to pay more than the
average customer to stay with the local utility. From a marketing
perspective, the local utility can easily retain and make extra proﬁts
from this customer by oﬀering a long-term contract under time-of-day
or seasonal rates.
The third customer dislikes seasonal and TOD rates, evaluating
them as if all of his consumption were in the highest-priced periods.
He dislikes long-term contracts far more than the average customer,
and yet, unlike most customers, prefers to receive service from a known
company that is not his local utility. This customer is a prime target
for capture by a well-known company if the company oﬀers him a ﬁxed
price without requiring a commitment.
The second customer is less clearly a marketing opportunity. A
well-known company is on about an equal footing with the local utility
in competing for this customer. This in itself might make the customer
a target of well-known suppliers, since he is less tied to the local utility
than most customers. However, beyond this information, there is little
beyond low prices (which all customers value) that would seem to
attract the customer. His evaluation of TOD and seasonal rates are
suﬃciently negative that it is unlikely that a supplier could attract and
make a proﬁt from the customer by oﬀering these rates. The customer
is willing to pay to avoid a long-term contract, and so a supplier could
attract this customer by not requiring a contract if other suppliers were
requiring contracts. However, if other suppliers were not requiring
contracts either, there seems to be little leverage that any supplier
would have over its competitors. This customer will apparently be
won by the supplier that oﬀers the lowest ﬁxed price.
The discussion of these three customers illustrates the type of information that can be obtained by conditioning on customer’s choices,
and how the information translates readily into characterizing each
customer and identifying proﬁtable marketing opportunities.

Conditional probability for the last choice
Recall that the last choice situation faced by each customer was not
included in the estimation. It can therefore be considered a new choice
situation and used to assess the eﬀect of conditioning on past choices.

11.6. CASE STUDY

317

We identiﬁed which alternative each customer chose in the new choice
situation and calculated the probability of this alternative. The probability was ﬁrst calculated without conditioning on previous choices.
This calculation uses the mixed logit formula (11.5) with the population distribution of βn and the point estimates of the population
parameters. The average of this unconditional probability over customers is 0.353. The probability was then calculated conditioned on
previous choices. Four diﬀerent ways of calculating this probability
were used:
1. based on formula (11.3) using the point estimates of the population parameters.
2. based on formula (11.3) along with the procedure in section (11.3)
that takes account of the sampling variance of the estimates of
the population parameters.
3-4 as the logit formula



eβn xniT +1
 β x
n njT +1
je
with the conditional mean β̄n being used as βn . This method is
equivalent to using the customer’s β̄n as if it were an estimate
of the customer’s true coeﬃcients, βn . The two versions diﬀer
in whether β̄n is calculated on the basis of the point estimate
of the population parameters (method 3) or takes the sampling
distribution into account (method 4).
Results are given in Table 11.6 for model 2. The most prominent result is that conditioning on each customer’s previous choices improves
the forecasts for the last choice situation considerably. The average
probability of the chosen alternative increases from 0.35 without conditioning to over 0.50 with conditioning. For nearly three-quarters of
the 361 sampled customers, the prediction of their last choice situation
is better with conditioning than without, with the average probability
rising by more than 0.25. For the other customers, the conditioning
makes the prediction in the last choice situations less accurate, with
the average probability for these customers dropping.
There are several reasons why the predicted probability after conditioning is not always greater. First, the choice experiments were
constructed such that each situation would be fairly diﬀerent from the

318

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

Table 11.6: Probability of chosen alternative in last choice situation
Method 1 Method 2 Method 3 Method 4
Average probability
0.5213
0.5041
0.5565
0.5487
Number of customers
whose probability
rises with conditioning
266
260
268
264
Average rise in
probability for
customers with a rise
0.2725
0.2576
0.3240
0.3204
Number of customers
whose probability
drops with conditioning
95
101
93
97
Average fall in
probability for
customers with a drop
0.1235
0.1182
0.1436
0.1391

other situations so as to obtain as much variation as possible. If the last
situation involves new tradeoﬀs, the previous choices will not be useful
and may in fact be detrimental to predicting the last choice. A more
appropriate test might be to design a series of choice situations that
elicited information on the relevant tradeoﬀs and then design an extra
”hold-out” situation that is within the range of tradeoﬀs of the previous ones. Second, we did not include in our model all of the attributes
of the alternatives that were presented to customers. In particular, we
omitted attributes that did not enter signiﬁcantly in the estimation of
the population parameters. Some customers might respond to these
omitted attributes, even though they are insigniﬁcant for the population as a whole. Insofar as the last choice situation involves tradeoﬀs of
these attributes, the conditional distributions of tastes would be misleading since the relevant tastes are excluded. This explanation might
imply that, if a mixed logit is going to be used for obtaining conditional densities for each customer, the researcher might want include
attributes that could be important for some individuals even though
they are insigniﬁcant for the population as a whole. Third, regardless
of how the survey and model are designed, some customers might respond to choice situations in a quixotic manner, such that the tastes
that are evidenced in previous choices are not applied by the customer
in the last choice situation. Last, random factors can cause the prob-

11.7. DISCUSSION

319

ability for some customers to drop with conditioning even when the
ﬁrst three reasons do not. While at least one of these factors may be
contributing to the lower choice probabilities for some of the customers
in our sample, the gain in predictive accuracy for the customers with
an increase in probability after conditioning is over twice as great as
the loss in accuracy for those with a decrease, and the number of customers with a gain is almost three times as great as the number with
a loss.
The third and easiest method, which simply calculates the standard
logit formula using the customers’ β̄n based on the point estimate of
the population parameters, gives the highest probability. This procedure does not account for the distribution of βn around β̄n nor the
sampling distribution of θ̂. Accounting for either variance reduces the
average probability: using the conditional distribution of βn rather
than just the mean β̄n (methods 1 and 2 compared with methods 3
and 4, respectively) reduces the average probability, and accounting for
the sampling distribution of θ̂ rather than the point estimate (methods
2 and 4 compared with methods 1 and 3, respectively) also reduces the
average probability. This result does not mean that method 3, which
incorporates the least variance, is superior to the others. Methods 3
and 4 are consistent only if the number of choice situations is able to
rise without bound, such that β̄n can be considered to be an estimate
of βn . With ﬁxed T , methods 1 and 2 are more appropriate since they
incorporate the entire conditional density.

11.7

Discussion

This chapter demonstrates how the distribution of coeﬃcients conditioned on the customer’s observed choices are obtained for the distribution of coeﬃcients in the population. While these conditional distributions can be useful in several ways, it is important to recognize the
limitations of the concept. First, the use of conditional distributions
in forecasting is limited to those customers whose previous choices are
observed. Second, while the conditional distribution of each customer
can be used in cluster analysis and for other identiﬁcation purposes,
the researcher will often want to relate preferences to observable demographics of the customers. Yet, these observable demographics of
the customers could be entered directly into the model itself such that
the population parameters vary with the observed characteristics of

320

CHAPTER 11. INDIVIDUAL-LEVEL PARAMETERS

the customers in the population. In fact, entering demographics into
the model is more direct and more accessible to hypothesis testing
than estimating a model without these characteristics, calculating the
conditional distribution for each customer, and then doing cluster and
other analyses on the moments of the conditional distributions.
Given these issues, there are three main reasons that a researcher
might beneﬁt from calculating customers’ conditional distributions.
First, information on the past choices of customers are becoming more
and more widely available. Examples include scanner data for customers with club cards at grocery stores, frequent ﬂier programs for
airlines, and purchases from internet retailers. In these situations,
conditioning on previous choices allows for eﬀective targeted marketing and the development of new products and services that match the
revealed preferences of subgroups of customers.
Second, the demographic characteristics that diﬀerentiate customers
with diﬀerent preferences might be more evident through cluster analysis on the conditional distributions than through speciﬁcation testing
in the model itself. Cluster analysis has its own unique way of identifying patterns, which might in some cases be more eﬀective than
speciﬁcation testing within a discrete choice model.
Third, examination of customers’ conditional distributions can often identify patterns that cannot be related to observed characteristics
of customers but are nevertheless useful to know. For instance, knowing that a product or marketing campaign will appeal to a share of the
population because of their particular preferences is often suﬃcient,
without needing to identify the people on the basis of their demographics. The conditional densities can greatly facilitate analyses that
have these goals.

Chapter 12

Bayesian Procedures
12.1

Introduction

A powerful set of procedures for estimating discrete choice models has
been developed within the Bayesian tradition. The breakthough concepts were introduced by Albert and Chib (1993) and McCulloch and
Rossi (1994) in the context of probit and Allenby and Lenk (1994)
and Allenby (1997) for mixed logits with normally distributed coeﬃcients. These authors showed how the parameters of the model can be
estimated without needing to calculate the choice probabilities. Their
procedures provide an alternative to the classical estimation methods
described in Chapter 10. Rossi et al. (1996), Allenby (1997), and Allenby and Rossi (1999) showed how the procedures can also be used
to obtain information on individual-level parameters within a model
with random taste variation. As such, they provide a Bayesian analog
to the classical procedures that we describe in Chapter 11. Variations of these procedures to accommodate other aspects of behavior
have been numerous. For example: Arora, Allenby and Ginter (1998)
generalized the mixed logit procedure to account for the quantity of
purchases as well as brand choice in each purchase occasion. Bradlow
and Fader (2001) showed how similar methods can be used to examine rankings data at an aggregate level rather than choice data at the
individual level. Chib and Greenberg (1998) and Wang, Bradlow and
Wainer (2001) developed methods for interrelated discrete responses.
Chiang et al. (1999) examined situations where the choice set that the
decision-maker considers is unknown to the researcher. Train (2001)
extended the Bayesian procedure for mixed logit to non-normal dis321

322

CHAPTER 12. BAYESIAN PROCEDURES

tributions of coeﬃcients, including lognormal, uniform, and triangular
distributions.
The Bayesian procedures avoid two of the most prominent diﬃculties associated with classical procedures. First, the Bayesian procedures do not require maximization of any function. With probit
and some mixed logit models (especially those with lognormal distributions), maximization of the simulated likelihood function can be
diﬃcult numerically. Often the algorithm fails to converge for various
reasons. The choice of starting values is often critical, with the algorithm converging from starting values that are close to the maximum
but not from other starting values. The issue of local versus global
maxima complicates the maximization further, since convergence does
not guarantee that the global maximum has been attained. Second,
desirable estimation properties, such as consistency and eﬃciency, can
be attained under more relaxed conditions with Bayesian procedures
than classical ones. As shown in Chapter 10, maximum simulated likelihood is consistent only if the number of draws used in simulation is
considered to rise with sample size; and eﬃciency is attained only if
the number of draws rises faster than the square root of sample size.
In contrast, the Bayesian estimators that we describe are consistent
for a ﬁxed number of draws used in simulation and are eﬃcient if the
number of draws rises at any rate with sample size.
These advantages come at a price, of course. For researchers who
are trained in a classical perspective, the learning curve can be steep.
Numerous interrelated techniques and concepts must be assimilated
before the power of them becomes clear. I can assure the reader,
however, that the eﬀort is worthwhile. Another cost of the Bayesian
procedures is more fundamental. To simulate relevant statistics that
are deﬁned over a distribution, the Bayesian procedures use an iterative process that converges, with a suﬃcient number of iterations, to
draws from that distribution. This convergence is diﬀerent from the
convergence to a maximum that is needed for classical procedures and
involves its own set of diﬃculties. The researcher cannot easily determine whether convergence has actually been achieved. As such, the
Bayesian procedures trade the diﬃculties of convergence to a maximum
for the diﬃculties associated with this diﬀerent kind of convergence.
The researcher will need to decide, in a particular setting, which type
of convergence is less burdensome.
For some behavioral models and distributional speciﬁcations, Bayesian

12.1. INTRODUCTION

323

procedures are far faster and, after the initial learning that a classicist
might need, are more straightforward from a programming perspective
than classical procedures. For other models, the classical procedures
are easier. We will explore the relative speed of Bayesian and classical
procedures in the sections to follow. The diﬀerences can be readily
categorized, through an understanding of how the two sets of procedures operate. The researcher can use this understanding in deciding
which procedure to use in a particular setting.
Two important notes are required before proceeding. First, the
Bayesian procedures, and the term “hierarchical Bayes” that is often
used in the context of discrete choice models, refer to an estimation
method, not a behavioral model. Probit, mixed logit, or any other
model that the researcher speciﬁes can, in principle, be estimated by
either classical or Bayesian procedures. Second, the Bayesian perspective from which these procedure arise provides a rich and intellectually
satisfying paradigm for inference and decision-making. Nevertheless,
a researcher who is uninterested in the Bayesian perspective can still
beneﬁt from Bayesian procedures: the use of Bayesian procedures does
not necessitate that the researcher adopt a Bayesian perspective on
statistics. As we will show, the Bayesian procedures provide an estimator whose properties can be examined and interpreted in purely
classical ways. Under certain conditions, the estimator that results
from the Bayesian procedures is asymptotically equivalent to the maximum likelihood estimator. The researcher can therefore use Bayesian
procedures to obtain parameter estimates and then interpret them the
same as if they were maximum likelihood estimates. A highlight of the
Bayesian procedures is that the results can be interpreted from both
perspectives simultaneously, drawing on the insights aﬀorded by each
tradition. This dual interpretation parallels that of the classical procedures, whose results can be transformed for Bayesian interpretation
as described by Geweke (1989). In short, the researcher’s statistical
perspective need not dictate her choice of procedure.
In the sections below, we provide an overview of Bayesian concepts
in general, introducing the prior and posterior distributions. We then
show how the mean of the posterior distribution can be interpreted
from a classical perspective as being asymptotically equivalent to the
maximum of the likelihood function. Next we address the numerical
issue of how to calculate the mean of the posterior distribution. Gibbs
sampling and, more generally, the Metropolis-Hastings algorithm can

324

CHAPTER 12. BAYESIAN PROCEDURES

be used to obtain draws from practically any posterior distribution,
no matter how complex. The mean of these draws simulates the mean
of the posterior and, as such, constitutes the parameter estimates.
The standard deviation of the draws provides the classical standard
errors of the estimates. We apply the method to a mixed logit model
and compare the numerical diﬃculty and speed of the Bayesian and
classical procedures under various speciﬁcations.

12.2

Overview of Bayesian concepts

Consider a model with parameters θ. The researcher has some initial
ideas about the value of these parameters and collects data to improve this understanding. Under Bayesian analysis, the researcher’s
ideas about the parameters are represented by a probability distribution over all possible values that the parameters can take, where
the probability represents how likely the researcher thinks it is for the
parameters to take a particular value. Prior to collecting data, the
researcher’s ideas are based on logic, intuition or past analyses. These
ideas are represented by a density on θ, called the prior distribution
and denoted k(θ). The researcher collects data in order to improve her
ideas about the value of θ. Suppose the researcher observes a sample of
N independent decision-makers. Let yn denote the observed choice (or
choices) of decision-maker n, and let the set of observed choices for the
entire sample be labeled collectively as Y = {y1 , . . . , yN }. Based on
this sample information, the researcher changes, or updates, her ideas
about θ. The updated ideas are represented by a new density on θ,
labeled K(θ | Y ) and called the posterior distribution. This posterior
distribution depends on Y since it incorporates the information that
is contained in the observed sample.
The question arises: how exactly do the researcher’s ideas about θ
change from observing Y ? That is, how does the posterior distribution
K(θ | Y ) diﬀer from the prior distribution k(θ)? There is a precise
relationship between the prior and posterior distribution, established
by Bayes rule. Let P (yn | θ) be the probability of outcome yn for
decision-maker n. This probability is the behavioral model that relates
the explanatory variables and parameters to the outcome, though the
notation for the explanatory variables is omitted for simplicity. The

12.2. OVERVIEW OF BAYESIAN CONCEPTS

325

probability of observing the sample outcomes Y is
N

P (yn | θ).

L(Y | θ) =
n=1

This is the likelihood function (not logged) of the observed choices.
Note that it is a function of the parameters θ.
Bayes’ rule provides the mechanism by which the researcher improves her ideas about θ. By the rules of conditioning,
K(θ | Y )L(Y ) = L(Y | θ)k(θ).

(12.1)

where L(Y ) is the marginal probability of Y , marginal over θ:


L(Y ) =

L(Y | θ)k(θ)dθ.

Both sides of equation (12.1) represent the joint probability of Y and
θ, with the conditioning in opposite direction. The left hand side is
the probability of Y times the probability of θ given Y , while the right
hand side is the probability of θ times the probability of Y given θ.
Rearranging we have
K(θ | Y ) =

L(Y | θ)k(θ)
.
L(Y )

(12.2)

This equation is Bayes’ rule applied to prior and posterior distributions. In general, Bayes rule links conditional and unconditional probabilities in any setting and does not imply a Bayesian perspective on
statistics. Bayesian statistics arises when the unconditional probability
is the prior distribution (which reﬂects the researcher’s ideas about θ
not conditioned on the sample information) and the conditional probability is the posterior distribution (which gives the researcher’s ideas
about θ conditioned on the sample information.)
We can express equation (12.2) in a more compact and convenient
form. The marginal probability of Y , L(Y ), is constant with respect
to θ and, more speciﬁcally, is the integral of the numerator of (12.2).
As such, L(Y ) is simply the normalizing constant that assures that
the posterior distribution integrates to 1, as required for any proper
density. Using this fact, equation (12.2) can be stated more succinctly
by saying simply that the posterior distribution is proportional to the
prior distribution times the likelihood function:
K(θ | Y ) ∝ L(Y | θ)k(θ)

326

CHAPTER 12. BAYESIAN PROCEDURES

Intuitively, the probability that the researcher ascribes to a given value
for the parameters after seeing the sample, is the probability that she
ascribes before seeing the sample times the probability (i.e., likelihood )
that those parameter values would result in the observed choices.
The mean of the posterior distribution is:


θ̄ =

θK(θ | Y )dθ

(12.3)

This mean has importance from both a Bayesian and classical perspective. From a Bayesian perspective, θ̄ is the value of θ that minimizes
the expected cost of the researcher being wrong about θ, if the cost of
error is quadratic in the size of the error. From a classical perspective,
θ̄ is an estimator that has the same asymptotic sampling distribution as
the maximum likelihood estimator. We explain both of these concepts
below.

12.2.1

Bayesian properties of θ̄

The researcher’s views about θ are represented by the posterior K(θ |
Y ) after observing the sample. Suppose that the researcher was required to guess the true value of θ and would be levied a penalty for
the extent to which her guess diﬀered from the true value. More realistically, suppose that some action must be taken that depends on the
value of θ, such as a manufacturer setting the price of a good when the
revenues at any price depend on the price elasticity of demand. There
is a cost to taking the wrong action, such as setting price based on the
belief that the price elasticity is -.2 when the true elasticity is actually
-.3. The question becomes: what value of θ should the researcher use in
these decisions in order to minimize her expected cost of being wrong,
given her beliefs about θ as represented in the posterior distribution?
If the cost of being wrong is quadratic in the distance between the
θ that is used in the decision and the true θ, then the optimal value of
θ to use in the decision is θ̄. This fact can be demonstrated as follows.
If the researcher uses θ0 in her decisions when the true value is θ∗ , the
cost of being wrong is:
C(θ0 , θ∗ ) = (θ0 − θ∗ ) B(θ0 − θ∗ )
where B is a matrix of constants. The researcher doesn’t know the true
value of θ but has beliefs about its value as represented in K(θ | Y ).

12.2. OVERVIEW OF BAYESIAN CONCEPTS

327

The researcher can therefore calculate the expected cost of being wrong
when using the value θ0 . This expected cost is:


EC(θ0 ) =



=

C(θ0 , θ)K(θ | Y )dθ
(θ0 − θ) B(θ0 − θ)K(θ | Y )dθ.

The value of θ0 that minimizes this expected cost is determined by
diﬀerentiating EC(θ0 ), setting the derivative to zero, and solving for
θ0 . The derivative is:

(θ0 − θ) B(θ0 − θ)
∂EC(θ0 )
=
K(θ | Y )dθ
∂θ0
∂θ0


=
=

2(θ0 − θ) BK(θ | Y )dθ

2θ0 B





K(θ | Y )dθ − 2



θK(θ | Y )dθ)

B

= 2θ0 B − 2θ̄ B.
Setting this expression to zero and solving for θ0 , we have
2θ0 B − 2θ̄ B = 0

θ0 B = θ̄ B
θ0 = θ̄.

The mean of the posterior, θ̄, is the value of θ that a Bayesian researcher would optimally act upon if the cost of being wrong about θ
rises quadratically with the distance to the true θ.
Zellner (1971) describes the optimal Bayesian estimator under other
loss functions. While the loss function is usually assumed to be symmetric and unbounded, like the quadratic, it need not be either; see,
for example, Wen and Levy (2001). Importantly, Bickel and Doksum
(2000) show that the correspondence that we describe in the next section between the mean of the posterior and the maximum likelihood
estimator also applies to Bayesian estimators that are optimal under
many other loss functions.

12.2.2

Classical properties of θ̄: The Bernstein-von Mises
theorem

Classical statistics is not concerned with the researcher’s beliefs and
contains no notion of prior and posterior distributions. The concern of

328

CHAPTER 12. BAYESIAN PROCEDURES

classical statistics is to determine the sampling distribution of an estimator. This distribution reﬂects the fact that a diﬀerent sample would
produce a diﬀerent point estimate. The sampling distribution is the
distribution of point estimates that would be obtained if many diﬀerent
samples were taken. Usually, the sampling distribution for an estimator cannot be derived for small samples. However, the asymptotic
sampling distribution can usually be derived, which approximates the
actual sampling distribution when sample size is large enough. In classical statistics, the asymptotic sampling distribution determines the
properties of the estimator, such as whether the estimator is consistent,
asymptotically normal, and eﬃcient. The variance of the asymptotic
distribution provides the standard errors of the estimates and allows
for hypothesis testing, the accuracy of which rises with sample size.
From a classical perspective, θ̄ is simply a statistic like any other
statistic. Its formula, given in (12.3), exists and can be applied even if
the researcher does not interpret the formula as representing the mean
a posterior distribution. The researcher can consider K(θ | Y ) to be
a function deﬁned by equation (12.2) for any arbitrarily deﬁned k(θ)
that meets the requirements of a density. The relevant question for
the classical researcher is the same as with any statistic: what is the
sampling distribution of θ̄?
The answer to this question is given by the Bernstein-von Mises
theorem. This theorem has a long provenance and takes many forms.
In the nineteenth century, LaPlace (1820) observed that posterior distributions start to look more and more like normal distributions as
sample size increases. Over the years, numerous versions of the observation have been demonstrated under various conditions, and its
implications have been more fully explicated. See Rao (1987), Cam
and Yang (1990), Lehmann and Casella (1998), and Bickel and Doksum (2000) for modern treatments with historical notes. The theorem
is named after Bernstein (1917) and von Mises (1931) because they
seem to be the ﬁrst to provide a formal proof of LaPlace’s observation,
though under restrictive assumptions that others later relaxed.
I describe the theorem as three related statements. In these statements, the information matrix, which we used extensively in Chapters
8 and 10, is important. Recall that the score of an observation is the
gradient of that observation’s log-likelihood with respect to the parameters: sn = ∂logP (yn | θ)/∂θ where P (yn | θ) is the probability
of decision-maker n’s observed choices. The information matrix, -H,

12.2. OVERVIEW OF BAYESIAN CONCEPTS

329

is the negative expected derivative of the score, evaluated at the true
parameters:


∂ 2 logP (yn | θ∗ )
.
−H = −E
∂θ∂θ
where the expectation is over the population. (The negative is taken
so that the information matrix can be positive deﬁnite, like a covariance matrix.) Recall also that the maximum likelihood estimator has
√
d
an asymptotic variance equal to (−H)−1 /N . That is, N (θ∗ − θ̂) →
a
N (0, (−H)−1 ), such that θ̂ ∼ N (θ∗ , (−H)−1 /N ), where θ̂ is the maximum likelihood estimator.
We can now give the three statements that collectively constitute
the Bernstein-von Mises theorem:
√
d
1. N (θ − θ̄) → N (0, (−H)−1 ).
Stated intuitively, the posterior distribution of θ converges to
a normal distribution with variance (−H)−1 /N as sample size
d
rises. In using the expression → in this context, it is important
to note that the
√ distribution that is converging is the posterior
distribution of N (θ − θ̄) rather than the sampling distribution.
In classical analysis of estimators, as in Chapter 10, the notation
d
→ is used to indicate that the sampling distribution is converging. Bayesian analysis examines the posterior rather than the
sampling distribution and the notation indicates that the posterior distribution is converging.
The important points to recognize in this ﬁrst statement are that,
as sample size rises, (i) the posterior becomes normal and (ii)
the variance of the posterior becomes the same as the sampling
variance of the maximum likelihood estimator. These two points
are relevant for the next two statements.
√
p
2. N (θ̄ − θ̂) → 0.
The mean of the posterior converges to the maximum of the likelihood function. An even stronger statement is being made. The
diﬀerence between the mean of the posterior and the maximum
of the likelihood function disappears
asymptotically, even when
√
the diﬀerence is scaled up by N .
This result makes intuitive sense, given the ﬁrst result. Since the
posterior eventually becomes normal, and the mean and maxi-

330

CHAPTER 12. BAYESIAN PROCEDURES

mum are the same for a normal distribution, the mean of the
posterior eventually becomes the same as the maximum of the
posterior. Also, the eﬀect of the prior distribution on the posterior disappears as sample size rises (provided of course that the
prior is not zero in the neighborhood of the true value). The
posterior is therefore proportional to the likelihood function for
large enough sample sizes. The maximum of the likelihood function becomes the same as the maximum of the posterior, which,
as stated, is also the mean. Stated succinctly: since the posterior is asymptotically normal such that its mean equals its maximum, and the posterior is proportional to the likelihood function
asymptotically, the diﬀerence between θ̄ and θ̂ eventually disappears.
√
d
3. N (θ̄ − θ∗ ) → N (0, (−H)−1 ).
The mean of the posterior, considered as a classical estimator, is
asymptotically equivalent to the maximum likelihood estimator.
a
That is, θ̄ ∼ N (θ∗ , (−H)−1 /N ), just like the maximum likelihood
estimator. Note that since we are now talking in classical terms,
the notation refers to the sampling distribution of θ̄, the same as
it would for any estimator.
This
is an implication of the ﬁrst two. The statis√third statement
∗
tic N (θ̄ − θ ) can be rewritten as:
√
√
√
N (θ̄ − θ∗ ) = N (θ̂ − θ∗ ) + N (θ̄ − θ̂)
√
p
From statement 2, we know that N (θ̄ − θ̂) → 0, such that the
second term disappears asymptotically. Only the ﬁrst term affects the asymptotic distribution. This ﬁrst term is the deﬁning
statistic for the maximum
likelihood estimator θ̂. We showed
√
d
in Chapter
10
that
N
(
θ̂
−
θ∗ ) → N (0, (−H)−1 ). The statis√
tic N (θ̄ − θ∗ ) therefore follows the same distribution asymptotically. Essentially, since θ̄ and θ̂ converge, their asymptotic
sampling distributions are the same.
The Bernstein-von Mises theorem establishes that θ̄ is on the same
footing, in classical terms, as θ̂. Instead of maximizing the likelihood
function, the researcher can calculate the mean of the posterior distribution and know that the resulting estimator is as good in classical
terms as maximum likelihood.

12.3. SIMULATION OF POSTERIOR MEAN

331

The theorem also provides a procedure for obtaining the standard
errors of the estimates. Statement 1 says that asymptotically the variance of the posterior distribution is (−H)−1 /N , which, by statement
3, is the asymptotic sampling variance of the estimator θ̄. The variance of the posterior is the asymptotic variance of the estimates. The
researcher can perform estimation entirely by using moments of the
posterior: The mean of the posterior provides the point estimates, and
the standard deviation of the posterior provides the standard errors.
In applications, the posterior mean and the maximum of the likelihood function can diﬀer when sample size is insuﬃcient for the asymptotic convergence. Huber and Train (2001) found the two to be remarkably similar in their application, while Ainslie et al. (2001) found
them to be suﬃciently diﬀerent to warrant consideration. When the
two estimates are not similar, other grounds must be used to choose
between them (if indeed a choice is necessary), since their asymptotic
properties are the same.

12.3

Simulation of posterior mean

To calculate the mean of the posterior distribution, simulation procedures are generally required. As stated above, the mean is:


θ̄ =

θK(θ | Y )dθ.

A simulated approximaton of this integral is obtained by taking draws
of θ from the posterior distribution and averaging the results. The
simulated mean is:
1 R r
θ
θ̌ =
R r=1
where θr is the r-th draw from K(θ | Y ). The standard deviation of
the posterior, which serves as the standard errors of the estimates, is
simulated by taking the standard deviation of the R draws.
As stated above, θ̄ has the same asymptotic properties as the maximum likelihood estimator θ̂. How does the use of simulation to approximate θ̄ aﬀect its properties as an estimator? For maximum simulated
likelihood (MSL), we found that the number of draws used in simulation must rise faster than the square root of sample size in order for
the estimator to be asymptotically equivalent to maximum likelihood.

CHAPTER 12. BAYESIAN PROCEDURES

332

With a ﬁxed number of draws, the MSL estimator is inconsistent. If
the number of draws rises with sample size but at a slower rate than
the square root of sample size, then MSL is consistent but not asymptotically normal or eﬃcient. As we will see, desirable properties of
the simulated mean of the posterior (SMP) are attained with more
relaxed conditions on the number of draws. In particular, the SMP
estimator is consistent and asymptotically normal for a ﬁxed number
of draws and becomes eﬃcient and equivalent to maximum likelihood
if the number of draws rises at any rate with sample size.
To demonstrate these properties, we examine the normalized statis√
tic N (θ̌ − θ∗ ). This statistic can be rewritten as:
√

N (θ̌ − θ∗ ) =

√

N (θ̄ − θ∗ ) +

√

N (θ̌ − θ̄).

From statement 3 of the Bernstein-von Mises theorem, we know the
√
d
limiting distribution of the ﬁrst term: N (θ̄ − θ∗ ) → N (0, (−H)−1 ).
The central limit theorem gives us the limiting distribution of the second term. θ̌ is the average of R draws from a distribution with mean
θ̄ and variance (−H−1 )/N . Assuming the draws are independent, the
central limit theorem states that the average of these R draws is distributed with mean θ̄ and variance (−H)−1 /RN . Plugging this infor√
d
mation into the second term, we have: N (θ̌ − θ̄) → N (0, (−H)−1 /R).
The two terms are independent by construction, and so
√

N (θ̌ − θ∗ ) → N (0, (1 + (1/R))(−H)−1 ).
d

The simulated mean of the posterior is consistent and asymptotically
normal for ﬁxed R. The covariance is inﬂated by a factor of 1/R due
to the simulation; however, the covariance matrix can be calculated
and so standard errors and hypothesis testing can be conducted that
take into account the simulation noise.
If R rises at any rate with N , then the second term disappears
asymptotically. We have
√

N (θ̌ − θ∗ ) → N (0, (−H)−1 )
d

which is the same as for the actual (unsimulated) mean θ̄ and the maximum likelihood estimator θ̂. When R rises with N , θ̌ is asymptotically
eﬃcient and equivalent to maximum likelihood.

12.4. DRAWING FROM THE POSTERIOR

333

Two notes are required regarding this derivation. First, we have
assumed that the draws from the posterior distribution are independent. In the sections to follow, we describe methods for drawing from
the posterior that result in draws that exhibit a type of serial correlation. When draws of this type are used, the variance of the simulated
mean is inﬂated by more than a factor of 1/R. The estimator is still
consistent and asymptotically normal with a ﬁxed number of nonindependent draws; its covariance is simply greater. And, if R rises
with N , the extra covariance due to simulation disappears asymptotically even with nonindependent draws, such that the simulated mean
is asymptotically equivalent to maximum likelihood.
Second, we have assumed that draws from the posterior distribution can be taken without needing to simulate the choice probabilities.
For some models, taking a draw from the posterior requires simulating
the choice probabilities on which the posterior is based. In this case,
the simulated mean of the posterior involves simulation within simulation, and the formula for its asymptotic distribution is more complex.
As we will see, however, for most models, including all the models that
we consider in this book, draws from the posterior can be taken without simulating the choice probabilities. One of the advantages of the
Bayesian procedures is that they usually avoid the need to simulate
choice probabilities.

12.4

Drawing from the posterior

Usually, the posterior distribution does not have a convenient form
from which to take draws. For example, we know how to take draws
easily from a joint untruncated normal distribution; however, it is rare
that the posterior takes this form for the entire parameter vector. Importance sampling, which we describe in section 9.2.7 in relation to
any density, can be useful for simulating statistics over the posterior.
Geweke (1992, 1997) describes the approach with respect to posteriors
and provides practical guidance on appropriate selection of a proposal
density. Two other methods that we described in Chapter 9 are particularly useful for taking draws from a posterior distribution: Gibbs
sampling and the Metropolis-Hasting algorithm. These methods are
often called Monte Carlo Markov Chain, or MCMC, methods. Formally, Gibbs sampling is a special type of Metropolis-Hasting algorithm (Gelman, 1992). However, the case is so special, and so con-

334

CHAPTER 12. BAYESIAN PROCEDURES

ceptually straightforward, that the term Metropolis-Hasting (M-H) is
usually reserved for versions that are more complex than Gibbs sampling. That is, when the M-H algorithm is Gibbs sampling, it is referred
to as Gibbs sampling, and when it is more complex than Gibbs sampling it is referred to as the M-H algorithm. I maintain this convention
hereafter.
It would be useful for the reader to review sections (9.2.8) and
(9.2.9), which describe Gibbs sampling and the M-H algorithm, since
we will be using these procedures extensively in the remainder of this
chapter. As stated above, the mean of the posterior is simulated by
taking draws from the posterior and averaging the draws. Instead
of taking draws from the multidimensional posterior for all the parameters, Gibbs sampling allows the researcher to take draws of one
parameter at a time (or a subset of parameters), conditional on values
of the other parameters (Casella and George, 1992). Drawing from
the posterior for one parameter conditional on the others is usually
much easier than drawing from the posterior for all parameters simultaneously. In some cases, the M-H algorithm is needed in conjunction
with Gibbs sampling. Suppose, for example, that the posterior for one
parameter conditional on the other parameters does not take a simple
form. In this case, the M-H algorithm can utilized, since it is applicable to (practically) any distribution (Chib and Greenberg, 1995). The
M-H algorithm is particularly useful in the context of posterior distributions because the normalizing constant for the posterior need not
be calculated. Recall that the posterior is the prior times the likelihood function, divided by a normalizing constant that assures that the
posterior integrates to one:
K(θ | Y ) =

L(Y | θ)k(θ)
.
L(Y )

where L(Y ) is the normalizing constant


L(Y ) =

L(Y | θ)k(θ)dθ.

This constant can be diﬃcult to calculate since it involves integration.
As described in section (9.2.9), the M-H algorithm can be applied without knowing or calculating the normalizing constant of the posterior.
In summary: Gibbs sampling, combined if necessary with the M-H
algorithm, allows draws to be taken from the posterior of a parameter vector for essentially any model. These procedures are applied

12.5. POSTERIORS FOR NORMALS

335

to a mixed logit model in section (12.6) below. First, however, we
will derive the posterior distribution for some very simple models. As
we will see, these results often apply in complex models for a subset
of the parameters. This fact facilitates the Gibbs sampling of these
parameters.

12.5

Posterior for the mean and variance of a
normal distribution

The posterior distribution takes a very convenient form for some simple
inference processes. We describe two of these situations, which, as we
will see, often arise within more complex models for a subset of the
parameters. Both results relate to the normal distribution. We ﬁrst
consider the situation where the variance of a normal distribution is
known, but the mean is not. We then turn the tables and consider the
mean to be known but not the variance. Finally, combining these two
situations with Gibbs sampling, we consider the situation where both
the mean and variance are unknown.

12.5.1

Result A: Unknown mean, known variance

We discuss the one-dimensional case ﬁrst, and then generalize to multiple dimensions. Consider a random variable β that is distributed
normal with unknown mean b and known variance σ. The researcher
observes a sample of N realizations of the random variable, labeled

βn , n = 1, . . . , N . The sample mean is β̄ = (1/N ) n βn . Suppose the
researcher’s prior on b is N (β0 , s0 ); that is, the researcher’s prior beliefs
are represented by a normal distribution with mean b0 and variance s0 .
Note that we now have two normal distributions: the distribution of β
which has mean b, and the prior distribution on this unknown mean,
which has mean β0 . The prior indicates that the researcher thinks it
is most likely that b = β0 and also thinks there is a 95 percent chance
√
√
that b is somewhere between β0 − 1.96 s0 and β0 + 1.96 s0 . Under
this prior, the posterior on b is N (b1 , s1 ) where
1
b0 + N
σ β̄
b1 = s 0 1
N
s0 + σ

CHAPTER 12. BAYESIAN PROCEDURES

336
and

1
.
N
s0 + σ

s1 = 1

The posterior mean b1 is the weighted average of the sample mean and
the prior mean.
Proof: The prior is
k(b) = √

1
2
e−(b−b0 ) /2s0
2πs0

The probability of drawing βn from N (b, σ) is
√

1
2
e−(b−βn ) /2σ
2πσ

and so the likelihood of the N draws is
L(βn ∀n | b) =
=
=
=

1
2
e−(b−βn ) /2σ
2πσ
n

1
− (b−βn )2 /2σ
e
(2πσ)N/2
1
2
e(−N s̄−N (b−β̄) )/2σ
N/2
(2πσ)
1
2
e−N s̄/2σ · e−N (b−β̄) /2σ
(2πσ)N/2
√



where s̄ = (1/N ) (βn − β̄)2 is the sample variance of the βn ’s. The
posterior is therefore
K(b | βn ∀n) ∝ L(βn ∀n | b)k(b)
1
1
2
2
e−N s̄/2σ · e−N (b−β̄) /2σ × √
e−(b−b0 ) /2s0
=
N/2
2πs0
(2πσ)
2

2

= m1 e−[N (b−β̄) /2σ]−[(b−b0 ) /2s0 ]
where m1 is a constant that contains all the multiplicative terms that
do not depend on b. With some algebraic manipulation, we have
2

2

K(b | βn ∀n) ∝ e−[N (b−β̄) /2σ]−[(b−b0 ) /2s0 )]
2

∝ e(b −2b1 b)/2s1
2

∝ e(b−b1 ) /2s1 .

12.5. POSTERIORS FOR NORMALS

337

The second ∝ removes β̄ 2 and b20 from the exponential, since they
do not depend on b and thereby only aﬀect the normalizing constant.
(Recall that exp(a+b) = exp(a)exp(b), such that adding and removing
terms from the exponential has a multiplicative eﬀect on K(b | βn ∀n).)
The third ∝ adds b1 β̄ to the exponential, which also does not depend
on b. The posterior is therefore
2

K(b | βn ∀n) = me(b−b1 ) /2s1 ,
where m is the normalizing constant. This formula is the normal density with mean b1 and variance s1 .
As stated above, the mean of the posterior is a weighted average of
the sample mean and the prior mean. The weight on the sample mean
rises as sample size rises, such that for large enough N , the prior mean
becomes irrelevant.
Often a researcher will want to specify a prior that represents very
little knowledge about the parameters before taking the sample. In
general, the researcher’s uncertainty is reﬂected in the variance of the
prior. A large variance means that the researcher has little idea about
the value of the parameter. Stated equivalently, a prior that is nearly
ﬂat means that the researcher considers all possible values of the parameters to be equally likely. A prior that represents little information
is called “diﬀuse.”
We can examine the eﬀect of a diﬀuse prior on the posterior of b.
By raising the variance of the prior, s0 , the normal prior becomes more
spread out and ﬂat. As s0 → ∞, representing an increasingly diﬀuse
prior, the posterior approaches N (β̄, σ/N ).
The multivariate versions of this result is similar. Consider a Kdimensional random vector β ∼ N (b, W ) with known W and unknown
b. The researcher observes a sample βn , n = 1, . . . , N whose sample
mean is β̄. If the researcher’s prior on b is diﬀuse (normal with an
unboundedly large variance), then the posterior is N (β̄, W/N ).
Taking draws from this posterior is easy. Let L be the Choleski
factor of W/N . Draw K iid standard normal deviates, ηi , i = 1, . . . , K,
and stack them into a vector η = η1 , . . . , ηK  . Calculate b̃ = β̄ + Lη.
The resulting vector b̃ is a draw from N (β̄, W/N ).

12.5.2

Result B: Unknown variance, known mean

Consider a (one-dimensional) random variable that is distributed normal with known mean b and unknown variance σ. The researcher

CHAPTER 12. BAYESIAN PROCEDURES

338

observes a sample of N realizations, labeled βn , n = 1, . . . , N . The

sample variance around the known mean is s̄ = (1/N ) n (βn − b)2 .
Suppose the researcher’s prior on σ is inverted gamma with degrees
of freedom v0 and scale s0 . This prior is denoted IG(v0 , s0 ). The
density is zero for any negative value for σ, reﬂecting the fact that a
variance must be positive. The mode of the inverted gamma prior is
s0 v0 /(1 + v0 ). Under the inverted gamma prior, the posterior on σ is
also inverted gamma IG(v1 , s1 ), where
v 1 = v0 + N
v0 s0 + N s̄
.
s1 =
v0 + N
Proof: An inverted gamma with v0 degrees of freedom and scale s0
has density
1
k(σ) =
e−v0 s0 /2σ
(v
m0 σ 0 +1)/2
where m0 is the normalizing constant. The likelihood of the sample,
treated as a function of σ, is
L(βn ∀n | σ) =


1
1
− (b−βn )2 /2σ
e
=
e−N s̄/2σ .
N/2
(2πσ)
(2πσ)N/2

The posterior is then
K(σ | βn ∀n) ∝ L(βn ∀n | σ)k(σ)
1
1 −N s̄/2σ
e
× (v +1)/2 e−v0 s0 /2σ
∝
σ N/2
σ 0
1
=
e−(N s̄+v0 s0 )/2σ
(N
+v
0 +1)/2
σ
1
=
e−v1 s1 /2σ
σ (v1 +1)/2
which is the inverted gamma density with v1 degrees of freedom and
scale s1 .
The inverted gamma prior becomes more diﬀuse with lower v0 . For
the density to integrate to one and have a mean, v0 must exceed 1. It
is customary to set s0 = 1 when specifying v0 → 1. Under this diﬀuse
prior, the posterior becomes IG(1 + N, (1 + N s̄)/(1 + N )). The mode
of this posterior is (1+N s̄)/(2+N ) which is approximately the sample
variance s̄ for large N .

12.5. POSTERIORS FOR NORMALS

339

The multivariate case is similar. The multivariate generalization of
an inverted gamma distribution is the inverted Wishart distribution.
The result in the multivariate case is the same as with one random
variable except that the inverted gamma is replaced by the inverted
Wishart.
A K-dimensional random vector β ∼ N (b, W ) has known b but
unknown W . A sample of size N from this distribution has variance

around the known mean of S̄ = (1/N ) n (βn − b)(βn − b) . If the
researcher’s prior on W is inverted Wishart with v0 degrees of freedom
and scale matrix S0 , labeled IW (v0 , S0 ), then the posterior on W is
IW (v1 , S1 ) where
v 1 = v0 + N
v0 S0 + N S̄
.
S1 =
v0 + N
The prior becomes more diﬀuse with lower v0 , though v0 must exceed K
in order for the prior to integrate to one and have means. With S0 = I,
where I is the K-dimensional identity matrix, the posterior under a
diﬀuse prior becomes IW (K + N, (KI + N S̄)/(K + N )). Conceptually,
the prior is equivalent to the researcher having a previous sample of K
observations whose sample variance was I. As N rises without bound,
the inﬂuence of the prior on the posterior eventually disappears.
It is easy to take draws from inverted gamma and inverted Wishart
distributions. Consider ﬁrst an inverted gamma IG(v1 , s1 ). Draws are
taken as follows:
1. Take v1 draws from a standard normal and label the draws ηi , i =
1, . . . , v1 .
√
result, and take the average.
2. Divide each draw by s1 , square the
 $
That is, calculate r = (1/v1 ) i ( 1/s1 ηi )2 , which is the sample
variance of v1 draws from a normal distribution whose variance
is 1/s1 .
3. Take the inverse of r: s̃ = 1/r is a draw from the inverted gamma.
Draws from a K-dimensional inverted Wishart IW (v1 , S1 ) are obtained as follows.
1. Take v1 draws of K-dimensional vectors whose elements are independent standard normal deviates. Label these draws ηi , i =
1, . . . , v1 .

340

CHAPTER 12. BAYESIAN PROCEDURES

2. Calculate the Choleski factor of the inverse of S1 , labeled L where
LL = S1−1 .


3. Create R = (1/v1 ) i (Lηi )(Lηi ) . Note that R is the variance of
draws from a distribution with variance S1−1 .
4. Take the inverse of R. The matrix S̃ = R−1 is a draw from
IW (v1 , S1 ).

12.5.3

Unknown mean and variance

Suppose that both the mean b and variance W are unknown. The
posterior for both parameters does not take a convenient form. However, draws can easily be obtained using Gibbs sampling and results
A and B. A draw of b is taken conditional on W , and then a draw of
W is taken conditional on b. Result A says that the posterior for b
conditional on W is normal, which is easy to draw from. Result B says
that the posterior for W conditional on b is inverted Wishart, which
is also easy to draw from. Iterating through numerous cycles of draws
from the conditional posteriors provides, eventually, draws from the
joint posterior.

12.6

Hierarchical Bayes for mixed logit

In this section we show how the Bayesian procedures can be used to
estimate the parameters of a mixed logit model. We utilize the approach developed by Allenby (1997), implemented by SawtoothSoftware (1999), and generalized by Train (2001). Let the utility that
person n obtains from alternative j in time period t be
Unjt = βn xnjt + εnjt
where εnjt is iid extreme value and βn ∼ N (b, W ). Giving βn a normal
distribution allows us to use results A and B, which speeds estimation
considerably. In the following section, we discuss the use of non-normal
distributions.
The researcher has priors on b and W . Suppose the prior on b is
normal with a unboundedly large variance. Suppose that the prior on
W is inverted Wishart with K degrees of freedom and scale matrix
I, the K-dimensional identity matrix. Note that these are the priors

12.6. HIERARCHICAL BAYES FOR MIXED LOGIT

341

used for results A and B above. More ﬂexible priors can be speciﬁed for
W , using the procedures of, for example, McCulloch and Rossi (2000),
though doing so makes the Gibbs sampling more complex.
A sample of N people is observed. The chosen alternatives in
all time periods for person n are denoted yn = yn1 , . . . , ynT , and
the choices of the entire sample are labeled Y = y1 , . . . , yN . The
probability of person n’s observed choices, conditional on β, is


L(yn | β) =
t



eβ xnynt t
 βx
njt
je



.

The probability not conditional on β is the integral of L(yn | β) over
all β:

L(yn | b, W ) =

L(yn | β)φ(β | b, W )dβ

where φ(β | b, W ) is the normal density with mean b and variance W .
This L(yn | b, W ) is the mixed logit probability.
The posterior distribution of b and W is, by deﬁnition
K(b, W | Y ) ∝

L(yn | b, W )k(b, W )

(12.4)

n

where k(b, W ) is the prior on b and W described above (i.e., normal
for b times inverted Wishart for W ).
It would be possible to draw directly from K(b, W | Y ) with the
M-H algorithm. However, doing so would be computationally very
slow. For each iteration of the M-H algorithm, it would be necessary to calculate the right hand side of (12.4). However, the choice
probability L(yn | b, W ) is an integral without a closed for and must
be approximated through simulation. Each iteration of the M-H algorithm would therefore require simulation of L(yn | b, W ) for each n. As
well as being very time consuming, the properties of the resulting estimator would be aﬀected by this simulation within the M-H algorithm.
Recall that the properties of the simulated mean of the posterior were
derived under the assumption that draws can be taken from the posterior without needing to simulate the choice probabilities. M-H applied
to (12.3) violates this assumption.
Drawing from K(b, W | Y ) becomes fast and simple if each βn is
considered to be a parameter along with b and W , and Gibbs sampling
is used for the three sets of parameters b, W , and βn ∀n. The posterior

CHAPTER 12. BAYESIAN PROCEDURES

342
for b, W, and βn ∀n is:

K(b, W, βn ∀n | Y ) ∝

L(yn | βn )φ(βn | b, W )k(b, W )
n

Draws from this posterior are obtained through Gibbs sampling. A
draw of each parameter is taken, conditional on the other parameters:
(1) Take a draw of b conditional on values of W and βn ∀n. (2) Take
a draw of W conditional on values of b and βn ∀n. (3) Take a draw of
βn ∀n conditional on values of b and W . Each of these steps is easy, as
we will see. Step 1 uses result A, which gives the posterior of the mean
given the variance. Step 2 uses result B, which gives the posterior of
the variance given the mean. Step 3 uses a M-H algorithm, but in a
way that does not involve simulation within the algorithm. Each step
is described below.
1. b | W, βn ∀n. We condition on W and each person’s βn in this
step, which means that we treat these parameters as if they were
known. Result A gives us the posterior distribution of b under
these conditions. The βn ’s constitute a sample of N realizations
from a normal distribution with unknown mean b and known
variance W . Given our diﬀuse prior on b, the posterior on b is
N (β̄, W/N ), where β̄ is the sample mean of the βn ’s. A draw
from this posterior is obtained as described in section (12.5.1).
2. W | b, βn ∀n. Result B gives us the posterior for W conditional
on b and the βn ’s. The βn ’s constitute a sample from a normal
distribution with known mean b and unknown variance W . Under our prior on W , the posterior on W is inverted Wishart with
K +N degrees of freedom and scale matrix (KI +N S1 )/(K +N )

where S1 = (1/N ) n (βn − b)(βn − b) is the sample variance of
the βn ’s around the known mean b. A draw from the inverted
Wishart is obtained as described in section (12.5.2).
3. βn | b, W. The posterior for each person’s βn , conditional on their
choices and the population mean and variance of βn is
K(βb | b, W, yn ) ∝ L(yn | βn )φ(βn | b, W )

(12.5)

There is no simple way to draw from this posterior, and so the
M-H algorithm is used. Note that the right hand side of (12.5)
is easy to calculate: L(yn | βn ) is a product of logits and φ(βn |

12.6. HIERARCHICAL BAYES FOR MIXED LOGIT

343

b, W ) is the normal density. The M-H algorithm operates as
follows:
(a) Start with a value βn0 .
(b) Draw K independent values from a standard normal density
and stack the draws into a vector labeled η 1 .
(c) Create a trial value of βn1 as β̃n1 = βn0 + ρLη 1 , where ρ is
a scalar speciﬁed by the researcher and L is the Choleski
factor of W . Note that the proposal distribution (which is
labeled g(·) in section (9.2.9)) is speciﬁed to be normal with
zero mean and variance ρ2 W .
(d) Draw a standard uniform variable µ1 .
(e) Calculate the ratio
F =

L(yn | β̃n1 )φ(β̃n1 | b, W )
L(yn | βn0 )φ(βn0 | b, W )

(f) If µ1 ≤ F , accept β̃n1 and let βn1 = β̃n1 . If µ1 > F , reject β̃n1
and let βn1 = βn0 .
(g) Repeat the process many times. For high enough t, βnt is a
draw from the posterior.
We now know how to draw from the posterior for each parameter
conditional on the other parameters. We combine the procedures into a
Gibbs sampler for the three sets of parameters. Start with any initial
values b0 , W 0 , and βn0 ∀n. The t-th iteration of the Gibbs sampler
consists of these steps:
1. Draw bt from N (β̄ t−1 , W t−1 /N ) where β̄ t−1 is the mean of the
βnt−1 ’s.
2. Draw Wt from IW (K +N, (KI +N S t−1 )/(K +N )) where S t−1 =

t−1 − bt )(β t−1 − bt ) ))/N .
n
n (βn
3. For each n, draw βnt using one iteration of the M-H algorithm
described above, starting from βnt−1 and using the normal density
φ(βn | bt , W t ).
These three steps are repeated for many iterations. The resulting
values converge to draws from the joint posterior of b, W, and βn ∀n.

344

CHAPTER 12. BAYESIAN PROCEDURES

Once the converged draws from the posterior are obtained, the mean
and standard deviation of the draws can be calculated to obtain estimates and standard errors of the parameters. Note that this procedure
provides information about βn for each n, similar to the procedure described in Chapter 11 using classical estimation.
As stated, the Gibbs sampler converges, with enough iterations, to
draws from the joint posterior of all the parameters. The iterations
prior to convergence are often called “burn-in”. Unfortunately, it is
not always easy to determine when convergence has been achieved,
as emphasized by Kass et al. (1998). Cowles and Carlin (1996) provide a description of the various tests and diagnostics that have been
proposed. For example, Gelman and Rubin (1992) suggest starting
the Gibbs sampler from several diﬀerent points and testing the hypothesis that the statistic of interest (in our case, the posterior mean)
is the same when calculated from each of the presumably converged
sequences. Sometimes convergence is fairly obvious such that formal
testing is unnecessary. During burn-in, the researcher will usually be
able to see the draws trending, that is, moving toward the mass of
the posterior. After convergence has been achieved, the draws tend to
move around (“traverse”) the posterior.
The draws from Gibbs sampling are correlated over iterations even
after convergence has been achieved, since each iteration builds on
the previous one. This correlation does not prevent the draws from
being used for calculating the posterior mean and standard deviation,
or other statistics. However, the researcher can reduce the amount
of correlation among the draws by using only a portion of the draws
that are obtained after convergence. For example, the researcher might
retain every tenth draw and discard the others, thereby reducing the
correlation among the retained draws by an order of 10. A researcher
might therefore specify a total of 20,000 iterations in order to obtain
1000 draws: 10,000 for burn-in and 10,000 after convergence of which
every tenth is retained.
One issue remains. In the M-H algorithm, the scalar ρ is speciﬁed by the researcher. This scalar determines the size of each jump.
Usually, smaller jumps translate into more accepts and larger jumps
result in fewer accepts. However, smaller jumps means that the M-H
algorithm takes more iterations to converge and embodies more serial correlation in the draws after convergence. Gelman et al. (1995,
p. 335) have examined the optimal acceptance rate in the M-H algo-

12.6. HIERARCHICAL BAYES FOR MIXED LOGIT

345

rithm. They found that the optimal rate is about 0.44 when K = 1
and drops toward .23 as K rises. The value of ρ can be set by the
researcher to achieve an acceptance rate in this neighborhood, lowering ρ to obtain a higher acceptance rate and raising it to get a lower
acceptance rate.
In fact, ρ can be adjusted within the iterative process. The researcher sets the initial value of ρ. In each iteration, a trial βn is
accepted or rejected for each sampled n. If in an iteration, the acceptance rate among the N observations is above a given value (say, .33),
then ρ is raised. If the acceptance rate is below this value, ρ is lowered.
The value of ρ then moves during the iteration process to attain the
speciﬁed acceptance level.

12.6.1

Succinct restatement

Now that the Bayesian procedures have been fully described, the model
and the Gibbs sampling can be stated succinctly, in the form that is
used in most publications. The model is:
Utility:
Unjt

=

εnjt iid

βn xnjt + εnjt
extreme value

∼

N (b, W )

=

i if and only if Unit > Unjt ∀j = i

=

k(b)k(W )

k(b)

is

N (b0 , S0 ) with extremely large variance

k(W )

is

IW (K, I)

βn
Observed choice:
ynt
Priors:
k(b, W )
where

The conditional posteriors are:


K(βn | b, W, yn ) ∝

eβn xnynt t
φ(βn | b, W )
 x
βn
njt
je

∀n


t

K(b | W, βn ∀n) is N (β̄, W/N )), where β̄ =

βn /N
n

K(W | b, βn ∀n) is IW (K + N, (KI + N S̄)/(K + N )),

346

CHAPTER 12. BAYESIAN PROCEDURES
(βn − b)(βn − b) /N

where S̄ =
n

The three conditional posteriors are called “layers” of the Gibbs
sampling. The ﬁrst layer for each n depends only on data for that
person, rather than for the entire sample. The second and third layers
do not depend on the data directly, only on the draws of βn which
themselves depend on the data.
The Gibbs sampling for this model is fast for two reasons. First,
none of the layers requires integration. In particular, the ﬁrst layer utilizes a product of logit formulas for a given value of βn . The Bayesian
procedure avoids the need to calculate the mixed logit probability, utilizing instead the simple logits conditional βn . Second, layers 2 and 3
do not utilize the data at all, since they depend only on the draws of
βn ∀n. Only the mean and variance of the βn ’s need be calculated in
these layers.
The procedure is often called “hierarchical Bayes” (HB) because
there is a hierarchy of parameters. βn is the “individual-level parameters” for person n, which describe the tastes of that person. The βn ’s
are distributed in the population with mean b and variance W . The
parameters b and W are often called the “population-level parameters”
or “hyper-parameters”. There is also a hierarchy of priors. The prior
on each person’s βn is the density of βn in the population. This prior
has parameters (hyper-parameters), namely its mean b and variance
W , which themselves have priors.

12.7

Case Study: Choice of energy supplier

We apply the Bayesian procedures to the data that were described
in Chapter 11 regarding customers’ choice among energy suppliers.
The Bayesian estimates are compared with estimates obtained through
maximum simulated likelihood (MSL).
Each of 361 customers was presented with up to 12 hypothetical
choice situations. In each choice situation, four energy suppliers were
described and the respondent was asked which one he would choose if
facing the choice in the real world. The suppliers were diﬀerentiated on
the basis of six factors: (1) whether the supplier charged ﬁxed prices,
and if so the rate in cents per kilowatt-hour (kWh), (2) the length
of contract in years, during which the rates were guaranteed and the
customer would be required a penalty to switch to another supplier,

12.7. CASE STUDY: CHOICE OF ENERGY SUPPLIER

347

(3) whether the supplier was the local utility, (4) whether the supplier
was a well-known company other than the local utility, (5) whether the
supplier charged time-of-day (TOD) rates at speciﬁed prices in each
period, and (6) whether the supplier charged seasonal rates at speciﬁed
prices in each season. In the experimental design, the ﬁxed rates varied
over situations, but the same prices were speciﬁed in all experiments
whenever a supplier was said to charge TOD or seasonal rates. The
coeﬃcient of the dummies for TOD and seasonal rates therefore reﬂect
the value of these rates at the speciﬁed prices. The coeﬃcient of the
ﬁxed price indicates the value of each cent per kWh.

12.7.1

Independent normal coeﬃcients

A mixed logit model was estimated under the initial assumption that
the coeﬃcients are independently normally distributed in the population. That is, βn ∼ N (b, W ) with diagonal W . The population
parameters are the mean and standard deviation of each coeﬃcient.
Table 12.1 gives the simulated mean of the posterior (SMP) for these
parameters, along with the MSL estimates. For the Bayesian procedure, 20,000 iterations of the Gibbs sampling were performed. The
ﬁrst 10,000 iterations were considered burn-in, and every tenth draw
was retained after convergence, for a total of 1000 draws from the posterior. The mean and standard deviation of these draws constitutes the
estimates and standard errors. For MSL, the mixed logit probability
was simulated with 200 Halton draws for each observation.
The two procedures provide similar results in this application. The
scale of the estimates from the Bayesian procedure is somewhat larger
than that for MSL. This diﬀerence indicates that the posterior is
skewed, with the mean exceeding the mode. When the MSL estimates
are scaled to have the same estimated mean for the price coeﬃcient,
the two sets of estimates are remarkably close, in standard errors as
well as point estimates. Run time was essentially the same for each
approach.
In other applications, e.g., Ainslie et al. (2001), the MSL and SMP
estimates have diﬀered. In general, the magnitude of diﬀerences depends on the number of observations relative to the number of parameters, as well as the amount of variation that is contained in the
observations. When the two sets of estimates diﬀer, it means that
the asymptotics are not yet operating completely (i.e., sample size is

348

CHAPTER 12. BAYESIAN PROCEDURES

Table 12.1: Mixed Logit Model of Choice Among Energy Suppliers
Estimates
(se’s in parens.)
Price coef:

mean
st dev

Contract coef:

mean
st dev

Local coef:

mean
st dev

Well-known coef:

mean
st dev

TOD coef:

mean
st dev

Seasonal coef:

mean
st dev

MSL

SMP

Scaled MSL

-0.976
(.0370)
.230
(.0195)
-0.194
(.0224)
.405
(.0238)
2.24
(.118)
1.72
(.122)
1.62
(.0865)
1.05
(.0849)
-9.28
(.314)
2.00
(.147)
-9.50
(.312)
1.24
(.188)

-1.04
(.0374)
.253
(.0169)
-0.240
(.0269)
.426
(.0245)
2.41
(.140)
1.93
(.123)
1.71
(.100)
1.28
(.0940)
-10.0
(.315)
2.51
(.193)
-10.2
(.310)
1.66
(.182)

-1.04
(.0396)
.246
(.0209)
-0.208
(.0240)
.434
(.0255)
2.40
(.127)
1.85
(.131)
1.74
(.0927)
1.12
(.0910)
-9.94
(.337)
2.14
(.157)
-10.2
(.333)
1.33
(.201)

12.7. CASE STUDY: CHOICE OF ENERGY SUPPLIER

349

insuﬃcient for the asymptotic properties to be fully exhibited). The
researcher might want to apply a Bayesian perspective in this case (if
she is not already doing so) in order to utilize the Bayesian approach
to small sample inference. The posterior distribution contains the relevant information for Bayesian analysis with any sample size, whereas
the classical perspective requires the researcher to rely on asymptotic
formulas for the sampling distribution that need not be meaningful
with small samples. Allenby and Rossi (1999) provide examples of the
diﬀerences and the value of the Bayesian approaches and perspective.
We re-estimated the model under a variety of other distributional
assumptions. In the following sections, we describe how each method is
implemented under these alternative assumptions. For reasons that are
inherent to the methodologies, the Bayesian procedures are easier and
faster for some types of speciﬁcations, while the classical procedures are
easier and faster for other speciﬁcations. Understanding these realms of
relative convenience can assist the researcher in deciding which method
to use for a particular model.

12.7.2

Multivariate normal coeﬃcients

We now allow the coeﬃcients to be correlated. That is, W is full
rather than diagonal. The classical procedure is the same except that
drawing from φ(βn | b, W ) for the simulation of the mixed logit probability requires creating correlation among independent draws from
a random number generator. The model is parameterized in terms
of the Choleski factor of W , labeled L. The draws are calculated as
β˜n = b + Lη where η is a draw of a K-dimensional vector of independent standard normal deviates. In terms of computation time for
MSL, the main diﬀerence is that the model has far more parameters
with full W than when W is diagonal: K +K(K +1)/2 rather than the
2K parameters for independent coeﬃcients. In our case with K = 6,
the number of parameters rises from 12 to 27. The gradient with respect to each of the new parameters takes time to calculate, and the
model requires more iterations to locate the maximum over the largerdimensioned log-likelihood function. As shown in the second line of
Table 12.2, the run time nearly triples for the model with correlated
coeﬃcients relative to independent coeﬃcients.
With the Bayesian procedure, correlated coeﬃcients are no harder
to handle than uncorrelated ones. For full W , the inverted gamma dis-

350

CHAPTER 12. BAYESIAN PROCEDURES

Table 12.2: Run-Times in minutes
Speciﬁcation
All normal, no correlations
All normal, full covariance
1 ﬁxed, others normal, no corr
3 lognormal, 3 normal, no corr
All triangular, no corr

MSL
48
139
42
69
56

SMP
53
55
112
54
206

tribution is replaced with its multivariate generalization, the inverted
Wishart. Draws are obtained by the procedure in section (12.5.2). The
only extra computer time relative to independent coeﬃcients arises in
the calculation of the covariance matrix of the βn ’s and its Choleski
factor, rather than the standard deviations of the βn ’s. This diﬀerence is trivial for typical numbers of parameters. As shown in Table
12.2, run time for the model with full covariance among the random
coeﬃcients was essentially the same as with independent coeﬃcients.

12.7.3

Fixed coeﬃcients for some variables

There are various reasons that the researcher might choose to specify
some of the coeﬃcients as ﬁxed. (1) Ruud (1996) argues that a mixed
logit with all random coeﬃcients is nearly unidentiﬁed empirically,
since only ratios of coeﬃcients are economically meaningful. He recommends holding at least one coeﬃcient ﬁxed, particularly when the
data contain only one choice situation for each decision-maker. (2) In
a model with alternative-speciﬁc constants, the ﬁnal iid extreme-value
terms constitute the random portion of these constants. Allowing the
coeﬃcients of the alternative-speciﬁc dummies to be random in addition to having the ﬁnal iid extreme-value terms is equivalent to assuming that the constants follow a distribution that is a mixture of extreme
value and whatever distribution is assumed for these coeﬃcients. If
the two distributions are similar, such as a normal and extreme value,
the mixture can be unidentiﬁable empirically. In this case, the analyst might choose to keep the coeﬃcients of the alternative-speciﬁc
constants ﬁxed. (3) The goal of the analysis might be to forecast substitution patterns correctly rather than to understand the distribution
of coeﬃcients. In this case, error components can be speciﬁed that
capture the correct substitution patterns while holding the coeﬃcients

12.7. CASE STUDY: CHOICE OF ENERGY SUPPLIER

351

of the original explanatory variables ﬁxed (as in Brownstone and Train,
1999.) (4) The willingness to pay (wtp) for an attribute is the ratio of
the attribute’s coeﬃcient to the price coeﬃcient. If the price coeﬃcient
is held ﬁxed, the distribution of wtp is simply the scaled distribution
of the attribute’s coeﬃcient. The distribution of wtp is more complex
when the price coeﬃcient varies also. Furthermore, if the usual distributions are used for the price coeﬃcient, such as normal or lognormal,
the issue arises of how to handle positive price coeﬃcients, price coefﬁcients that are close to zero such that the implied wtp is extremely
high, and price coeﬃcients that are extremely negative. The ﬁrst of
these issues is avoided with lognormals, but not the other two. The
analyst might choose to hold the price coeﬃcient ﬁxed to avoid these
problems.
In the classical approach, holding one or more coeﬃcient ﬁxed is
very easy. The corresponding elements of W and L are simply set to
zero, rather than treated as parameters. Run time is reduced since
there are fewer parameters. As indicated in the third line of Table
12.2, run time decreased by about 12 percent with one ﬁxed coeﬃcient
and the rest independent normal relative to all independent normals.
With correlated normals, a larger percent reduction would occur, since
the number of parameters drops more than proportionately.
In the Bayesian procedure, allowing for ﬁxed coeﬃcients requires
the addition of a new layer of Gibbs sampling. The ﬁxed coeﬃcient
cannot be drawn as part of the M-H algorithm for the random coeﬃcients for each person. Recall that under M-H, trial draws are accepted
or rejected in each iteration. If a trial draw, which contains a new value
of a ﬁxed coeﬃcient along with new values of the random coeﬃcients,
is accepted for one person, but the trial draw for another person is not
accepted, then the two people will have diﬀerent values of the ﬁxed
coeﬃcient, which contradicts the fact that it is ﬁxed. Instead, the random coeﬃcients, and the population parameters of these coeﬃcients,
must be drawn conditional on a value of the ﬁxed coeﬃcients; and
then the ﬁxed coeﬃcients are drawn conditional on the values of the
random coeﬃcients. Drawing from the conditional posterior for the
ﬁxed coeﬃcients requires a M-H algorithm, in addition to the M-H
algorithm that is used to draw the random coeﬃcients.
To be explicit, rewrite the utility function as
Unjt = α znjt + βn xnjt + εnjt ,

(12.6)

CHAPTER 12. BAYESIAN PROCEDURES

352

where α is a vector of ﬁxed coeﬃcients and βn is random as before
with mean b and variance W . The probability of the person’s choice
sequence given α and βn is


L(yn | α, βn ) =
t



eα znynt t +βn xnynt t
 α z +β  x .
njt
n njt
je

(12.7)

The conditional posteriors for Gibbs sampling are:
1. K(βn | α, b, W ) ∝ L(yn | α, βn )φ(βn | b, W ). M-H is used for
these draws in the same way as with all normals, except that
now α znjt is included in the logit formulas.


2. K(b | W, βn ∀n) is N ( n βn /N, W/N )). Note that α does not
enter this posterior; its eﬀect is incorporated into the draws of
βn from layer 1.
3. K(W | b, βn ∀n) is IW (K + N, (KI + N S̄)/(K + N )) where

S̄ = n (βn − b)(βn − b) /N . Again, α does not enter directly.


4. K(α | βn ) ∝ n L(yn | α, βn ), if the prior on α is essentially
ﬂat (e.g., normal with suﬃciently large variance.) Draws are
obtained with M-H on the pooled data.
Layer 4 takes as much time as layer 1, since each involves calculation of a logit formula for each observation. The Bayesian procedure
with ﬁxed and normal coeﬃcients can therefore be expected to take
about twice as much time as with all normal coeﬃcients. As indicated
in the third line of Table 12.2, this expectation is conﬁrmed in our
application.

12.7.4

Lognormals

Lognormal distributions are often speciﬁed when the analyst wants to
assure that the coeﬃcient takes the same sign for all people. Little
changes in either procedure when some or all of the coeﬃcients are
distributed lognormal instead of normal. Normally distributed coeﬃcients are drawn, and then the ones that are lognormally distributed
are exponentiated when they enter utility. With all lognormals, utility
is speciﬁed as
(12.8)
Unjt = (eβn ) xnjt + εnjt ,

12.7. CASE STUDY: CHOICE OF ENERGY SUPPLIER

353

with βn distributed normal as before with mean b and variance W .
The probability of the person’s choice sequence given βn is
β n ) x

e(e

L(yn | α, βn ) =


t

nynt t

(eβn ) x

je

njt

.

(12.9)

With this one change, the rest of the steps are the same with both
procedures. In the classical approach, however, locating the maximum
of the likelihood function is considerably more diﬃcult with lognormal coeﬃcients than normal ones. Often the numerical maximization
procedures fail to ﬁnd an increase after a number of iterations. Or
a “maximum” is found and yet the Hessian is singular at that point.
It is often necessary to specify starting values that are close to the
maximum. And the fact that the iterations can fail at most starting
values makes it diﬃcult to determine whether a maximum is local or
global. The Bayesian procedure does not encounter these diﬃculties
since it does not search for the maximum. The Gibbs sampling seems
to converge a bit more slowly, but not appreciably so. As indicated
in Table 12.2, run time for the classical approach rose nearly 50 percent with lognormal relative to normals (due to more iterations being
needed), while the Bayesian procedure took about the same amount of
time with each. This comparison is generous to the classical approach,
since convergence at a maximum was achieved in this application while
in many other applications we have not been able to obtain convergence
with lognormals or have done so only after considerable time was spent
ﬁnding successful starting values.

12.7.5

Triangulars

Normal and lognormal distributions allow coeﬃcients of unlimited magnitude. In some situations, the analyst might want to assure that the
coeﬃcients for all people remain within a reasonable range. This goal
is accomplished by specifying distributions that have bounded support, such as uniform, truncated normal, and triangular distributions.
In the classical approach, these distributions are easy to handle. The
only change occurs in the line of code that creates the random draws
from the distributions. For example, the density of a triangular distribution with mean b and “spread” s is zero beyond the range (b−s, b+s),
rises linearly from b − s to b, and drops linearly to b + s. $A draw is
√
created as βn = b + s( 2µ − 1) if µ < 0.5 and = b + s(1 − 2(1 − µ))

CHAPTER 12. BAYESIAN PROCEDURES

354

otherwise, where µ is a draw from a standard uniform. Given draws of
βn , the calculation of the simulated probability and the maximization
of the likelihood function are the same as with draws from a normal.
Experience indicates that estimation of the parameters of uniform,
truncated normal and triangular distributions takes about the same
number of iterations as for normals. The last line of Table 12.2 reﬂects
this experience.
With the Bayesian approach, the change to non-normal distributions is far more complicated. With normally distributed coeﬃcients,
the conditional posterior for the population moments are very convenient: normal for the mean and inverted Wishart for the variance.
Most other distributions do not give such convenient posteriors. Usually, a M-H algorithm is needed for the population parameters, in addition to the M-H algorithm for the customer-level βn ’s. This addition
adds considerably to computation time. The issue is exacerbated for
distributions with bounded support, since, as we see below, the M-H
algorithm can be expected to converge slowly for these distributions.
With independent triangular distributions for all coeﬃcients with
mean and spread vectors b and s, and ﬂat priors on each, the conditional posteriors are:
1. K(βn | b, s) ∝ L(yn | βn )h(βn | b, s) where h is the triangular
density. Draws are obtained through M-H, separately for each
person. This step is the same as with independent normals except
that the density for βn is changed.


2. K(b, s | βn ) ∝ n h(βn | b, s) when the priors on b and s are
essentially ﬂat. Draws are obtained through M-H on the βn ’s for
all people.
Because of the bounded support of the distribution, the algorithm
is exceedingly slow to converge. Consider, for example, the spread of
the distribution. In the ﬁrst layer, draws of βn that are outside the
range (b − s, b + s) from the second layer are necessarily rejected. And
in the second layer, draws of b and s that create a range (b − s, b + s)
that does not cover all the βn ’s from the ﬁrst layer are necessarily
rejected. It is therefore diﬃcult for the range to grow narrower from
one iteration to the next. For example, if the range is 2 to 4 in one
iteration of the ﬁrst layer, then the next iteration will result in values of
βn between 2 and 4 and will usually cover most of the range if sample

12.8. BAYESIAN PROCEDURES FOR PROBIT MODELS

355

size is suﬃciently large. In the next draw of b and s, any draw that
does not cover the range of the βn ’s (which is nearly 2 to 4) will be
rejected. There is indeed some room for play, since the βn ’s will not
cover the entire range from 2 to 4. The algorithm converges, but in our
application we found that far more iterations were needed to achieve a
semblance of convergence, compared with normal distributions. Run
time rose by a factor of four as a result.

12.7.6

Summary of results

For normal distributions with full covariance matrixes, and for transformations of normals that can be expressed in the utility function,
such as exponentiating to represent lognormal distributions, the Bayesian
approach seems to be very attractive computationally. Fixed coeﬃcients add a layer of conditioning to the Bayesian approach that doubles its run time. In contrast, the classical approach becomes faster
for each coeﬃcient that is ﬁxed instead of random, because there are
fewer parameters to estimate. For distributions with bounded support,
like triangulars, the Bayesian approach is very slow, while the classical
approach handles these distributions as quickly as normals.
These comparisons relate to mixed logits only. Other behavioral
models can be expected to have diﬀerent relative run times for the two
approaches. The comparison with mixed logit elucidates the issues
that arise in implementing each method. Understanding these issues
assists the researcher in specifying the model and method that is most
appropriate and convenient for the choice situation.

12.8

Bayesian procedures for probit models

Bayesian procedures can be applied to probit models. In fact, the
methods are even faster for probit models than mixed logits. The procedure is described by Albert and Chib (1993), McCulloch and Rossi
(1994), Allenby and Rossi (1999), and McCulloch and Rossi (2000).
The method diﬀers in a critical way from the procedure for mixed
logits. In particular, for a probit model, the probability of each person’s choices condition on the coeﬃcients of the variables, which is the
analog to L(yn | βn ) for logit, is not a closed form. Procedures that
utilize this probability, as in the ﬁrst layer of Gibbs sampling for mixed
logit, cannot be readily applied to probit. Instead, Gibbs sampling for

356

CHAPTER 12. BAYESIAN PROCEDURES

probits is accomplished by considering the utility of each alternative,
Unjt , to be parameters themselves. The conditional posterior for each
Unjt is truncated normal, which is easy to draw from. The layers for
the Gibbs sampling are:
1. Draw b conditional on W and βn ∀n.
2. Draw W conditional on b and βn ∀n. These two layers are the
same as for mixed logit.
3. For each n, draw βn conditional on Unjt ∀j, t. These draws are
obtained by recognizing that, given the value of utility, the function Unjt = βn xnjt + εnjt is a regression of xnjt on Unjt . Bayesian
posteriors for regression coeﬃcients and normally distributed errors have been derived (similar to our results A and B) and are
easy to draw from.
4. For each n, i, t, draw Unit conditional on βn and the value of Unjt
for each j = i. As stated above, the conditional posterior for
each Unit is a univariate truncated normal, which is easy to draw
from with the procedure given in section (9.2.4).
Details are provided in the cited articles.
Bolduc, Fortin and Gordon (1997) compared the Bayesian method
with MSL and found the Bayesian procedure to require about half as
much computer time as MSL with random draws. If Halton draws
had been used, it seems that MSL would have been faster for the
same level of accuracy, since fewer than half as many draws would
be needed. The Bayesian procedure for probit relies on all random
terms being normally distributed. However, the concept of treating
the utilities as parameters can be generalized for other distributions,
giving a Bayesian procedure for mixed probits.
Bayesian procedures can be developed in some form or another for
essentially any behavioral model. In many cases, they provide large
computational advantages over classical procedures. Examples include
the dynamic discrete choice models of Ching, Imai and Jain (2001), the
joint models of the timing and quantity of purchases of Boatwright,
Borle and Kadane (2001), and Brownstone’s (2001) mixtures of distinct
discrete choice models. The power of these procedures, and especially
the potential for cross-fertilization with classical methods, create a
bright outlook for the ﬁeld.

Bibliography
Adamowicz, W. (1994), ‘Habit formation and variety seeking in a discrete choice model of recreation demand’, Journal of Agricultural
and Resource Economics 19, 19–31.
Ainslie, A., R. Andrews and I. Currim (2001), ‘An empirical comparison of logit choice models with discrete vs. continuous representation of heterogeneity’, Working Paper, Department of Business
Administration, University of Delaware.
Albert, J. and S. Chib (1993), ‘Bayesian analysis of binary and polychotomous response data’, Journal of the American Statistical Association 88, 669–679.
Allenby, G. (1997), ‘An introduction to hierarchical bayesian modeling’, Tutorial notes, Advanced Research Techniques Forum,
American Marketing Association.
Allenby, G. and P. Lenk (1994), ‘Modeling household purchase behavior with logistic normal regression’, Journal of the American
Statistical Association 89, 1218–1231.
Allenby, G. and P. Rossi (1999), ‘Marketing models of consumer heterogeneity’, Journal of Econometrics 89, 57–78.
Amemiya, T. (1978), ‘On two-step estimation of multivariate logit
models’, Journal of Econometrics 8, 13–21.
Arora, N., G. Allenby and J. Ginter (1998), ‘A hierachical bayes model
of primary and secondary demand’, Marketing Science 17, 29–44.
Beggs, S., S. Cardell and J. Hausman (1981), ‘Assessing the potential
demand for electric cars’, Journal of Econometrics 16, 1–19.
357

358

BIBLIOGRAPHY

Bellman, R. (1957), Dynamic Programming, Princeton University
Press, Princeton NJ.
Ben-Akiva, M. (1972), The Structure of Travel Demand Models, PhD
thesis, MIT.
Ben-Akiva, M. and B. Francois (1983), ‘Mu-homogenous generalized
extreme value model’, Working Paper, Department of Civil Engineering, MIT.
Ben-Akiva, M. and D. Bolduc (1996), ‘Multinomial probit with a
logit kernel and a general parametric speciﬁcation of the covariance structure’, Working Paper, Department of Civil Engineering,
MIT.
Ben-Akiva, M., D. Bolduc and J. Walker (2001), ‘Speciﬁcation, estimation and identiﬁcation of the logit kernel (or continuous mixed
logit) model’, Working Paper, Department of Civil Engineering,
MIT.
Ben-Akiva, M., D. Bolduc and M. Bradley (1993), ‘Estimation of travel
model choice models with randomly distributed values of time’,
Transportation Research Record 1413, 88–97.
Ben-Akiva, M. and M. Bierlaire (1999), Discrete choice methods and
their applications in short term travel decisions, in R.Hall, ed.,
‘The Handbook of Transportation Science’, Kluwer, Dordrecht,
the Netherlands, pp. 5–33.
Ben-Akiva, M. and S. Lerman (1985), Discrete Choice Analysis : Theory and Application to Travel Demand, MIT Press, Cambridge,
Massahusetts.
Ben-Akiva, M. and T. Morikawa (1990), ‘Estimation of switching models from revealed preferences and stated intentions’, Transportation Research A 24, 485–495.
Berkovec, J. and S. Stern (1991), ‘Job exit behavior of older men’,
Econometrica 59, 189–210.
Berndt, E., B. Hall, R. Hall and J. Hausman (1974), ‘Estimation and
inference in nonlinear structural models’, Annals of Economic and
Social Measurement 3/4, 653–665.

BIBLIOGRAPHY

359

Bernstein, S. (1917), Calcul des probabilites.
Berry, S. (1994), ‘Estimating discrete choice models of product diﬀerentiation’, RAND Journal of Economics 25, 242–262.
Berry, S., J. Levinsohn and A. Pakes (1995), ‘Automobile prices in
market equilibrium’, Econometrica 63, 841–889.
Bhat, C. (1995), ‘A heteroscedastic extreme value model of intercity
mode choice’, Transportation Research B 29, 471–483.
Bhat, C. (1997), ‘Covariance heterogeneity in nested logit models:
Econometric structure and application to intercity travel’, Transportation Research B 31, 11–21.
Bhat, C. (1998a), ‘Accommodating variations in responsiveness to
level-of-service variables in travel mode choice models’, Transportation Research A 32, 455–507.
Bhat, C. (1998b), ‘An analysis of travel mode and departure time
choice for urban shopping trips’, Transportation Research B
32, 361–371.
Bhat, C. (1999), ‘An analysis of evening commute stop-making behavior using repeated choice observation from a multi-day survey’,
Transportation Research B 33, 495–510.
Bhat, C. (2000), ‘Incorporating observed and unobserved heterogeneity in urban work mode choice modeling’, Transportation Science
34, 228–238.
Bhat, C. (2001), ‘Quasi-random maximum simulated likelihood estimation of the mixed multinomial logit model’, Transportation Research B 35, 677–693.
Bhat, C. (forthcoming), ‘Simulation estimation of mixed discrete
choice models using randomized and scrambled halton sequences’,
Transportation Research .
Bhat, C. and S. Castelar (2001), ‘A uniﬁed mixed logit framework
for modeling revealed and stated preferences: Formulation and
application to congestion pricing analysis in the san francisco bay
area’, Transportation Research .

360

BIBLIOGRAPHY

Bickel, P. and K. Doksum (2000), Mathematical Statistics: Basic ideas
and Selected Topics, Vol. 1, Prentice Hall, Upper Saddle River,
NJ.
Bierlaire, M. (1998), Discrete choice models, in m. Labbe, G.Laporte,
K.Tanczos and P.Toint, eds, ‘Operations Research and Decision
Aid Methodologies in Traﬃc and Transportation Management’,
Spinger Verlag, Heidelberg, Germany, pp. 203–227.
Boatwright, P., S. Borle and J. Kadane (2001), ‘A model of the joint
distribution of purchase quantity and timing’, Conference Presentation, Bayesian Applications and Methods in Marketing Conference, Ohio State University.
Bolduc, D. (1992), ‘Generalized autoregressive errors: the multinomial
probit model’, Transportation Research B 26, 155–170.
Bolduc, D. (1993), ‘Maximum simulated likelihood estimation of mnp
models using the ghk probability simulation with analytic derivatives’, Working Paper, Department d’ Economique, Universite
Laval, Quebec.
Bolduc, D. (1999), ‘A practical technique to estimate multinomial probit models in transportation’, Transportation Research B 33, 63–
79.
Bolduc, D., B. Fortin and M. Fournier (1996), ‘The impact of incentive
policies on the practice location of doctors: A multinomial probit
analysis’, Journal of Labor Economics 14, 703–732.
Bolduc, D., B. Fortin and S. Gordon (1997), ‘Multinomial probit estimation of spatially interdependent choices: An empirical comparison of two new techniques’, International Regional Science
Review 20, 77–101.
Borsch-Supan, A. and V. Hajivassiliou (1993), ‘Smooth unbiased multivariate probablility simulation for maximum likelihood estimation
of limited dependent variable models’, Journal of Econometrics
58, 347–368.
Borsch-Supan, A., V. Hajivassiliou, L. Kotlikoﬀ and J. Morris (1991),
Health, children, and elderly living arrangements: A multiperiod

BIBLIOGRAPHY

361

multinomial probit model with unobserved heterogeneity and autocorrelated errors, in D.Wise, ed., ‘Topics in the Economics of
Aging’, University of Chicago Press, Chicago, IL.
Boyd, J. and J. Mellman (1980), ‘The eﬀect of fuel economy standards on the u.s. automotive market: a hedonic demand analysis’,
Transportation Research A 14, 367–378.
Braatan and Weller (1979), ‘An improved low-discrepancy sequence
for multi-dimensional quasi-monte carlo integration’, Journal of
Computational Physics 33, 249–258.
Bradley, M. and Andrew Daly (1994), ‘Use of the logit scaling approach
to test for rank-order and fatigue eﬀects in stated preference data’,
Transportation 21, 167–184.
Bradlow, E. and P. Fader (2001), ‘A bayesian lifetime model for the
’hot 100’ billboard songs’, Working Paper, The Wharton School,
University of Pennsylvania.
Brownstone, D. (2001), Discrete choice modeling for transportation, in
D.Hensher, ed., ‘Travel Behavior Research: The Leading Edge’,
Elsevier, Oxford, UK, pp. 97–124.
Brownstone, D., D. Bunch and K. Train (2000), ‘Joint mixed logit
models of stated and revealed preferences for alternative-fuel vehicles’, Transportation Research B 34, 315–338.
Brownstone, D. and K. Small (1989), ‘Eﬃcient estimation of nested
logit model’, Journal of Business and Economic Statistics 7, 67–
74.
Brownstone, D. and K. Train (1999), ‘Forecasting new product penetration with ﬂexible substitution patterns’, Journal of Econometrics 89, 109–129.
Bunch, D. (1991), ‘Estimability in the multinomial probit model’,
Transportation Research B 25, 1–12.
Bunch, D. and R. Kitamura (1989), ‘Multinomial probit estimation
revisited: Testing new algorithms and evaluation of alternative
model speciﬁcation of household car ownership’, Transportation
Research Group Report UCD-TRG-RR-4, University of California, Davis.

362

BIBLIOGRAPHY

Butler, J. and R. Moﬃtt (1982), ‘A computationally eﬃcient quadrature procedure for the one factor multinomial probit model’,
Econometrica 50, 761–764.
Cai, Y., I. Deilami and K. Train (1998), ‘Customer retention in a
competitive power market: Analysis of a ‘double-bounded plus
follow-ups’ questionnaire’, The Energy Journal 19, 191–215.
Cam, L. Le and G. Yang (1990), Asymptotics in Statistics, SpringerVerlag, New York.
Cameron, T. (1988), ‘A new paradigm for valuing non-market goods
using referendum data: Maximum likelihood estimation by censored logistic regression’, Journal of Environmental Economics
and Management 15, 355–379.
Cameron, T. and J. Quiggin (1994), ‘Estimation using contingent valuation data from a ‘dichotomous choice with follow-up’ questionnaire’, Journal of Environmental Economics and Management
27, 218–234.
Cameron, T. and M. James (1987), ‘Eﬃcient estimation methods for
closed-ended contingent valuation survey data’, Review of Economics and Statistics 69, 269–276.
Cardell, S. and F. Dunbar (1980), ‘Measuring the societal impacts of
automobile downsizing’, Tranportation Research A 14, 423–434.
Carneiro, P., J. Heckman and E. Vytlacil (2001), ‘Estimating the returns to education when it varies among individuals’, Working
Paper, Department of Economics, University of Chicago.
Casella, G. and E. George (1992), ‘Explaining the gibbs sampler’, The
American Statistician 46, 167–174.
Chapman, R. and R. Staelin (1982), ‘Exploiting rank ordered choice
set data within the stochastic utility model’, Journal of Marketing
Research 14, 288–301.
Chesher, A. and J. Santos-Silva (2002), ‘Taste variation in discrete
choice models’, Review of Economic Studies 69, 62–78.

BIBLIOGRAPHY

363

Chiang, J., S. Chib and C. Narasimhan (1999), ‘Markov chain monte
carlo and models of consideration set and parameter heterogeneity’, Journal of Econometrics 89, 223–248.
Chib, S. and E. Greenberg (1995), ‘Understanding the metropolis hastings algorithm’, American Statistician 49, 327–335.
Chib, S. and E. Greenberg (1996), ‘Markov chain monte carlo simulation methods in econometrics’, Econometric Theory 12, 409–431.
Chib, S. and E. Greenberg (1998), ‘Analysis of multivariate probit
models’, Biometrika 85, 347–361.
Ching, A., S. Imai and N. Jain (2001), ‘Bayesian estimation of dynamics discrete choice models’, Conference Presentation, Bayesian Applications and Methods in Marketing Conference, Ohio State University.
Chintagunta, P., D. Jain and N. Vilcassim (1991), ‘Investigating heterogeneity in brand preference in logit models for panel data’,
Journal of Marketing Research 28, 417–428.
Chipman, J. (1960), ‘The foundations of utility’, Econometrica
28, 193–224.
Chu, C. (1981), Structural Issues and Sources of Bias in Residential
Location and Travel Choice Models, PhD thesis, Northwestern
University.
Chu, C. (1989), ‘A paired combinational logit model for travel demand
analysis’, Proceedings of Fifth World Conference on Transportation Research 4, 295–309.
Clark, C. (1961), ‘The greatest of a ﬁnite set of random variables’,
Operations Research 9, 145–162.
Cosslett, S. (1981), Eﬃcient estimation of discrete choice models, in
C.Manski and D.McFadden, eds, ‘Structural Analysis of Discrete
Data with Econometric Applications’, MIT Press, Cambridge,
MA.
Cowles, M. and B. Carlin (1996), ‘Markov chain monte carlo convergence diagnostics: A comparative review’, Journal of American
Statistical Association 91, 883–904.

364

BIBLIOGRAPHY

Daganzo, C. (1979), Multinomial Probit: The Theory and Its Application to Demand Forecasting, Academic Press, New York.
Daganzo, C., F. Bouthelier and Y. Sheﬃ (1977), ‘Multinomial probit
and qualitative choice: A computationally eﬃcient algorithm’,
Transportation Science 11, 338–358.
Dagsvik, J. (1994), ‘Discrete and continuous choice max-stable processes and independence from irrelevant alternatives’, Econometrica 62, 1179–205.
Daly, A. (1987), ‘Estimating ’tree’ logit models’, Transportation Research B 21, 251–267.
Daly, A. and S. Zachary (1978), Improved multiple choice models, in
D.Hensher and M.Dalvi, eds, ‘Determinants of Travel Choice’,
Saxon House, Sussex.
Debreu, G. (1960), ‘Review of r.d. luce individual choice behavior’,
American Economic Review 50, 186–88.
DeSarbo, W., V. Ramaswamy and S. Cohen (1995), ‘Market segmentation with choice-based conjoint analysis’, Marketing Letters
6, 137–147.
Desvousges, W., S. Waters and K. Train (1996), ‘Potential economic
losses associated with recreational services in the upper clark fork
river basin’, Report, Triangle Economic Research, Durham, NC.
Dubin, J. and D. McFadden (1984), ‘An econometric analysis of residential electric appliance holdings and consumption’, Econometrica 52, 345–362.
Eckstein, Z. and K. Wolpin (1989), ‘The speciﬁcation and estimation
of dynamic stochastic discrete choice models: A survey’, Journal
of Human resources 24, 562–598.
Elrod, T. and M. Keane (1995), ‘A factor analytic probit model for
representing the market structure in panel data’, Journal of Marketing Research 32, 1–16.
Erdem, T. (1996), ‘A dynamic analysis of market structure based on
panel data’, Marketing Science 15, 359–378.

BIBLIOGRAPHY

365

Forinash, C. and F. Koppelman (1993), ‘Application and interpretation
of nested logit models of intercity mode choice’, Transportation
Research Record 1413, 98–106.
Gelman, A. (1992), ‘Iterative and non-iterative simulation algorithms’,
Computing Science and Statistics (Interface Proceedings) 24, 433–
438.
Gelman, A. and D. Rubin (1992), ‘Inference from iterative simulation
using multiple sequences’, Statistical Sciences 7, 457–511.
Gelman, A., J. Carlin, H. Stern and D. Rubin (1995), Bayesian Data
Analysis, Chapman and Hall, Suﬀolk.
Geman, S. and D. Geman (1984), ‘Stochastic relaxation gibbs distributions and the bayesian restoration of images’, IEEE Transactions
on Pattern Analysis and Machine Intelligence 6, 721–741.
Geweke, J. (1988), ‘Antithetic acceleration of monte carlo integration
in bayesian inference’, Journal of Econometrics 38, 73–89.
Geweke, J. (1989), ‘Bayesian inference in econometric models using
monte carlo integration’, Econometrica 57, 1317–1339.
Geweke, J. (1991), ‘Eﬃcient simulation from the multivariate normal
and student -t distributions subject to linear constraints’, Computer Science and Statistics: Proceedings of the Twenty-Third
Symposium on the Interface pp. 571–578.
Geweke, J. (1992), Evaluating the accuracy of sampling-based approaches to the calculation of posterior moments, in J.Bernardo,
J.Berger, A.Dawid and F.Smith, eds, ‘Bayesian Statistics’, Oxford
University Press, New York, pp. 169–193.
Geweke, J. (1996), Monte carlo simulation and numerical integration,
in D.Kendrick and J.Rust, eds, ‘Handbook of Computational Economics’, Elsevier Science, Amsterdam, pp. 731–800.
Geweke, J. (1997), Posterior simulators in econometrics, in D.Kreps
and K.Wallis, eds, ‘Advance Economics and Econometric Theory
and Applications’, Cambridge University Press, New York.

366

BIBLIOGRAPHY

Geweke, J., M. Keane and D. Runkle (1994), ‘Alternative computational approaches to inference in the multinomial probit model’,
Review of Economics and Statistics 76, 609–632.
Gourieroux, C. and A. Monfort (1993), ‘Simulation-based inference:
A survey with special reference to panel data models’, Journal of
Econometrics 59, 5–33.
Greene, W. (2000), Econometric Analysis, 4th edn, Prentice Hall, Upper Saddle River, New Jersey.
Greene, W. (2001), ‘Fixed and random eﬀects in nonlinear models’,
Working Paper, Stern School of Business, New York University.
Griﬃths, W. (1972), ‘Estimation of actual response coeﬃcients in the
hildreth-horck random coeﬃcient model’, Journal of the American
Statistical Association 67, 663–635.
Guilkey, D. and J. Murphy (1993), ‘Estimation and testing in the random eﬀects probit model’, Journal of Econometrics 59, 301–317.
Haaijer, M., M. Wedel, M. Vriens and T. Wansbeek (1998), ‘Utility covariances and context eﬀects in conjoint mnp models’, Marketing
Science 17, 236–252.
Hajivassiliou, V. and D. McFadden (1998), ‘The method of simulated
scores for the estimation of ldv models’, Econometrica 66, 863–96.
Hajivassiliou, V., D. McFadden and P. Ruud (1996), ‘Simulation of
multivariate normal rectangle probabilities and their derivatives:
Theoretical and computational results’, Journal of Econometrics
72, 85–134.
Hajivassiliou, V. and P. Ruud (1994), Classical estimation methods
for ldv models using simulation, in R.Engle and D.McFadden,
eds, ‘Handbook of Econometrics’, North-Holland, Amsterdam,
pp. 2383–441.
Halton, J. (1960), ‘On the eﬃciency of evaluating certain quasi-random
sequences of points in evaluating multi-dimensional integrals’, Numerische Mathematik 2, 84–90.
Hamilton, J. (1996), ‘Speciﬁcation testing in markov-switching timeseries models’, Journal of Econometrics 70, 127–157.

BIBLIOGRAPHY

367

Hamilton, J. and R. Susmel (1994), ‘Autoregressive conditional heteroskedasticity and changes in regime’, Journal of Econometrics
64, 307–333.
Hammersley, J. and K. Morton (1956), ‘A new monte carlo technique:
Antithetic variates’, Proceedings of the Cambridge Philosophical
Society 52, 449–474.
Hanemann, M., J. Loomis and B. Kanninen (1991), ‘Statistical eﬃciency of double-bounded dichotomous choice contengent valuation’, American Journal of Agricultural Economics 73, 1255–1263.
Hastings, W. (1970), ‘Monte carlo sampling methods using markov
chains and their applications’, Biometrika 57, 97–109.
Hausman, J. and D. McFadden (1984), ‘Speciﬁcation tests for the
multinomial logit model’, Econometrica 52, 1219–40.
Hausman, J. and D. Wise (1978), ‘A conditional probit model for qualitative choice: Discrete decisions recognizing interdependence and
heterogeneous preferences’, Econometrica 48, 403–429.
Hausman, J., ed. (1993), Contingent Valuation: A Critical assessment,
North Holland, New York.
Hausman, J. and P. Ruud (1987), ‘Specifying and testing econometric
models for rank-ordered data’, Journal of Econometrics 34, 83–
103.
Heckman, J. (1978), ‘Dummy endogenous variables in a simultaneous
equation system’, Econometrica 46, 931–959.
Heckman, J. (1979), ‘Sample selection bias as a speciﬁcation error’,
Econometrica 47, 153–162.
Heckman, J. (1981a), The incidental parameters problem and the problem of initial condition in estimating a discrete time-discrete data
stochastic process, in C.Manski and D.McFadden, eds, ‘Structural
Analysis of Discrete Data with Econometric Applications’, MIT
Press, Cambridge, Massachusetts, pp. 179–85.

368

BIBLIOGRAPHY

Heckman, J. (1981b), Statistical models for the analysis of discrete
panel data, in C.Manski and D.McFadden, eds, ‘Structural Analysis of Discrete Data with Econometric Applications’, MIT Press,
Cambridge, MA, pp. 114–78.
Heckman, J. and B. Singer (1986), Econometric analysis of longitudinal data, in Z.Griliches and M.Intriligator, eds, ‘Handbook of
Econometrics’, North-Holland, Amsterdam, pp. 1689–1763.
Heiss, F. (2002), ‘Structural choice analysis with nested logit models’,
Working Paper, University of Mannheim.
Hensher, D. (2001), ‘The valuation of commter travel time savings for
car drivers in new zealand: Evaluating alternative model speciﬁcations’, Transportation 28, 101–118.
Hensher, D., J. Louviere and J. Swait (1999), ‘Combining sources of
preference data’, Journal of Econometrics 89, 197–221.
Hensher, D. and M. Bradley (1993), ‘Using stated response data to enrich revealed preference discrete choice models’, Marketing Leters
4, 39–152.
Hensher, D. and W. Greene (2001), ‘The mixed logit model: The state
of practice and warnings for the unwary’, Working Paper, School
of Business, The University of Sydney.
Hensher, D. and W. Greene (forthcoming), ‘Speciﬁcation and estimation of nested logit model’, Transportation Research B .
Herriges, J. and C. Kling (1996), ‘Testing the consistency of nested
logit models with utility maximization’, Economic Letters 50, 33–
39.
Horowitz, J. (1991), ‘Reconsidering the multinomial probit model’,
Transportation Research B 25, 433–438.
Horowitz, J., J. Sparmann and C. Daganzo (1982), ‘An investigation
of the accuracy of the clark approximation for the multinomial
probit model’, Transportation Science 16, 382–401.
Hotz, V. and R. Miller (1993), ‘Conditional choice probabilities and
the estimation of dynamic models’, Review of Economic Studies
60, 497–529.

BIBLIOGRAPHY

369

Hotz, V., R. Miller, S. Sanders and J. Smith (1993), ‘A simulation estimator for dynamic models of discrete choice’, Review of Economic
Studies 61, 265–289.
Huber, J. and K. Train (2001), ‘On the similarity of classical and
bayesian estimates of individual mean partworths’, Marketing Letters 12, 259–269.
Joe, S. and I. Sloan (1993), ‘Implementation of a lattice method for numerical multiple integration’, ACM Transactions in Mathematical
Software 19, 523–545.
Johannesson, M. and D. Lundin (2000), ‘The impact of physical preferences and patient habits on the diﬀusion of new drugs’, Working Paper, Department of Economics, Stockholm School of Economics.
Johnson, N., S. Kotz and N. Balakrishnan (1994), Continuous Multivariate Distributions, 2nd edn, John Wiley, New York.
Judge, G., R. Hill, W. Griﬃths, H. Lutkepohl and T. Lee (1988),
Introduction to the Theory and Practice Econometrics, 2nd edn,
John Wiley and Sons, New York.
Judge, G., R. Hill, W. Griﬃths and T. Lee (1985), The Theory and
Practice Econometrics, 2nd edn, John Wiley and Sons, New York.
Kamakura, W.A. and G. Russell (1989), ‘A probabilistic choice model
for market segmentation and elasticity structure’, Journal of Marketing Research 26, 379–390.
Karlstrom, A. (2000), ‘Non-linear value functions in random utility
econometrics’, Conference Presentation, 9th IATBR Travel Behavior Conference, Australia.
Karlstrom, A. (2001), ‘Developing generalized extreme value models
using the piekands’ representation theorem’, Working Paper, Infrastructure and Planning, Royal Institute of Technology, Stockholm, Sweden.
Kass, R., B. Carlin, A. Gelman and R. Neal (1998), ‘Markov chain
monte carlo in practice: A roundtable discussion’, The American
Statistician 52, 93–100.

370

BIBLIOGRAPHY

Keane, M. (1990), Four Essays in Empirical Macro and Labor Economics, PhD thesis, Brown University.
Keane, M. (1994), ‘A computationally practical simulation estimator
for panel data’, Econometrica 62, 95–116.
Keane, M. and K. Wolpin (1994), ‘The solutions and estimation of
discrete choice dynamic programming models by simulation and
interpretation: Monte carlo evidence’, The Review of Economics
and Statistics 76, 648–672.
Kling, C. and J. Herriges (1995), ‘An empirical investigation of the consistency of nested logit models with utility maximization’, American Journal of Agricultural Economics 77, 875–884.
Koppelman, F. and C. Wen (1998), ‘Alternative nested logit models:
Structure, properties and estimation’, Transportation Research B
32, 289–298.
Koppelman, F. and C. Wen (2000), ‘The paired combination logit
model: Properties, estimation and application’, Transportation
Research B 34, 75–89.
LaPlace, P. (1820), Theorie Analytique Des Probabilites, 3rd edn,
Paris.
Lee, B. (1999), ‘Calling patterns and usage of residential toll service under self-selecting tariﬀs’, Journal of Regulatory Economics 16, 45–
82.
Lee, L. (1992), ‘On the eﬃciency of methods of simulated moments
and simulated likelihood estimation of discrete choice models’,
Econometric Theory 8, 518–552.
Lee, L. (1995), ‘Asymptotic bias in simulated maximum likelihood estimation of discrete choice models’, Econometric Theory 11, 437–
483.
Lehmann, E. and G. Casella (1998), Theory of Point Estimation, 2nd
edn, Springer, New York.
Levy, A. (2001), ‘A simple consistent non-parametric estimator of the
regression function in truncated samples’, Working Paper, Department of Economics, North Carolina State University.

BIBLIOGRAPHY

371

Lewbel, A. and O. Linton (forthcoming), ‘Nonparametric censored and
truncated regression’, Econometrica .
Liu, Y. and H. Mahmassani (2000), ‘Global maximum likelihood estimation procedures for multinomial probit (mnd) model parameters’, Transportation Research B 34, 419–444.
Louviere, J., D. Hensher and J. Swait (2000), Stated Choice Methods: Analysis and Applications, Cambridge University Press, New
York.
Luce, D. (1959), Individual Choice Behavior, John Wiley and Sons,
New York.
Luce, D. and P. Suppes (1965), Preferences, utility and subjective
probability, in R.Luce, R.Bush and E.Galanter, eds, ‘Handbook
of Mathematical Psychology’, John Wiley and Sons, New York,
pp. 249–410.
Manski, C. and D. McFadden (1981), Alternative estimators
and sample designs for discrete choice analysis, in C.Manski
and D.McFadden, eds, ‘Structural Analysis of Discrete Data
with Econometric Applications’, MIT Press, Cambridge, Massachusetts, pp. 2–50.
Manski, C. and S. Lerman (1977), ‘The estimation of choice probabilities from choice based samples’, Econometrica 45, 1977–88.
Manski, C. and S. Lerman (1981), On the use of simulated
frequencies to approximate choice probabilities, in C.Manski
and D.McFadden, eds, ‘Structural Analysis of Discrete Data
with Econometric Applications’, MIT Press, Cambridge, Massachusetts, pp. 305–19.
Marschak, J. (1960), Binary choice constraints on random utility indications, in K.Arrow, ed., ‘Stanford Symposium on Mathematical
Methods in the Social Science’, Stanford University Press, Stanford, California, pp. 312–29.
McCulloch, R. and P. Rossi (1994), ‘An exact likelihood analysis of the
multinomial probit model’, Journal of Econometrics 64, 207–240.

372

BIBLIOGRAPHY

McCulloch, R. and P. Rossi (2000), Bayesian analysis of the multinomial probit model, in R.Mariano, T.Schuermann and M.Weeks,
eds, ‘Simulation-Based Inference in Econometrics’, Cambridge
University Press, New York.
McFadden, D. (1974), Conditional logit analysis of qualitative choice
behavior, in P.Zarembka, ed., ‘Frontiers in Econometrics’, Academic Press, New York, pp. 105–42.
McFadden, D. (1978), Modeling the choice of residential location, in
A.Karlqvist, L.Lundqvist, F.Snickars and J.Weibull, eds, ‘Spatial
Interaction Theory and Planning Models’, North-Holland, Amsterdam, pp. 75–96.
McFadden, D. (1987), ‘Regression-based speciﬁcation tests for the
multinomial logit model’, Journal of Econometrics 34, 63–82.
McFadden, D. (1989), ‘A method of simulated moments for estimation of discrete response models without numerical integration’,
Econometrica 57, 995–1026.
McFadden, D. (1996), ‘Lectures on simulation-assisted statistical inference’, Conference Presentation, EC-squared Conference, Florence, Italy.
McFadden, D. (1999), Computing willingness-to-pay in random utility
models, in J.Moore, R.Riezman and J.Melvin, eds, ‘Trade, Theory and Econometrics: Essays in Honour of John S. Chipman’,
Routledge, London, pp. 253–274.
McFadden, D. (2001), ‘Economic choices’, American Economic Review
91, 351–378.
McFadden, D., A. Talvitie, S. Cosslett, I. Hasan, M Johnson, F.
Reid and K. Train (1977), ‘Demand model estimation and validation’, Final Report, Volume V, Urban Travel Demand Forecasting Project, Institute of Transportation Studies, University of
California, Berkeley.
McFadden, D. and K. Train (1996), ‘Consumers’ evaluation of new
products: Learning from self and others’, Journal of Political
Economy 104, 683–703.

BIBLIOGRAPHY

373

McFadden, D. and K. Train (2000), ‘Mixed mnl models of discrete
response’, Journal of Applied Econometrics 15, 447–470.
McFadden, D., K. Train and W. Tye (1978), ‘An application of diagnostic tests for the independence from irrelevant alternatives
property of the multinomial logit model’, Transportation Research
Record 637, 39–46.
McGrath, E. (1970), Fundamentals of Operations Research, West
Coast University Press, San Francisco.
Mehndiratta, S. (1996), Time-of-Day Eﬀects in Inter-City Business
Travel, PhD thesis, University of California, Berkeley.
Metropolis, N., A. Rosenbluth, M. Rosenbluth, A. Teller and E. Teller
(1953), ‘Equations of state calculations by fast computing machines’, Journal of Chemical Physics 21, 1087–1092.
Morokoﬀ, W. and R. Caﬂisch (1995), ‘Quasi-monte carlo integration’,
Journal of Computational Physics 122, 218–230.
Munizaga, M. and R. Alvarez-Daziano (2001), ‘Mixed logit versus
nested logit and probit’, Working Paper, Departmento de Ingeniera Civil, Universidad de Chile.
Nevo, A. (2000), ‘A practitioner’s guide to estimation of random coefﬁcients logit models of demand’, Journal of Economics and Management Science 9, 513–548.
Nevo, A. (2001), ‘Measuring market power in the ready-to-eat cereal
industry’, Econometrica 69, 307–342.
Niederreiter, H. (1978), ‘Quasi-monte carlo methods and pseudorandom numbers’, Bulletin of the American Mathematical Society
84, 957–1041.
Niederreiter, H. (1988), ‘Low-discrepancy and low dispersion sequences’, Journal of Number Theory 30, 51–70.
O’Donoghue, T. and M. Rabin (1999), ‘Doing it now or later’, American Economic Review 89, 103–124.
Ortuzar, J. (1983), ‘Nested logit models for mixed-mode travel in urban
corridors’, Transportation Research A 17, 283–299.

374

BIBLIOGRAPHY

Pakes, A. (1986), ‘Patents as options: Some estimates of the value of
holding european patent stocks’, Econometrica 54, 755–785.
Pakes, A. and D. Pollard (1989), ‘Simulation and asymptotics of optimization estimators’, Econometrica 57, 1027–1057.
Papatla, P. and L. Krishnamurthi (1992), ‘A probit model of choice
dynamics’, Marketing Science 11, 189–206.
Rao, B. (1987), Asymptotic Theory of Statistical Inference, John Wiley,
New York.
Recker, W. (1995), ‘Discrete choice with an oddball atlernative’, Transportation Research B 29, 207–211.
Revelt, D. (1999), Three Discrete Choice Random Coeﬃcients Papers
and One Police Crime Study, PhD thesis, University of California,
Berkeley.
Revelt, D. and K. Train (1998), ‘Mixed logit with repeated choices’,
Review of Economics and Statistics 80, 647–657.
Revelt, D. and K. Train (2000), ‘Speciﬁc taste parameters and mixed
logit’, Working Paper No. E00-274, Department of Economics,
University of California, Berkeley.
Rossi, P., R. McCulloch and G. Allenby (1996), ‘The value of household
information in target marketing’, Marketing Science 15, 321–340.
Rust, J. (1987), ‘Optimal replacement of gmc bus engines: An empirical model of harold zurchner’, Econometrica 55, 993–1033.
Rust, J. (1994), Estimation of dynamic structural models, problems
and prospects: Discrete decision processes, in C.Sims, ed., ‘Advances in Econometrics: Sixth World Congress’, Vol. II, Cambridge University Press, New York, pp. 5–33.
Rust, J. (1997), ‘Using randomization to break the curse of dimensionality’, Econometrica 65, 487–516.
Ruud, P. (2000), An Introduction to Classical Econometric Theory,
Oxford University Press, New York.

BIBLIOGRAPHY

375

Sándor, Z. and K. Train (2002), ‘Quasi-random simulation of discrete
choice models’, Working Paper, Department of Economics, University of Gronigen, The Netherlands.
Sándor, Z. and P. András (2001), ‘Alternative sampling methods for
estimating multivariate normal probabilities’, Working Paper, Department of Economics, University of Gronigen, The Netherlands.
SawtoothSoftware (1999), ‘The cbc/hb module for hierarchical bayes’,
at www.sawtoothsoftware.com.
Schechter, L. (2001), ‘The apple and your eye: Visual and taste rankordered probit analysis’, Working Paper, Department of Agricultural and Resource Economics, University of California, Berkeley.
Siikamaki, J. (2001), Discrete Choice Experiments Valuing Biodiversity Conservation in Finland, PhD thesis, University of California,
Davis.
Siikamaki, J. and D. Layton (2001), ‘Pooled models for contingent valuation and contingent ranking data: Valuing beneﬁts from biodiversity conservation’, Working Paper, Department of Agricultural
and Resource Economics, University of California, Davis.
Sloan, I and H. Wozniakowski (1998), ‘When are quasi-monte carlo
algorithms eﬃcient for high dimensional integrals?’, Journal of
Complexity 14, 1–33.
Small, K. (1987), ‘A discrete choice model for ordered alternatives’,
Econometrica 55, 409–424.
Small, K. (1994), ‘Approximate generalized extreme value models of
discrete choice’, Journal of Econometrics 62, 351–382.
Small, K. and H. Rosen (1981), ‘Applied welfare economics of discrete
choice models’, Econometrica 49, 105–130.
Spanier, J. and E. Maize (1991), ‘Quasi-random methods for estimating integrals using relatively small samples’, SIAM Review 36, 18–
44.
Srinivasan, K. and H. Mahmassani (2000), ‘Dynamic kernel logit model
for the analysis of longtitude discrete choice data: Properties and

376

BIBLIOGRAPHY
computational assessment’, Working Paper, Department of Civil
Engineering, University of Texas, Austin.

Steckel, J. and W. Vanhonacker (1988), ‘A heterogeneous conditional
logit model of choice’, Journal of Business and Economic Statistics 6, 391–398.
Swait, J. and J. Louviere (1993), ‘The role of the scale parameter in
the estimation and use of multinomial logit models’, Journal of
Marketing Research 30, 305–314.
Talvitie, A. (1976), ‘Disaggregate travel demand models with disaggregate data, not aggregate data, and why’, Working Paper No. 7615,
Urban Travel Demand Forecasting Project, Institute of Transportation Studies, University of California, Berkeley.
Theil, H. (1971), Principles of Econometrics, John Wiley, New York.
Thurstone, L. (1927), ‘A law of comparative judgement’, Psychological
Review 34, 273–86.
Train, K. (1978), ‘A validation test of a diaggregate mode choice
model’, Transportation Research 12, 167–174.
Train, K. (1986), Qualitative Choice Analysis, MIT Press, Cambridge,
MA.
Train, K. (1998), ‘Recreation demand models with taste variation’,
Land Economics 74, 230–239.
Train, K. (1999), Mixed logit models for recreation demand, in
J.Herriges and C.Kling, eds, ‘Valuing Recreation and the Environment’, Edward Elgar, Northampton, MA.
Train, K. (2000), ‘Halton sequences for mixed logit’, Working Paper
No. E00-278, Department of Economics, University of California,
Berkeley.
Train, K. (2001), ‘A comparison of hierarchical bayes and maximum
simulated likelihood for mixed logit’, Working Paper, Department
of Economics, University of California, Berkeley.

BIBLIOGRAPHY

377

Train, K. and D. McFadden (1978), ‘The goods-leisure tradeoﬀ and
disaggregate work trip mode choice models’, Transportation Research 12, 349–353.
Train, K., D. McFadden and A. Goett (1987), ‘Consumer attitudes and
voluntary rate schedules for public utilities’, Review of Economics
and Statistics LXIX, 383–391.
Train, K., D. McFadden and M. Ben-Akiva (1987), ‘The demand for
local telephone service: A fully discrete model of residential calling
patterns and service choice’, Rand Journal of Economics 18, 109–
123.
Train, K., M. Ben-Akiva and T. Atherton (1989), ‘Consumption patterns and self-selecting tariﬀs’, Review of Economics and Statistics
71, 62–73.
Tuﬃn, B. (1996), ‘On the use of low-discrepancy sequences in monte
carlo methods’, Monte Carlo Methods and Applications 2, 295–
320.
Tversky, A. (1972), ‘Elimination by aspects: A theory of choice’, Psychological Review 79, 281–299.
Vijverberg, W. (1997), ‘Monte carlo evaluation of multivariate normal
probabilities’, Journal of Econometrics 76, 281–307.
VonMises, R. (1931), Wahrscheinlichkeitsrechnung, Springer Verlag,
Berlin.
Vovsha, P. (1997), ‘The cross-nested logit model: Application to mode
choice in the tel aviv metropolitan area’, Conference presentation,
76th Transportation Research Board Meetings, Washington, DC.
Wang, X., E. Bradlow and H. Wainer (2001), ‘A general bayesian model
for testlets: Theory and application’, Working Paper, Department
of Statistics, University of North Carolina, Chapel Hill.
Wedel, M. and W. Kamakura (2000), Market Segmentation: Conceptual and Methodological Foundations, 2nd edn, Kluwer Academic
Publishers, Boston, MA.
Wen, C.-H. and F. Koppelman (2001), ‘The generalized nested logit
model’, Transportation Research B 35, 627–641.

378

BIBLIOGRAPHY

Wen, D. and M. Levy (2001), ‘An application of bayes estimation under
bounded asymmetric blinex loss: Direct mail decision problem’,
Conference presentation, Bayesian Application and Methods in
Marketing Conference, Ohio State University.
Williams, H. (1977), ‘On the formation of travel demand models and
economic evaluation measures of user beneﬁts’, Environment and
Planning A 9, 285–344.
Wolpin, K. (1984), ‘An estimable dynamic stochastic model of fertility
and child mortality’, Journal of Political Economy 92, 852–74.
Wolpin, K. (1987), ‘Estimating a structural search model: The transition from scool to work’, Econometrica 55, 801–18.
Yai, T., S. Iwakura and S. Morichi (1997), ‘Multinomial probit with
structured covariance for route choice behavior’, Transporation
Research B 31, 195–207.
Zavoina, R. and W. McElvey (1975), ‘A statistical model for the analysis of ordinal level dependent variables’, Journal of Mathematical
Sociology Summer, 103–120.
Zellner, A. (1971), An Introduction to Bayesian Inference in Econometrics, John Wiley and Sons, New York.

